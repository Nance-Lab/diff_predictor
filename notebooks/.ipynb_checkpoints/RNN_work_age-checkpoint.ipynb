{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- added to file ----\n",
    "# Takes in a String, \"bucket_name\", a string, \"remote_folder\",\n",
    "# and a list of strings or a single string, \"keywords\". Gets all\n",
    "# s3 keys for bucket_name/remote_folder. Uses a list convention\n",
    "# to go through keywords (i.e): ['a', 'b', 'c OR d OR e'] will \n",
    "# find all files containing 'a' and 'b' and either 'c', 'd', or 'e'.\n",
    "# Using '' will return every file key in folder.\n",
    "def get_s3_keys(bucket_name, remote_folder, keywords=''):\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    obj_list = []\n",
    "    keywords = [i.split('OR') for i in list(keywords)]\n",
    "    keywords = [list(map(lambda x:x.strip(), i)) for i in keywords]\n",
    "    for object in bucket.objects.all():\n",
    "        filename = object.key.split(\"/\")[-1]\n",
    "        kwds_in = all(any(k in filename for k in ([keyword]*isinstance(keyword, str) or keyword)) for keyword in keywords)\n",
    "        if remote_folder in object.key and kwds_in:\n",
    "            obj_list.append(s3.Object(object.bucket_name, object.key))\n",
    "    return obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Takes in a path and list of keywords. Returns a list of filenames\n",
    "# that are within the path that contain one of the keyword in the list.\n",
    "# Set keyword to \"\" to get all files in the path.\n",
    "def get_files(path, keywords = [\"features_ OR msd_\"]):\n",
    "    \"\"\"\n",
    "    Takes in a path and list of keywords. Returns a list of filenames\n",
    "    that are within the path that contain one of the keyword in the list.\n",
    "    Set keyword to \"\" to get all files in the path.\n",
    "    \"\"\"\n",
    "    keywords = [i.split('OR') for i in list(keywords)]\n",
    "    keywords = [list(map(lambda x:x.strip(), i)) for i in keywords]\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    file_list = []\n",
    "    for filename in files:\n",
    "        kwds_in = all(any(k in filename for k in ([keyword]*isinstance(keyword, str) or keyword)) for keyword in keywords)\n",
    "        if (kwds_in):\n",
    "            file_list.append(filename)\n",
    "    return file_list\n",
    "\n",
    "# Pre: Both files must exhist; Feature must be in the feature file\n",
    "# Throws a FileNotFoundError exception if preconditions not met\n",
    "#\n",
    "# Adds a feature from produced features file to the track file.\n",
    "def combine_track(trackFile, feature=None, featureDF=None):\n",
    "    '''\n",
    "    Adds a feature or set of feature to the corresponding track file\n",
    "    Preconditions: Both files must exhist; Feature(s) must be in the \n",
    "    feature file. \n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    trackFile : string :\n",
    "        The file location of the dataframe \n",
    "    feature : list : string : tuple :\n",
    "        feature or set of features to attach to track dataframe\n",
    "    Output:\n",
    "    -------\n",
    "    trackDF : pd.DataFrame :\n",
    "        DataFrame of the combined tracks\n",
    "    '''\n",
    "    if isinstance(trackFile, str):\n",
    "        try:\n",
    "            trackDF = pd.read_csv(trackFile)\n",
    "        except FileNotFoundError:\n",
    "            raise(\"DataFrame cannot be located\")\n",
    "    else:\n",
    "        trackDF = trackFile\n",
    "    if featureDF is None:\n",
    "        featureDF = find_pair(trackFile)\n",
    "    if feature is None:\n",
    "        feature = np.setdiff1d(featureDF.columns.values, trackDF.columns.values)\n",
    "    elif isinstance(feature, str):\n",
    "        feature = [feature]\n",
    "    elif isinstance(feature, tuple):\n",
    "        feature = list(feature)\n",
    "    trackDF = trackDF.reindex(columns=[*trackDF.columns.tolist()] + [*feature], fill_value=np.nan)\n",
    "    maxFrames = int(trackDF[\"Frame\"].max())\n",
    "    maxTracks = int(trackDF[\"Track_ID\"].max())\n",
    "    for i in range(int(maxTracks)+1):\n",
    "        for feat in feature:\n",
    "            trackFeature = featureDF.loc[i, feat]\n",
    "            trackDF.loc[(maxFrames)*(i+1) + i, feat] = trackFeature\n",
    "    return trackDF\n",
    "\n",
    "# Trys to find the feature file pair for either the msd_ or Traj_\n",
    "# Returns the pd.DataFrame of that pair if found.\n",
    "def find_pair(filename):\n",
    "    \"\"\"\n",
    "    Trys to find the feature file pair for either the msd_ or traj_ df,\n",
    "    or the Traj_ or msd_ file for input feauture_ file.\n",
    "    Returns the pd.DataFrame of that pair if found.\n",
    "    \"\"\"\n",
    "    if \"msd_\" in filename:\n",
    "        try:\n",
    "            filename = filename.replace(\"msd_\", \"\").replace(\"Traj_\", \"\")\n",
    "            filename = filename.split(\"/\")\n",
    "            filename[-1] = \"features_\" + filename[-1]\n",
    "            featureFile = \"/\".join(filename)\n",
    "            return pd.read_csv(featureFile)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File pair could not be found\")  \n",
    "    elif \"features_\" in filename:\n",
    "        try:\n",
    "            filename = filename.replace(\"features_\", \"\")\n",
    "            filename = filename.split(\"/\")\n",
    "            filename[-1] = \"msd_\" + filename[-1]\n",
    "            featureFile = \"/\".join(filename)\n",
    "            return pd.read_csv(featureFile)\n",
    "        except:\n",
    "            try:\n",
    "                filename = filename.replace(\"features_\", \"\")\n",
    "                filename = filename.split(\"/\")\n",
    "                filename[-1] = \"Traj_\" + filename[-1]\n",
    "                featureFile = \"/\".join(filename)\n",
    "                return pd.read_csv(featureFile)\n",
    "            except FileNotFoundError:\n",
    "                print(\"File pair could not be found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Notebook Dir: C:\\Users\\david\\Documents\\nancework\\source\\diff_predictor\\notebooks\n",
      "Using current directory for loading data: C:\\Users\\david\\Documents\\nancework\\source\\diff_predictor\n"
     ]
    }
   ],
   "source": [
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = getcwd()\n",
    "print('Current Notebook Dir: ' + workbookDir)\n",
    "chdir(workbookDir) # Go to current workbook Dir\n",
    "chdir('..')        # Go up one\n",
    "print(f'Using current directory for loading data: {getcwd()}')\n",
    "workbookDir = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './region_feature_folder/'\n",
    "track_file_list = get_files(dataset_path, keywords=['msd_'])\n",
    "feature_file_list = get_files(dataset_path, ['features_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/david/Documents/nancework/source/diff_predictor\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_NT_brain_2_slice_1_vid_1.csv size: (416, 23)\n",
      "features_NT_brain_2_slice_1_vid_2.csv size: (833, 91)\n",
      "features_NT_brain_2_slice_1_vid_3.csv size: (1017, 91)\n",
      "features_NT_brain_2_slice_1_vid_4.csv size: (878, 91)\n",
      "features_NT_brain_2_slice_1_vid_5.csv size: (467, 91)\n",
      "features_NT_brain_2_slice_2_vid_1.csv size: (2488, 91)\n",
      "features_NT_brain_2_slice_2_vid_2.csv size: (2322, 91)\n",
      "features_NT_brain_2_slice_2_vid_3.csv size: (1735, 91)\n",
      "features_NT_brain_2_slice_2_vid_4.csv size: (1650, 91)\n",
      "features_NT_brain_2_slice_2_vid_5.csv size: (2100, 91)\n",
      "features_NT_brain_2_slice_3_vid_1.csv size: (562, 91)\n",
      "features_NT_brain_2_slice_3_vid_2.csv size: (853, 91)\n",
      "features_NT_brain_2_slice_3_vid_3.csv size: (817, 91)\n",
      "features_NT_brain_2_slice_3_vid_4.csv size: (598, 23)\n",
      "features_NT_brain_2_slice_3_vid_5.csv size: (1062, 91)\n",
      "features_P14_40nm_s1_v1.csv size: (793, 91)\n",
      "features_P14_40nm_s1_v2.csv size: (1356, 91)\n",
      "features_P14_40nm_s1_v3.csv size: (519, 91)\n",
      "features_P14_40nm_s1_v4.csv size: (140, 91)\n",
      "features_P14_40nm_s1_v5.csv size: (268, 91)\n",
      "features_P14_40nm_s2_v1.csv size: (568, 91)\n",
      "features_P14_40nm_s2_v2.csv size: (938, 91)\n",
      "features_P14_40nm_s2_v3.csv size: (220, 91)\n",
      "features_P14_40nm_s2_v4.csv size: (162, 91)\n",
      "features_P14_40nm_s2_v5.csv size: (258, 91)\n",
      "features_P14_40nm_s3_v1.csv size: (151, 91)\n",
      "features_P14_40nm_s3_v2.csv size: (243, 91)\n",
      "features_P14_40nm_s3_v3.csv size: (323, 91)\n",
      "features_P14_40nm_s3_v4.csv size: (113, 91)\n",
      "features_P14_40nm_s3_v5.csv size: (389, 91)\n",
      "features_P21_40nm_s1_v1.csv size: (807, 91)\n",
      "features_P21_40nm_s1_v2.csv size: (2481, 91)\n",
      "features_P21_40nm_s1_v3.csv size: (1330, 91)\n",
      "features_P21_40nm_s1_v4.csv size: (1294, 91)\n",
      "features_P21_40nm_s1_v5.csv size: (2540, 91)\n",
      "features_P21_40nm_s2_v1.csv size: (2584, 91)\n",
      "features_P21_40nm_s2_v2.csv size: (846, 91)\n",
      "features_P21_40nm_s2_v3.csv size: (435, 91)\n",
      "features_P21_40nm_s2_v4.csv size: (1506, 91)\n",
      "features_P21_40nm_s2_v5.csv size: (2884, 91)\n",
      "features_P21_40nm_s3_v1.csv size: (1086, 91)\n",
      "features_P21_40nm_s3_v2.csv size: (679, 91)\n",
      "features_P21_40nm_s3_v3.csv size: (456, 91)\n",
      "features_P21_40nm_s3_v4.csv size: (1417, 91)\n",
      "features_P21_40nm_s3_v5.csv size: (915, 91)\n",
      "features_P28_40nm_s1_v1.csv size: (679, 91)\n",
      "features_P28_40nm_s1_v2.csv size: (480, 91)\n",
      "features_P28_40nm_s1_v3.csv size: (195, 91)\n",
      "features_P28_40nm_s1_v4.csv size: (699, 91)\n",
      "features_P28_40nm_s1_v5.csv size: (457, 91)\n",
      "features_P28_40nm_s2_v1.csv size: (500, 91)\n",
      "features_P28_40nm_s2_v2.csv size: (610, 91)\n",
      "features_P28_40nm_s2_v3.csv size: (494, 91)\n",
      "features_P28_40nm_s2_v4.csv size: (703, 91)\n",
      "features_P28_40nm_s2_v5.csv size: (372, 91)\n",
      "features_P28_40nm_s3_v1.csv size: (203, 91)\n",
      "features_P28_40nm_s3_v2.csv size: (306, 91)\n",
      "features_P28_40nm_s3_v3.csv size: (326, 91)\n",
      "features_P28_40nm_s3_v4.csv size: (75, 91)\n",
      "features_P28_40nm_s3_v5.csv size: (195, 91)\n"
     ]
    }
   ],
   "source": [
    "fstats_tot = None\n",
    "video_num = 0\n",
    "for filename in feature_file_list[1:-1]:\n",
    "    try:\n",
    "        fstats = pd.read_csv(dataset_path + '/' + filename, encoding = \"ISO-8859-1\", index_col='Unnamed: 0')\n",
    "        tstats = find_pair(dataset_path + '/' + filename)\n",
    "        print('{} size: {}'.format(filename, fstats.shape))\n",
    "        if 'P14' in filename:\n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[14], index=fstats.index)\n",
    "        elif 'P21' in filename: \n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[21], index=fstats.index)\n",
    "        elif 'P28' in filename:\n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[28], index=fstats.index)\n",
    "        elif 'NT_brain_2' in filename:\n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[35], index=fstats.index)\n",
    "        else:\n",
    "            print('Error, no target')\n",
    "        fstats['Video Number'] = pd.Series(fstats.shape[0]*[video_num], index=fstats.index)\n",
    "        fstats = combine_track(tstats, np.append(feat, ['age']), featureDF=fstats)\n",
    "        if fstats_tot is None:\n",
    "            fstats_tot = fstats\n",
    "        else:\n",
    "            fstats_tot = fstats_tot.append(fstats, ignore_index=True)\n",
    "        video_num += 1\n",
    "    except Exception:\n",
    "        print('Skipped!: {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fstats_tot.to_csv('saved_datasets/P14_P21_P28_P32_featuresandtracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot = pd.read_csv('saved_datasets/P14_P21_P28_P32_featuresandtracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.array(['AR', 'D_fit', 'Deff1', 'Deff2', 'MSD_ratio', 'alpha',\n",
    "       'asymmetry1', 'asymmetry2', 'asymmetry3', 'boundedness',\n",
    "       'efficiency', 'elongation', 'fractal_dim', 'frames', 'kurtosis',\n",
    "       'straightness', 'trappedness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_df(df, col, res=(0, 651)):\n",
    "    '''\n",
    "    Zeros a single dataframe column so that the first value will be\n",
    "    located at the start of the track.\n",
    "    '''\n",
    "    try:\n",
    "        shift_val = df.iloc[res[0]:res[1]][col].reset_index().dropna().index[0]\n",
    "    except:\n",
    "        shift_val = res[0]-res[1]-1\n",
    "    return df.iloc[res[0]:res[1]][col].reset_index().shift(-shift_val, fill_value=np.nan)[col]\n",
    "\n",
    "def get_zeroed_tracks(df, col, res=650):\n",
    "    '''\n",
    "    Creates an array of all the tracks for a single column in a file\n",
    "    in which the value is zeroed to frame = 0\n",
    "    '''\n",
    "    lower = 0\n",
    "    upper = res+1\n",
    "    value = []\n",
    "    while (upper <= len(df)):\n",
    "        value.append(list(zero_df(df, col=col, res=[lower, upper])))\n",
    "        lower = upper\n",
    "        upper = lower + res + 1\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Creates x and y datasets for LSTM based off of input\n",
    "# track_df data\n",
    "def get_xy_data(df, target, feat=None, use_feat=False, res=650):\n",
    "    n_tracks = int((len(df))/(res+1))\n",
    "    frame = get_zeroed_tracks(df, 'Frame', res=res)\n",
    "    X = get_zeroed_tracks(df, 'X', res=res)\n",
    "    Y = get_zeroed_tracks(df, 'Y', res=res)\n",
    "    MSDs = get_zeroed_tracks(df, 'MSDs', res=res)\n",
    "    trgt = df[target]\n",
    "    datax = []\n",
    "    datay = []\n",
    "    datafeat = []\n",
    "    print(n_tracks)\n",
    "    for j in range(n_tracks):\n",
    "        trackx = []\n",
    "        tracky = []\n",
    "        trackfeat = []\n",
    "        for i in range(res+1):\n",
    "            trackx.append([int(frame[j][i]), X[j][i], Y[j][i], MSDs[j][i]])\n",
    "        datax.append(trackx)\n",
    "        del(trackx)\n",
    "        tracky.append(trgt[(res+1)*(j+1)-1])\n",
    "        datay.append(tracky)\n",
    "        del(tracky)\n",
    "        if use_feat is True:\n",
    "            trackfeat.append(list(df.loc[(res+1)*(j+1)-1, feat]))\n",
    "        datafeat.append(trackfeat)\n",
    "        del(trackfeat)\n",
    "    del(df, frame, X, Y, MSDs, trgt)\n",
    "    datax = np.array(datax)\n",
    "    datax = datax.reshape(n_tracks, res+1, 4)\n",
    "    datay = np.array(datay)\n",
    "    datay = datay.reshape(n_tracks, 1)\n",
    "    datafeat = np.array(datafeat)\n",
    "    datafeat = datafeat.reshape(n_tracks, len(feat))\n",
    "    result = [datax, datay]\n",
    "    if use_feat is True:\n",
    "        result += [datafeat]\n",
    "    return tuple(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(datax, datay, datafeat) = get_xy_data(fstats_tot, 'age', feat, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track(df, track, res):\n",
    "    return df.loc[(res+1)*(track):(res+1)*(track+1)-1]\n",
    "\n",
    "def get_feat(df, track, res, feat):\n",
    "    return df.loc[(res+1)*(track+1)-1, feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./saved_datasets/RNN_datax', datax)\n",
    "# np.save('./saved_datasets/RNN_datay', datay)\n",
    "# np.save('./saved_datasets/RNN_datafeat', datafeat)\n",
    "datax = np.load('./saved_datasets/RNN_datax.npy')\n",
    "datay = np.load('./saved_datasets/RNN_datay.npy')\n",
    "datafeat = np.load('./saved_datasets/RNN_datafeat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1010\n",
    "np.random.seed(seed)\n",
    "split = 0.9\n",
    "train_index = np.random.choice(np.arange(0, len(datax)), int(len(datax)*0.7), replace=False)\n",
    "test_index = np.setdiff1d(np.arange(0, len(datax)), train_index)\n",
    "datax = np.nan_to_num(datax, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "datay = np.nan_to_num(datay, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "datafeat = np.nan_to_num(datafeat, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "X_train = datax[train_index]\n",
    "y_train = datay[train_index]\n",
    "feat_train = datafeat[train_index]\n",
    "X_test = datax[test_index]\n",
    "y_test = datay[test_index]\n",
    "feat_test = datafeat[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numpy_one_hot_encode(mat, encoder=None):\n",
    "    if encoder is None:\n",
    "        encoder = np.unique(mat)\n",
    "    mat = np.array(encoder == mat).astype(int)\n",
    "    return mat, encoder\n",
    "y_train, encoder = numpy_one_hot_encode(y_train)\n",
    "y_test, encoder = numpy_one_hot_encode(y_test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_decode(mat, encoder):\n",
    "    return np.array([i[i!=0] for i in mat * encoder])\n",
    "y_train = numpy_decode(y_train, encoder)\n",
    "y_test = numpy_decode(y_test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26452152, 14.82302878, -1.        , ...,  1.78059403,\n",
       "         0.34533962, -0.15742109],\n",
       "       [ 4.93337269, 12.36510785, -1.        , ...,  7.45517275,\n",
       "         0.42748064, -0.20779744],\n",
       "       [ 3.90237424,  1.30709157,  9.18849923, ...,  2.14101599,\n",
       "         0.80377365, -0.21617611],\n",
       "       ...,\n",
       "       [ 1.25578743, 17.48048731,  2.42073665, ...,  2.45137659,\n",
       "         0.09499466, -0.17637805],\n",
       "       [ 1.70976244,  7.57289291,  2.59848218, ...,  1.88967251,\n",
       "         0.10516635, -0.20748742],\n",
       "       [ 1.47336601,  5.68432668, 18.27565097, ...,  4.05696883,\n",
       "         0.27481758, -0.21087214]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, 4, 4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36255, 17)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, n_feat_size = feat_train.shape\n",
    "(n_samples, n_feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kera libraries\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Concatenate, Flatten, TimeDistributed\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 100)               42000     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 52,504\n",
      "Trainable params: 52,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 36255 samples\n",
      "Epoch 1/40\n",
      "36255/36255 [==============================] - 17s 471us/sample - loss: 1.2307 - accuracy: 0.4355\n",
      "Epoch 2/40\n",
      "36255/36255 [==============================] - 16s 447us/sample - loss: 1.1964 - accuracy: 0.4644\n",
      "Epoch 3/40\n",
      "36255/36255 [==============================] - 16s 447us/sample - loss: 1.1898 - accuracy: 0.4696\n",
      "Epoch 4/40\n",
      "36255/36255 [==============================] - 16s 447us/sample - loss: 1.1877 - accuracy: 0.4704\n",
      "Epoch 5/40\n",
      "36255/36255 [==============================] - 16s 445us/sample - loss: 1.1847 - accuracy: 0.4725\n",
      "Epoch 6/40\n",
      "36255/36255 [==============================] - 16s 448us/sample - loss: 1.1818 - accuracy: 0.4749- los\n",
      "Epoch 7/40\n",
      "36255/36255 [==============================] - 16s 446us/sample - loss: 1.1810 - accuracy: 0.4756\n",
      "Epoch 8/40\n",
      "36255/36255 [==============================] - 16s 445us/sample - loss: 1.1815 - accuracy: 0.4748\n",
      "Epoch 9/40\n",
      "36255/36255 [==============================] - 16s 444us/sample - loss: 1.1796 - accuracy: 0.4750\n",
      "Epoch 10/40\n",
      "36255/36255 [==============================] - 16s 445us/sample - loss: 1.1759 - accuracy: 0.4782- loss: 1.1760 - \n",
      "Epoch 11/40\n",
      "36255/36255 [==============================] - 16s 447us/sample - loss: 1.1733 - accuracy: 0.4777\n",
      "Epoch 12/40\n",
      "36255/36255 [==============================] - 16s 447us/sample - loss: 1.1737 - accuracy: 0.4786\n",
      "Epoch 13/40\n",
      "35800/36255 [============================>.] - ETA: 0s - loss: 1.1703 - accuracy: 0.4799"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-b6c1c3a9c305>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_clsfy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_timesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_40_EPOCHS_40_DROPOUT_100_batch_SHACK'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_clsfy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_timesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-128-b6c1c3a9c305>\u001b[0m in \u001b[0;36mrnn_clsfy\u001b[1;34m(X_train, y_train, n_timesteps, n_features, n_outputs, epochs, batch_size, verbose, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;31m# Final evaluation:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \"\"\"\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LSTM without dropout for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "def rnn_clsfy(X_train, y_train, n_timesteps, n_features, n_outputs, epochs=15, batch_size=64, verbose=0, **kwargs):\n",
    "    if 'dropout' not in kwargs:\n",
    "        dropout = 0.5\n",
    "    else:\n",
    "        dropout = kwargs['dropout']\n",
    "    if 'seed' not in kwargs:\n",
    "        seed = 123\n",
    "    else:\n",
    "        seed = kwargs['seed']\n",
    "    if 'metrics' not in kwargs:\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        metrics = kwargs['metrics']\n",
    "    if 'n_rnnnodes' not in kwargs:\n",
    "        n_rnnnodes = 100\n",
    "    else:\n",
    "        n_rnnnodes = kwargs['n_rnnnodes']\n",
    "    if 'n_nnnodes' not in kwargs:\n",
    "        n_rnnnodes = 100\n",
    "    else:\n",
    "        n_rnnnodes = kwargs['n_nnnodes']\n",
    "    # create the model\n",
    "    numpy.random.seed(seed)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_rnnnodes, input_shape=(n_timesteps, n_features), return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n_rnnnodes, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    # Final evaluation:\n",
    "    score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(f'Accuracy: {score[1]}')\n",
    "    return model\n",
    "\n",
    "model = rnn_clsfy(X_train, y_train, n_timesteps, n_features, n_outputs, epochs=40, batch_size=100, verbose=0, dropout=0.4, seed=10, metrics = ['accuracy'])\n",
    "model.save('.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_40_EPOCHS_40_DROPOUT_100_batch_SHACK')\n",
    "model = rnn_clsfy(X_train, y_train, n_timesteps, n_features, n_outputs, epochs=100, batch_size=100, verbose=0, dropout=0.4, seed=10, metrics = ['accuracy'])\n",
    "model.save('.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_100_batch_SHACK')\n",
    "model = rnn_clsfy(X_train, y_train, n_timesteps, n_features, n_outputs, epochs=100, batch_size=100, verbose=0, dropout=0.4, seed=10, metrics = ['accuracy'], rnnnodes=200)\n",
    "model.save('.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_100_batch_200_RNNnode_SHACK')\n",
    "model = rnn_clsfy(X_train, y_train, n_timesteps, n_features, n_outputs, epochs=100, batch_size=100, verbose=0, dropout=0.4, seed=10, metrics = ['accuracy'], nnnodes=200)\n",
    "model.save('.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_100_batch_200_NNnode_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 100)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: .\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_100_batch_SHACK\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_100_batch_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_100_batch_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 100)               42000     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 52,504\n",
      "Trainable params: 52,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TimeSeries (InputLayer)         [(None, 651, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 100)          42000       TimeSeries[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 50)           5050        lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 50)           0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "SpatialFeatures (InputLayer)    [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 67)           0           dropout_27[0][0]                 \n",
      "                                                                 SpatialFeatures[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 4)            272         concatenate_27[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 47,322\n",
      "Trainable params: 47,322\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 24290 samples, validate on 11965 samples\n",
      "Epoch 1/250\n",
      "24290/24290 [==============================] - 14s 594us/sample - loss: 1.7803 - accuracy: 0.3501 - val_loss: 1.4556 - val_accuracy: 0.4414\n",
      "Epoch 2/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.4565 - accuracy: 0.4134 - val_loss: 1.3527 - val_accuracy: 0.4448\n",
      "Epoch 3/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.3728 - accuracy: 0.4138 - val_loss: 1.3136 - val_accuracy: 0.4497\n",
      "Epoch 4/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.3484 - accuracy: 0.4186 - val_loss: 1.2996 - val_accuracy: 0.4510\n",
      "Epoch 5/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.3343 - accuracy: 0.4215 - val_loss: 1.2899 - val_accuracy: 0.4505\n",
      "Epoch 6/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.3239 - accuracy: 0.4226 - val_loss: 1.2799 - val_accuracy: 0.4511\n",
      "Epoch 7/250\n",
      "24290/24290 [==============================] - 13s 553us/sample - loss: 1.3163 - accuracy: 0.4231 - val_loss: 1.2722 - val_accuracy: 0.4508\n",
      "Epoch 8/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.3098 - accuracy: 0.4220 - val_loss: 1.2665 - val_accuracy: 0.4551\n",
      "Epoch 9/250\n",
      "24290/24290 [==============================] - 13s 553us/sample - loss: 1.3017 - accuracy: 0.4266 - val_loss: 1.2620 - val_accuracy: 0.4550\n",
      "Epoch 10/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.2933 - accuracy: 0.4293 - val_loss: 1.2575 - val_accuracy: 0.4550\n",
      "Epoch 11/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.2894 - accuracy: 0.4284 - val_loss: 1.2535 - val_accuracy: 0.4562\n",
      "Epoch 12/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.2829 - accuracy: 0.4342 - val_loss: 1.2509 - val_accuracy: 0.4562\n",
      "Epoch 13/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2853 - accuracy: 0.4320 - val_loss: 1.2490 - val_accuracy: 0.4544\n",
      "Epoch 14/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2793 - accuracy: 0.4295 - val_loss: 1.2464 - val_accuracy: 0.4572\n",
      "Epoch 15/250\n",
      "24290/24290 [==============================] - 13s 551us/sample - loss: 1.2708 - accuracy: 0.4350 - val_loss: 1.2445 - val_accuracy: 0.4577\n",
      "Epoch 16/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2726 - accuracy: 0.4360 - val_loss: 1.2424 - val_accuracy: 0.4588\n",
      "Epoch 17/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2680 - accuracy: 0.4385 - val_loss: 1.2415 - val_accuracy: 0.4562\n",
      "Epoch 18/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.2681 - accuracy: 0.4390 - val_loss: 1.2389 - val_accuracy: 0.4566\n",
      "Epoch 19/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2637 - accuracy: 0.4377 - val_loss: 1.2387 - val_accuracy: 0.4589\n",
      "Epoch 20/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2594 - accuracy: 0.4395 - val_loss: 1.2360 - val_accuracy: 0.4573\n",
      "Epoch 21/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2571 - accuracy: 0.4434 - val_loss: 1.2350 - val_accuracy: 0.4561\n",
      "Epoch 22/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2577 - accuracy: 0.4405 - val_loss: 1.2325 - val_accuracy: 0.4593\n",
      "Epoch 23/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.2547 - accuracy: 0.4418 - val_loss: 1.2320 - val_accuracy: 0.4637\n",
      "Epoch 24/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2553 - accuracy: 0.4449 - val_loss: 1.2305 - val_accuracy: 0.4616\n",
      "Epoch 25/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.2523 - accuracy: 0.4454 - val_loss: 1.2288 - val_accuracy: 0.4623\n",
      "Epoch 26/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.2497 - accuracy: 0.4438 - val_loss: 1.2283 - val_accuracy: 0.4630\n",
      "Epoch 27/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.2501 - accuracy: 0.4458 - val_loss: 1.2275 - val_accuracy: 0.4639\n",
      "Epoch 28/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2483 - accuracy: 0.4488 - val_loss: 1.2262 - val_accuracy: 0.4637\n",
      "Epoch 29/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2452 - accuracy: 0.4481 - val_loss: 1.2268 - val_accuracy: 0.4588\n",
      "Epoch 30/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2432 - accuracy: 0.4509 - val_loss: 1.2269 - val_accuracy: 0.4624\n",
      "Epoch 31/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.2426 - accuracy: 0.4506 - val_loss: 1.2255 - val_accuracy: 0.4586\n",
      "Epoch 32/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2405 - accuracy: 0.4519 - val_loss: 1.2256 - val_accuracy: 0.4583\n",
      "Epoch 33/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.2386 - accuracy: 0.4522 - val_loss: 1.2250 - val_accuracy: 0.4618\n",
      "Epoch 34/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.2367 - accuracy: 0.4521 - val_loss: 1.2238 - val_accuracy: 0.4598\n",
      "Epoch 35/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.2351 - accuracy: 0.4556 - val_loss: 1.2226 - val_accuracy: 0.4615\n",
      "Epoch 36/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2342 - accuracy: 0.4568 - val_loss: 1.2220 - val_accuracy: 0.4609\n",
      "Epoch 37/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.2311 - accuracy: 0.4570 - val_loss: 1.2210 - val_accuracy: 0.4599\n",
      "Epoch 38/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.2338 - accuracy: 0.4547 - val_loss: 1.2202 - val_accuracy: 0.4618\n",
      "Epoch 39/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.2299 - accuracy: 0.4552 - val_loss: 1.2190 - val_accuracy: 0.4609\n",
      "Epoch 40/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.2317 - accuracy: 0.4540 - val_loss: 1.2187 - val_accuracy: 0.4617\n",
      "Epoch 41/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2268 - accuracy: 0.4588 - val_loss: 1.2181 - val_accuracy: 0.4644\n",
      "Epoch 42/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2277 - accuracy: 0.4566 - val_loss: 1.2170 - val_accuracy: 0.4613\n",
      "Epoch 43/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2253 - accuracy: 0.4597 - val_loss: 1.2167 - val_accuracy: 0.4643\n",
      "Epoch 44/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2260 - accuracy: 0.4576 - val_loss: 1.2160 - val_accuracy: 0.4628\n",
      "Epoch 45/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.2249 - accuracy: 0.4574 - val_loss: 1.2151 - val_accuracy: 0.4638\n",
      "Epoch 46/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.2257 - accuracy: 0.4570 - val_loss: 1.2152 - val_accuracy: 0.4654\n",
      "Epoch 47/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2230 - accuracy: 0.4590 - val_loss: 1.2142 - val_accuracy: 0.4630\n",
      "Epoch 48/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2241 - accuracy: 0.4594 - val_loss: 1.2133 - val_accuracy: 0.4627\n",
      "Epoch 49/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.2209 - accuracy: 0.4617 - val_loss: 1.2131 - val_accuracy: 0.4628\n",
      "Epoch 50/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2202 - accuracy: 0.4606 - val_loss: 1.2128 - val_accuracy: 0.4669\n",
      "Epoch 51/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2211 - accuracy: 0.4624 - val_loss: 1.2131 - val_accuracy: 0.4679\n",
      "Epoch 52/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.2192 - accuracy: 0.4637 - val_loss: 1.2116 - val_accuracy: 0.4680\n",
      "Epoch 53/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.2178 - accuracy: 0.4639 - val_loss: 1.2108 - val_accuracy: 0.4638\n",
      "Epoch 54/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.2185 - accuracy: 0.4592 - val_loss: 1.2102 - val_accuracy: 0.4629\n",
      "Epoch 55/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.2161 - accuracy: 0.4631 - val_loss: 1.2106 - val_accuracy: 0.4676\n",
      "Epoch 56/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.2178 - accuracy: 0.4608 - val_loss: 1.2107 - val_accuracy: 0.4686\n",
      "Epoch 57/250\n",
      "24290/24290 [==============================] - 13s 555us/sample - loss: 1.2148 - accuracy: 0.4635 - val_loss: 1.2095 - val_accuracy: 0.4659\n",
      "Epoch 58/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2163 - accuracy: 0.4637 - val_loss: 1.2090 - val_accuracy: 0.4637\n",
      "Epoch 59/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.2153 - accuracy: 0.4633 - val_loss: 1.2097 - val_accuracy: 0.4653\n",
      "Epoch 60/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2155 - accuracy: 0.4632 - val_loss: 1.2037 - val_accuracy: 0.4654\n",
      "Epoch 61/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.2101 - accuracy: 0.4644 - val_loss: 1.2037 - val_accuracy: 0.4669\n",
      "Epoch 62/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2096 - accuracy: 0.4649 - val_loss: 1.2041 - val_accuracy: 0.4646\n",
      "Epoch 63/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.2093 - accuracy: 0.4617 - val_loss: 1.2035 - val_accuracy: 0.4659\n",
      "Epoch 64/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2072 - accuracy: 0.4663 - val_loss: 1.2033 - val_accuracy: 0.4627\n",
      "Epoch 65/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2066 - accuracy: 0.4671 - val_loss: 1.2039 - val_accuracy: 0.4675\n",
      "Epoch 66/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2069 - accuracy: 0.4665 - val_loss: 1.2028 - val_accuracy: 0.4642\n",
      "Epoch 67/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2071 - accuracy: 0.4663 - val_loss: 1.2030 - val_accuracy: 0.4667\n",
      "Epoch 68/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2050 - accuracy: 0.4658 - val_loss: 1.2028 - val_accuracy: 0.4684\n",
      "Epoch 69/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.2057 - accuracy: 0.4671 - val_loss: 1.2019 - val_accuracy: 0.4676\n",
      "Epoch 70/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.2060 - accuracy: 0.4649 - val_loss: 1.2016 - val_accuracy: 0.4636\n",
      "Epoch 71/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2048 - accuracy: 0.4656 - val_loss: 1.2015 - val_accuracy: 0.4674\n",
      "Epoch 72/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2034 - accuracy: 0.4708 - val_loss: 1.2010 - val_accuracy: 0.4661\n",
      "Epoch 73/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2034 - accuracy: 0.4659 - val_loss: 1.2007 - val_accuracy: 0.4656\n",
      "Epoch 74/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.2029 - accuracy: 0.4649 - val_loss: 1.2006 - val_accuracy: 0.4660\n",
      "Epoch 75/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.2037 - accuracy: 0.4701 - val_loss: 1.2002 - val_accuracy: 0.4678\n",
      "Epoch 76/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.2029 - accuracy: 0.4686 - val_loss: 1.2002 - val_accuracy: 0.4670\n",
      "Epoch 77/250\n",
      "24290/24290 [==============================] - 14s 557us/sample - loss: 1.2006 - accuracy: 0.4704 - val_loss: 1.1998 - val_accuracy: 0.4654\n",
      "Epoch 78/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2025 - accuracy: 0.4701 - val_loss: 1.1999 - val_accuracy: 0.4696\n",
      "Epoch 79/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.2022 - accuracy: 0.4676 - val_loss: 1.1996 - val_accuracy: 0.4674\n",
      "Epoch 80/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2028 - accuracy: 0.4695 - val_loss: 1.1993 - val_accuracy: 0.4678\n",
      "Epoch 81/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.2026 - accuracy: 0.4673 - val_loss: 1.1991 - val_accuracy: 0.4684\n",
      "Epoch 82/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.2010 - accuracy: 0.4690 - val_loss: 1.1988 - val_accuracy: 0.4684\n",
      "Epoch 83/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.2000 - accuracy: 0.4695 - val_loss: 1.1985 - val_accuracy: 0.4663\n",
      "Epoch 84/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.2006 - accuracy: 0.4649 - val_loss: 1.1988 - val_accuracy: 0.4698\n",
      "Epoch 85/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.2004 - accuracy: 0.4726 - val_loss: 1.1981 - val_accuracy: 0.4663\n",
      "Epoch 86/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.2010 - accuracy: 0.4689 - val_loss: 1.1980 - val_accuracy: 0.4702\n",
      "Epoch 87/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1991 - accuracy: 0.4693 - val_loss: 1.1983 - val_accuracy: 0.4690\n",
      "Epoch 88/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.1988 - accuracy: 0.4704 - val_loss: 1.1971 - val_accuracy: 0.4666\n",
      "Epoch 89/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.1990 - accuracy: 0.4690 - val_loss: 1.1973 - val_accuracy: 0.4666\n",
      "Epoch 90/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.1987 - accuracy: 0.4729 - val_loss: 1.1971 - val_accuracy: 0.4657\n",
      "Epoch 91/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1995 - accuracy: 0.4679 - val_loss: 1.1973 - val_accuracy: 0.4663\n",
      "Epoch 92/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1979 - accuracy: 0.4713 - val_loss: 1.1970 - val_accuracy: 0.4690\n",
      "Epoch 93/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.1979 - accuracy: 0.4712 - val_loss: 1.1972 - val_accuracy: 0.4666\n",
      "Epoch 94/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1982 - accuracy: 0.4714 - val_loss: 1.1963 - val_accuracy: 0.4695\n",
      "Epoch 95/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1974 - accuracy: 0.4699 - val_loss: 1.1973 - val_accuracy: 0.4705\n",
      "Epoch 96/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1974 - accuracy: 0.4732 - val_loss: 1.1960 - val_accuracy: 0.4694\n",
      "Epoch 97/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1965 - accuracy: 0.4730 - val_loss: 1.1960 - val_accuracy: 0.4697\n",
      "Epoch 98/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1963 - accuracy: 0.4702 - val_loss: 1.1957 - val_accuracy: 0.4684\n",
      "Epoch 99/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1971 - accuracy: 0.4704 - val_loss: 1.1959 - val_accuracy: 0.4676\n",
      "Epoch 100/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1978 - accuracy: 0.4701 - val_loss: 1.1955 - val_accuracy: 0.4716\n",
      "Epoch 101/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1959 - accuracy: 0.4724 - val_loss: 1.1959 - val_accuracy: 0.4714\n",
      "Epoch 102/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1968 - accuracy: 0.4707 - val_loss: 1.1951 - val_accuracy: 0.4705\n",
      "Epoch 103/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1959 - accuracy: 0.4684 - val_loss: 1.1952 - val_accuracy: 0.4720\n",
      "Epoch 104/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.1955 - accuracy: 0.4720 - val_loss: 1.1948 - val_accuracy: 0.4705\n",
      "Epoch 105/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.1951 - accuracy: 0.4724 - val_loss: 1.1947 - val_accuracy: 0.4721\n",
      "Epoch 106/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1963 - accuracy: 0.4698 - val_loss: 1.1945 - val_accuracy: 0.4706\n",
      "Epoch 107/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1957 - accuracy: 0.4714 - val_loss: 1.1946 - val_accuracy: 0.4696\n",
      "Epoch 108/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1953 - accuracy: 0.4724 - val_loss: 1.1947 - val_accuracy: 0.4716\n",
      "Epoch 109/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1953 - accuracy: 0.4721 - val_loss: 1.1945 - val_accuracy: 0.4711\n",
      "Epoch 110/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1948 - accuracy: 0.4726 - val_loss: 1.1942 - val_accuracy: 0.4710\n",
      "Epoch 111/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1941 - accuracy: 0.4775 - val_loss: 1.1944 - val_accuracy: 0.4660\n",
      "Epoch 112/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1943 - accuracy: 0.4692 - val_loss: 1.1941 - val_accuracy: 0.4715\n",
      "Epoch 113/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1956 - accuracy: 0.4719 - val_loss: 1.1938 - val_accuracy: 0.4697\n",
      "Epoch 114/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1939 - accuracy: 0.4713 - val_loss: 1.1937 - val_accuracy: 0.4700\n",
      "Epoch 115/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1942 - accuracy: 0.4737 - val_loss: 1.1935 - val_accuracy: 0.4695\n",
      "Epoch 116/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1937 - accuracy: 0.4743 - val_loss: 1.1935 - val_accuracy: 0.4706\n",
      "Epoch 117/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1927 - accuracy: 0.4725 - val_loss: 1.1936 - val_accuracy: 0.4734\n",
      "Epoch 118/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1925 - accuracy: 0.4759 - val_loss: 1.1931 - val_accuracy: 0.4720\n",
      "Epoch 119/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1934 - accuracy: 0.4729 - val_loss: 1.1932 - val_accuracy: 0.4720\n",
      "Epoch 120/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1930 - accuracy: 0.4748 - val_loss: 1.1932 - val_accuracy: 0.4710\n",
      "Epoch 121/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1925 - accuracy: 0.4745 - val_loss: 1.1931 - val_accuracy: 0.4712\n",
      "Epoch 122/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1931 - accuracy: 0.4727 - val_loss: 1.1932 - val_accuracy: 0.4686\n",
      "Epoch 123/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1925 - accuracy: 0.4736 - val_loss: 1.1928 - val_accuracy: 0.4715\n",
      "Epoch 124/250\n",
      "24290/24290 [==============================] - 13s 537us/sample - loss: 1.1919 - accuracy: 0.4768 - val_loss: 1.1934 - val_accuracy: 0.4716\n",
      "Epoch 125/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1906 - accuracy: 0.4746 - val_loss: 1.1928 - val_accuracy: 0.4721\n",
      "Epoch 126/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1922 - accuracy: 0.4760 - val_loss: 1.1922 - val_accuracy: 0.4718\n",
      "Epoch 127/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1924 - accuracy: 0.4756 - val_loss: 1.1923 - val_accuracy: 0.4716\n",
      "Epoch 128/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1921 - accuracy: 0.4753 - val_loss: 1.1923 - val_accuracy: 0.4713\n",
      "Epoch 129/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1917 - accuracy: 0.4765 - val_loss: 1.1920 - val_accuracy: 0.4721\n",
      "Epoch 130/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1912 - accuracy: 0.4734 - val_loss: 1.1919 - val_accuracy: 0.4700\n",
      "Epoch 131/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1916 - accuracy: 0.4730 - val_loss: 1.1919 - val_accuracy: 0.4720\n",
      "Epoch 132/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1920 - accuracy: 0.4758 - val_loss: 1.1919 - val_accuracy: 0.4687\n",
      "Epoch 133/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1903 - accuracy: 0.4748 - val_loss: 1.1917 - val_accuracy: 0.4715\n",
      "Epoch 134/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1914 - accuracy: 0.4757 - val_loss: 1.1921 - val_accuracy: 0.4730\n",
      "Epoch 135/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1909 - accuracy: 0.4779 - val_loss: 1.1912 - val_accuracy: 0.4718\n",
      "Epoch 136/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1900 - accuracy: 0.4762 - val_loss: 1.1935 - val_accuracy: 0.4674\n",
      "Epoch 137/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1905 - accuracy: 0.4790 - val_loss: 1.1915 - val_accuracy: 0.4713\n",
      "Epoch 138/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1909 - accuracy: 0.4769 - val_loss: 1.1913 - val_accuracy: 0.4722\n",
      "Epoch 139/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1910 - accuracy: 0.4746 - val_loss: 1.1917 - val_accuracy: 0.4694\n",
      "Epoch 140/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1902 - accuracy: 0.4786 - val_loss: 1.1910 - val_accuracy: 0.4734\n",
      "Epoch 141/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1906 - accuracy: 0.4788 - val_loss: 1.1910 - val_accuracy: 0.4730\n",
      "Epoch 142/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1910 - accuracy: 0.4753 - val_loss: 1.1907 - val_accuracy: 0.4717\n",
      "Epoch 143/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1898 - accuracy: 0.4757 - val_loss: 1.1908 - val_accuracy: 0.4720\n",
      "Epoch 144/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1890 - accuracy: 0.4762 - val_loss: 1.1907 - val_accuracy: 0.4717\n",
      "Epoch 145/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1904 - accuracy: 0.4780 - val_loss: 1.1915 - val_accuracy: 0.4684\n",
      "Epoch 146/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1896 - accuracy: 0.4780 - val_loss: 1.1906 - val_accuracy: 0.4696\n",
      "Epoch 147/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1903 - accuracy: 0.4746 - val_loss: 1.1907 - val_accuracy: 0.4737\n",
      "Epoch 148/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1893 - accuracy: 0.4799 - val_loss: 1.1905 - val_accuracy: 0.4693\n",
      "Epoch 149/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1889 - accuracy: 0.4764 - val_loss: 1.1900 - val_accuracy: 0.4716\n",
      "Epoch 150/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1898 - accuracy: 0.4741 - val_loss: 1.1903 - val_accuracy: 0.4715\n",
      "Epoch 151/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1895 - accuracy: 0.4765 - val_loss: 1.1904 - val_accuracy: 0.4722\n",
      "Epoch 152/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1903 - accuracy: 0.4764 - val_loss: 1.1913 - val_accuracy: 0.4717\n",
      "Epoch 153/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1890 - accuracy: 0.4797 - val_loss: 1.1899 - val_accuracy: 0.4735\n",
      "Epoch 154/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1889 - accuracy: 0.4762 - val_loss: 1.1901 - val_accuracy: 0.4723\n",
      "Epoch 155/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1892 - accuracy: 0.4765 - val_loss: 1.1894 - val_accuracy: 0.4716\n",
      "Epoch 156/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.1894 - accuracy: 0.4755 - val_loss: 1.1894 - val_accuracy: 0.4715\n",
      "Epoch 157/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.1891 - accuracy: 0.4776 - val_loss: 1.1896 - val_accuracy: 0.4714\n",
      "Epoch 158/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1880 - accuracy: 0.4782 - val_loss: 1.1896 - val_accuracy: 0.4730\n",
      "Epoch 159/250\n",
      "24290/24290 [==============================] - 13s 551us/sample - loss: 1.1879 - accuracy: 0.4793 - val_loss: 1.1893 - val_accuracy: 0.4720\n",
      "Epoch 160/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1877 - accuracy: 0.4788 - val_loss: 1.1904 - val_accuracy: 0.4659\n",
      "Epoch 161/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1878 - accuracy: 0.4769 - val_loss: 1.1894 - val_accuracy: 0.4724\n",
      "Epoch 162/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1872 - accuracy: 0.4795 - val_loss: 1.1894 - val_accuracy: 0.4730\n",
      "Epoch 163/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1874 - accuracy: 0.4770 - val_loss: 1.1891 - val_accuracy: 0.4720\n",
      "Epoch 164/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1880 - accuracy: 0.4776 - val_loss: 1.1890 - val_accuracy: 0.4725\n",
      "Epoch 165/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1881 - accuracy: 0.4791 - val_loss: 1.1898 - val_accuracy: 0.4732\n",
      "Epoch 166/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1872 - accuracy: 0.4800 - val_loss: 1.1895 - val_accuracy: 0.4722\n",
      "Epoch 167/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1876 - accuracy: 0.4804 - val_loss: 1.1891 - val_accuracy: 0.4716\n",
      "Epoch 168/250\n",
      "24290/24290 [==============================] - 13s 554us/sample - loss: 1.1872 - accuracy: 0.4786 - val_loss: 1.1884 - val_accuracy: 0.4724\n",
      "Epoch 169/250\n",
      "24290/24290 [==============================] - 13s 551us/sample - loss: 1.1876 - accuracy: 0.4808 - val_loss: 1.1888 - val_accuracy: 0.4717\n",
      "Epoch 170/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1879 - accuracy: 0.4765 - val_loss: 1.1883 - val_accuracy: 0.4716\n",
      "Epoch 171/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1862 - accuracy: 0.4813 - val_loss: 1.1895 - val_accuracy: 0.4684\n",
      "Epoch 172/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1869 - accuracy: 0.4753 - val_loss: 1.1888 - val_accuracy: 0.4713\n",
      "Epoch 173/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1872 - accuracy: 0.4792 - val_loss: 1.1886 - val_accuracy: 0.4718\n",
      "Epoch 174/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1879 - accuracy: 0.4798 - val_loss: 1.1886 - val_accuracy: 0.4730\n",
      "Epoch 175/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1872 - accuracy: 0.4796 - val_loss: 1.1887 - val_accuracy: 0.4713\n",
      "Epoch 176/250\n",
      "24290/24290 [==============================] - 13s 551us/sample - loss: 1.1875 - accuracy: 0.4797 - val_loss: 1.1883 - val_accuracy: 0.4737\n",
      "Epoch 177/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1878 - accuracy: 0.4764 - val_loss: 1.1882 - val_accuracy: 0.4724\n",
      "Epoch 178/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1874 - accuracy: 0.4795 - val_loss: 1.1878 - val_accuracy: 0.4715\n",
      "Epoch 179/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1876 - accuracy: 0.4791 - val_loss: 1.1879 - val_accuracy: 0.4715\n",
      "Epoch 180/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1869 - accuracy: 0.4819 - val_loss: 1.1878 - val_accuracy: 0.4716\n",
      "Epoch 181/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1873 - accuracy: 0.4787 - val_loss: 1.1881 - val_accuracy: 0.4711\n",
      "Epoch 182/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1861 - accuracy: 0.4789 - val_loss: 1.1877 - val_accuracy: 0.4719\n",
      "Epoch 183/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1870 - accuracy: 0.4793 - val_loss: 1.1880 - val_accuracy: 0.4735\n",
      "Epoch 184/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1865 - accuracy: 0.4801 - val_loss: 1.1879 - val_accuracy: 0.4733\n",
      "Epoch 185/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1854 - accuracy: 0.4817 - val_loss: 1.1878 - val_accuracy: 0.4713\n",
      "Epoch 186/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1866 - accuracy: 0.4809 - val_loss: 1.1875 - val_accuracy: 0.4717\n",
      "Epoch 187/250\n",
      "24290/24290 [==============================] - 14s 556us/sample - loss: 1.1862 - accuracy: 0.4795 - val_loss: 1.1874 - val_accuracy: 0.4738\n",
      "Epoch 188/250\n",
      "24290/24290 [==============================] - 13s 555us/sample - loss: 1.1862 - accuracy: 0.4811 - val_loss: 1.1874 - val_accuracy: 0.4718\n",
      "Epoch 189/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1860 - accuracy: 0.4812 - val_loss: 1.1871 - val_accuracy: 0.4707\n",
      "Epoch 190/250\n",
      "24290/24290 [==============================] - 13s 554us/sample - loss: 1.1862 - accuracy: 0.4800 - val_loss: 1.1874 - val_accuracy: 0.4726\n",
      "Epoch 191/250\n",
      "24290/24290 [==============================] - 14s 564us/sample - loss: 1.1858 - accuracy: 0.4786 - val_loss: 1.1875 - val_accuracy: 0.4712\n",
      "Epoch 192/250\n",
      "24290/24290 [==============================] - 14s 556us/sample - loss: 1.1857 - accuracy: 0.4802 - val_loss: 1.1871 - val_accuracy: 0.4710\n",
      "Epoch 193/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1850 - accuracy: 0.4825 - val_loss: 1.1873 - val_accuracy: 0.4717\n",
      "Epoch 194/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1869 - accuracy: 0.4791 - val_loss: 1.1874 - val_accuracy: 0.4715\n",
      "Epoch 195/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1862 - accuracy: 0.4772 - val_loss: 1.1873 - val_accuracy: 0.4720\n",
      "Epoch 196/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1856 - accuracy: 0.4805 - val_loss: 1.1873 - val_accuracy: 0.4723.48\n",
      "Epoch 197/250\n",
      "24290/24290 [==============================] - 13s 551us/sample - loss: 1.1847 - accuracy: 0.4817 - val_loss: 1.1874 - val_accuracy: 0.4742\n",
      "Epoch 198/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1859 - accuracy: 0.4811 - val_loss: 1.1870 - val_accuracy: 0.4734\n",
      "Epoch 199/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1853 - accuracy: 0.4821 - val_loss: 1.1867 - val_accuracy: 0.4717\n",
      "Epoch 200/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1845 - accuracy: 0.4809 - val_loss: 1.1867 - val_accuracy: 0.4708\n",
      "Epoch 201/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1849 - accuracy: 0.4809 - val_loss: 1.1867 - val_accuracy: 0.4711\n",
      "Epoch 202/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1843 - accuracy: 0.4800 - val_loss: 1.1868 - val_accuracy: 0.4726\n",
      "Epoch 203/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1851 - accuracy: 0.4801 - val_loss: 1.1871 - val_accuracy: 0.4711\n",
      "Epoch 204/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1846 - accuracy: 0.4804 - val_loss: 1.1865 - val_accuracy: 0.4725\n",
      "Epoch 205/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1848 - accuracy: 0.4808 - val_loss: 1.1865 - val_accuracy: 0.4719\n",
      "Epoch 206/250\n",
      "24290/24290 [==============================] - 13s 553us/sample - loss: 1.1853 - accuracy: 0.4791 - val_loss: 1.1867 - val_accuracy: 0.4727\n",
      "Epoch 207/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1849 - accuracy: 0.4810 - val_loss: 1.1866 - val_accuracy: 0.4734\n",
      "Epoch 208/250\n",
      "24290/24290 [==============================] - 13s 555us/sample - loss: 1.1845 - accuracy: 0.4803 - val_loss: 1.1865 - val_accuracy: 0.4720\n",
      "Epoch 209/250\n",
      "24290/24290 [==============================] - 13s 548us/sample - loss: 1.1839 - accuracy: 0.4810 - val_loss: 1.1865 - val_accuracy: 0.4733\n",
      "Epoch 210/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1850 - accuracy: 0.4822 - val_loss: 1.1866 - val_accuracy: 0.4734\n",
      "Epoch 211/250\n",
      "24290/24290 [==============================] - 13s 551us/sample - loss: 1.1843 - accuracy: 0.4811 - val_loss: 1.1864 - val_accuracy: 0.4740\n",
      "Epoch 212/250\n",
      "24290/24290 [==============================] - 14s 558us/sample - loss: 1.1847 - accuracy: 0.4809 - val_loss: 1.1865 - val_accuracy: 0.4732\n",
      "Epoch 213/250\n",
      "24290/24290 [==============================] - 14s 559us/sample - loss: 1.1847 - accuracy: 0.4793 - val_loss: 1.1860 - val_accuracy: 0.4703ss: 1.1845 - accuracy: \n",
      "Epoch 214/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1840 - accuracy: 0.4804 - val_loss: 1.1863 - val_accuracy: 0.4727\n",
      "Epoch 215/250\n",
      "24290/24290 [==============================] - 14s 558us/sample - loss: 1.1847 - accuracy: 0.4803 - val_loss: 1.1861 - val_accuracy: 0.4699\n",
      "Epoch 216/250\n",
      "24290/24290 [==============================] - 13s 555us/sample - loss: 1.1831 - accuracy: 0.4795 - val_loss: 1.1860 - val_accuracy: 0.4710\n",
      "Epoch 217/250\n",
      "24290/24290 [==============================] - 14s 557us/sample - loss: 1.1842 - accuracy: 0.4795 - val_loss: 1.1862 - val_accuracy: 0.4737\n",
      "Epoch 218/250\n",
      "24290/24290 [==============================] - 14s 560us/sample - loss: 1.1834 - accuracy: 0.4818 - val_loss: 1.1861 - val_accuracy: 0.4713ccuracy\n",
      "Epoch 219/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1837 - accuracy: 0.4822 - val_loss: 1.1860 - val_accuracy: 0.4704\n",
      "Epoch 220/250\n",
      "24290/24290 [==============================] - 13s 554us/sample - loss: 1.1835 - accuracy: 0.4814 - val_loss: 1.1858 - val_accuracy: 0.4722\n",
      "Epoch 221/250\n",
      "24290/24290 [==============================] - 13s 549us/sample - loss: 1.1835 - accuracy: 0.4804 - val_loss: 1.1863 - val_accuracy: 0.4732\n",
      "Epoch 222/250\n",
      "24290/24290 [==============================] - 13s 550us/sample - loss: 1.1838 - accuracy: 0.4837 - val_loss: 1.1859 - val_accuracy: 0.4716\n",
      "Epoch 223/250\n",
      "24290/24290 [==============================] - 13s 547us/sample - loss: 1.1834 - accuracy: 0.4835 - val_loss: 1.1858 - val_accuracy: 0.4711\n",
      "Epoch 224/250\n",
      "24290/24290 [==============================] - 13s 544us/sample - loss: 1.1836 - accuracy: 0.4834 - val_loss: 1.1856 - val_accuracy: 0.4737\n",
      "Epoch 225/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1831 - accuracy: 0.4818 - val_loss: 1.1854 - val_accuracy: 0.4733\n",
      "Epoch 226/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1837 - accuracy: 0.4796 - val_loss: 1.1855 - val_accuracy: 0.4710\n",
      "Epoch 227/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1836 - accuracy: 0.4797 - val_loss: 1.1855 - val_accuracy: 0.4714\n",
      "Epoch 228/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1843 - accuracy: 0.4809 - val_loss: 1.1856 - val_accuracy: 0.4709\n",
      "Epoch 229/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1835 - accuracy: 0.4797 - val_loss: 1.1857 - val_accuracy: 0.4735\n",
      "Epoch 230/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1826 - accuracy: 0.4836 - val_loss: 1.1857 - val_accuracy: 0.4730\n",
      "Epoch 231/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1835 - accuracy: 0.4827 - val_loss: 1.1853 - val_accuracy: 0.4722\n",
      "Epoch 232/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1835 - accuracy: 0.4829 - val_loss: 1.1858 - val_accuracy: 0.4717\n",
      "Epoch 233/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1831 - accuracy: 0.4836 - val_loss: 1.1853 - val_accuracy: 0.4721\n",
      "Epoch 234/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1834 - accuracy: 0.4825 - val_loss: 1.1855 - val_accuracy: 0.4731\n",
      "Epoch 235/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1826 - accuracy: 0.4851 - val_loss: 1.1852 - val_accuracy: 0.4731\n",
      "Epoch 236/250\n",
      "24290/24290 [==============================] - 13s 539us/sample - loss: 1.1833 - accuracy: 0.4822 - val_loss: 1.1857 - val_accuracy: 0.4744\n",
      "Epoch 237/250\n",
      "24290/24290 [==============================] - 13s 538us/sample - loss: 1.1820 - accuracy: 0.4826 - val_loss: 1.1853 - val_accuracy: 0.4727\n",
      "Epoch 238/250\n",
      "24290/24290 [==============================] - 13s 540us/sample - loss: 1.1825 - accuracy: 0.4839 - val_loss: 1.1857 - val_accuracy: 0.4731\n",
      "Epoch 239/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1828 - accuracy: 0.4818 - val_loss: 1.1849 - val_accuracy: 0.4724\n",
      "Epoch 240/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1825 - accuracy: 0.4818 - val_loss: 1.1854 - val_accuracy: 0.4725\n",
      "Epoch 241/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1830 - accuracy: 0.4825 - val_loss: 1.1852 - val_accuracy: 0.4720\n",
      "Epoch 242/250\n",
      "24290/24290 [==============================] - 13s 545us/sample - loss: 1.1824 - accuracy: 0.4832 - val_loss: 1.1862 - val_accuracy: 0.4738\n",
      "Epoch 243/250\n",
      "24290/24290 [==============================] - 13s 551us/sample - loss: 1.1825 - accuracy: 0.4832 - val_loss: 1.1854 - val_accuracy: 0.4750\n",
      "Epoch 244/250\n",
      "24290/24290 [==============================] - 13s 543us/sample - loss: 1.1821 - accuracy: 0.4839 - val_loss: 1.1852 - val_accuracy: 0.4725\n",
      "Epoch 245/250\n",
      "24290/24290 [==============================] - 13s 541us/sample - loss: 1.1828 - accuracy: 0.4817 - val_loss: 1.1851 - val_accuracy: 0.4721\n",
      "Epoch 246/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1827 - accuracy: 0.4814 - val_loss: 1.1851 - val_accuracy: 0.4745\n",
      "Epoch 247/250\n",
      "24290/24290 [==============================] - 13s 555us/sample - loss: 1.1828 - accuracy: 0.4807 - val_loss: 1.1850 - val_accuracy: 0.4727\n",
      "Epoch 248/250\n",
      "24290/24290 [==============================] - 13s 552us/sample - loss: 1.1825 - accuracy: 0.4804 - val_loss: 1.1852 - val_accuracy: 0.4717\n",
      "Epoch 249/250\n",
      "24290/24290 [==============================] - 13s 542us/sample - loss: 1.1826 - accuracy: 0.4830 - val_loss: 1.1847 - val_accuracy: 0.4730\n",
      "Epoch 250/250\n",
      "24290/24290 [==============================] - 13s 546us/sample - loss: 1.1817 - accuracy: 0.4827 - val_loss: 1.1852 - val_accuracy: 0.4726\n",
      "Accuracy: 0.48745012283325195\n"
     ]
    }
   ],
   "source": [
    "def rnn_clsfy_aux(X_train, aux_train, y_train, n_timesteps, n_features, n_outputs, n_feat_size, epochs=15, dropout=0.4, batch_size=64, verbose=0, **kwargs):\n",
    "    if 'dropout' not in kwargs:\n",
    "        dropout = 0.5\n",
    "    else:\n",
    "        dropout = kwargs['dropout']\n",
    "    if 'seed' not in kwargs:\n",
    "        seed = 123\n",
    "    else:\n",
    "        seed = kwargs['seed']\n",
    "    if 'metrics' not in kwargs:\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        metrics = kwargs['metrics']\n",
    "    if 'n_rnnnodes' not in kwargs:\n",
    "        n_rnnnodes = 100\n",
    "    else:\n",
    "        n_rnnnodes = kwargs['n_rnnnodes']\n",
    "    t_input = Input(shape=(n_timesteps, n_features), dtype='float32', name='TimeSeries')\n",
    "    aux_input = Input(shape=(n_feat_size), dtype='float32', name='SpatialFeatures')\n",
    "    \n",
    "    lstm = LSTM(n_rnnnodes)(t_input) # First LSTM value\n",
    "    dense = Dense(50, activation='relu')(lstm)\n",
    "    drpout = Dropout(dropout)(dense)\n",
    "    \n",
    "    merge = Concatenate()([drpout, aux_input]) # add merge 1 here\n",
    "    \n",
    "#     hidden = Dense(100, activation='relu')(merge)\n",
    "#     hidden = Dense(100, activation='relu')(hidden)\n",
    "    output = Dense(n_outputs, activation='softmax')(merge)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "                                    name='Adam', clipvalue=0.1)\n",
    "    opt = SGD(lr=0.0001)\n",
    "    \n",
    "    model = Model(inputs=[t_input, aux_input], outputs = output)\n",
    "    model.compile(loss='kullback_leibler_divergence', optimizer=opt, metrics=metrics)\n",
    "    print(model.summary())\n",
    "    model.fit([X_train, aux_train], y_train, epochs=epochs, batch_size=batch_size, validation_split=0.33)\n",
    "    return model\n",
    "\n",
    "model = rnn_clsfy_aux(X_train, feat_train, y_train, n_timesteps, n_features, n_outputs, n_feat_size, epochs=250, batch_size=100, verbose=0, dropout=0.6, seed=10, metrics = ['accuracy'])\n",
    "score = model.evaluate([X_test, feat_test], y_test, batch_size=100, verbose=0)\n",
    "print(f'Accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = py.figure(figsize=(9,10))\n",
    "ax = f.add_subplot(211)\n",
    "ax.plot(model.history.history['loss'], label='train')\n",
    "ax.plot(model.history.history['val_loss'], label='test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "\n",
    "ax2 = f.add_subplot(212)\n",
    "ax2.plot(model.history.history['accuracy'], label='train')\n",
    "ax2.plot(model.history.history['val_accuracy'], label='test')\n",
    "ax2.legend()\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_xlabel('Number of Epochs')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.\\saved_models\\LSTM_RNN_AUX_MODEL_50_50_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('.\\saved_models\\LSTM_RNN_AUX_MODEL_50_50_SPLIT_P14_P21_P28_P35_TARGET_JUL3020_DATE_50_EPOCHS_40_DROPOUT_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for filename in filenames:\n",
    "    if tag:\n",
    "        file_tag = next(tag)\n",
    "    else:\n",
    "        file_tag = None\n",
    "    try:\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        print(file_path)\n",
    "        file_data = pd.read_csv(file_path, encoding = \"utf-8\", delimiter = 'sep')\n",
    "        if file_tag:\n",
    "            size = file_data.shape[0]\n",
    "            file_data['Tag'] = pd.Series(size*[file_tag], index=file_data.index)\n",
    "        data = pd.concat([data, file_data])\n",
    "    except IOError as err:\n",
    "        print(f'Skipped!: {filename} {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 64)      64000       input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 64)      64000       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 200)          212000      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 200)          212000      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500)          0           concatenate[0][0]                \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 40)           20040       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 40)           1640        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            41          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 573,721\n",
      "Trainable params: 573,721\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x2eac3c88b08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_clsfy(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import MAX_NB_VARIABLES, MAX_TIMESTEPS_LIST\n",
    "from utils.generic_utils import load_dataset_at, calculate_dataset_metrics, cutoff_choice, \\\n",
    "    cutoff_sequence\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Permute\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "def multi_label_log_loss(y_pred, y_true):\n",
    "    return K.sum(K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "\n",
    "\n",
    "def _average_gradient_norm(model, X_train, y_train, batch_size):\n",
    "    # just checking if the model was already compiled\n",
    "    if not hasattr(model, \"train_function\"):\n",
    "        raise RuntimeError(\"You must compile your model before using it.\")\n",
    "\n",
    "    weights = model.trainable_weights  # weight tensors\n",
    "\n",
    "    get_gradients = model.optimizer.get_gradients(\n",
    "        model.total_loss, weights)  # gradient tensors\n",
    "\n",
    "    input_tensors = [\n",
    "        # input data\n",
    "        model.inputs[0],\n",
    "        # how much to weight each sample by\n",
    "        model.sample_weights[0],\n",
    "        # labels\n",
    "        model.targets[0],\n",
    "        # train or test mode\n",
    "        K.learning_phase()\n",
    "    ]\n",
    "\n",
    "    grad_fct = K.function(inputs=input_tensors, outputs=get_gradients)\n",
    "\n",
    "    steps = 0\n",
    "    total_norm = 0\n",
    "    s_w = None\n",
    "\n",
    "    nb_steps = X_train.shape[0] // batch_size\n",
    "\n",
    "    if X_train.shape[0] % batch_size == 0:\n",
    "        pad_last = False\n",
    "    else:\n",
    "        pad_last = True\n",
    "\n",
    "    def generator(X_train, y_train, pad_last):\n",
    "        for i in range(nb_steps):\n",
    "            X = X_train[i * batch_size: (i + 1) * batch_size, ...]\n",
    "            y = y_train[i * batch_size: (i + 1) * batch_size, ...]\n",
    "\n",
    "            yield (X, y)\n",
    "\n",
    "        if pad_last:\n",
    "            X = X_train[nb_steps * batch_size:, ...]\n",
    "            y = y_train[nb_steps * batch_size:, ...]\n",
    "\n",
    "            yield (X, y)\n",
    "\n",
    "    datagen = generator(X_train, y_train, pad_last)\n",
    "\n",
    "    while steps < nb_steps:\n",
    "        X, y = next(datagen)\n",
    "        # set sample weights to one\n",
    "        # for every input\n",
    "        if s_w is None:\n",
    "            s_w = np.ones(X.shape[0])\n",
    "\n",
    "        gradients = grad_fct([X, s_w, y, 0])\n",
    "        total_norm += np.sqrt(np.sum([np.sum(np.square(g))\n",
    "                                      for g in gradients]))\n",
    "        steps += 1\n",
    "\n",
    "    if pad_last:\n",
    "        X, y = next(datagen)\n",
    "        # set sample weights to one\n",
    "        # for every input\n",
    "        if s_w is None:\n",
    "            s_w = np.ones(X.shape[0])\n",
    "\n",
    "        gradients = grad_fct([X, s_w, y, 0])\n",
    "        total_norm += np.sqrt(np.sum([np.sum(np.square(g))\n",
    "                                      for g in gradients]))\n",
    "        steps += 1\n",
    "\n",
    "    return total_norm / float(steps)\n",
    "\n",
    "\n",
    "def rnn_train_model(model: Model, \n",
    "                    train_dataset, \n",
    "                    eval_dataset,\n",
    "                    folds=5, \n",
    "                    epochs=50, \n",
    "                    batch_size=128, \n",
    "                    val_subset=None,\n",
    "                    cutoff=None,  \n",
    "                    learning_rate=1e-3, \n",
    "                    monitor='loss', \n",
    "                    optimization_mode='auto', \n",
    "                    compile_model=True):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, is_timeseries = load_dataset_at(dataset_id,\n",
    "                                                                      fold_index=dataset_fold_id,\n",
    "                                                                      normalize_timeseries=normalize_timeseries)\n",
    "    max_timesteps, max_nb_variables = calculate_dataset_metrics(X_train)\n",
    "\n",
    "    if max_nb_variables != MAX_NB_VARIABLES[dataset_id]:\n",
    "        if cutoff is None:\n",
    "            choice = cutoff_choice(dataset_id, max_nb_variables)\n",
    "        else:\n",
    "            assert cutoff in [\n",
    "                'pre', 'post'], 'Cutoff parameter value must be either \"pre\" or \"post\"'\n",
    "            choice = cutoff\n",
    "\n",
    "        if choice not in ['pre', 'post']:\n",
    "            return\n",
    "        else:\n",
    "            X_train, X_test = cutoff_sequence(\n",
    "                X_train, X_test, choice, dataset_id, max_nb_variables)\n",
    "            \n",
    "    classes = np.unique(y_train)\n",
    "    le = LabelEncoder()\n",
    "    y_ind = le.fit_transform(y_train.ravel())\n",
    "    recip_freq = len(y_train) / (len(le.classes_) *\n",
    "                                 np.bincount(y_ind).astype(np.float64))\n",
    "    class_weight = recip_freq[le.transform(classes)]\n",
    "\n",
    "    print(\"Class weights : \", class_weight)\n",
    "\n",
    "    y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
    "    y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
    "\n",
    "    if is_timeseries:\n",
    "        factor = 1./np.cbrt(2)\n",
    "    else:\n",
    "        factor = 1./np.sqrt(2)\n",
    "\n",
    "    if dataset_fold_id is None:\n",
    "        weight_fn = \"./weights/%s_weights.h5\" % dataset_prefix\n",
    "    else:\n",
    "        weight_fn = \"./weights/%s_fold_%d_weights.h5\" % (\n",
    "            dataset_prefix, dataset_fold_id)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(weight_fn, verbose=1, mode=optimization_mode,\n",
    "                                       monitor=monitor, save_best_only=True, save_weights_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=monitor, patience=100, mode=optimization_mode,\n",
    "                                  factor=factor, cooldown=0, min_lr=1e-4, verbose=2)\n",
    "    callback_list = [model_checkpoint, reduce_lr]\n",
    "\n",
    "    optm = Adam(lr=learning_rate)\n",
    "\n",
    "    if compile_model:\n",
    "        model.compile(optimizer=optm,\n",
    "                      loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if val_subset is not None:\n",
    "        X_test = X_test[:val_subset]\n",
    "        y_test = y_test[:val_subset]\n",
    "\n",
    "    model.fit([X_train, ], y_train, batch_size=batch_size, epochs=epochs, callbacks=callback_list,\n",
    "              class_weight=class_weight, verbose=2, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "def evaluate_model(model: Model, dataset_id, dataset_prefix, dataset_fold_id=None, batch_size=128, test_data_subset=None,\n",
    "                   cutoff=None, normalize_timeseries=False):\n",
    "    _, _, X_test, y_test, is_timeseries = load_dataset_at(dataset_id,\n",
    "                                                          fold_index=dataset_fold_id,\n",
    "                                                          normalize_timeseries=normalize_timeseries)\n",
    "    max_timesteps, max_nb_variables = calculate_dataset_metrics(X_test)\n",
    "\n",
    "    if max_nb_variables != MAX_NB_VARIABLES[dataset_id]:\n",
    "        if cutoff is None:\n",
    "            choice = cutoff_choice(dataset_id, max_nb_variables)\n",
    "        else:\n",
    "            assert cutoff in [\n",
    "                'pre', 'post'], 'Cutoff parameter value must be either \"pre\" or \"post\"'\n",
    "            choice = cutoff\n",
    "\n",
    "        if choice not in ['pre', 'post']:\n",
    "            return\n",
    "        else:\n",
    "            _, X_test = cutoff_sequence(\n",
    "                None, X_test, choice, dataset_id, max_nb_variables)\n",
    "\n",
    "    if not is_timeseries:\n",
    "        X_test = pad_sequences(\n",
    "            X_test, maxlen=MAX_NB_VARIABLES[dataset_id], padding='post', truncating='post')\n",
    "    y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
    "\n",
    "    optm = Adam(lr=1e-3)\n",
    "    model.compile(optimizer=optm, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if dataset_fold_id is None:\n",
    "        weight_fn = \"./weights/%s_weights.h5\" % dataset_prefix\n",
    "    else:\n",
    "        weight_fn = \"./weights/%s_fold_%d_weights.h5\" % (\n",
    "            dataset_prefix, dataset_fold_id)\n",
    "    model.load_weights(weight_fn)\n",
    "\n",
    "    if test_data_subset is not None:\n",
    "        X_test = X_test[:test_data_subset]\n",
    "        y_test = y_test[:test_data_subset]\n",
    "\n",
    "    print(\"\\nEvaluating : \")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print()\n",
    "    print(\"Final Accuracy : \", accuracy)\n",
    "\n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def set_trainable(layer, value):\n",
    "    layer.trainable = value\n",
    "\n",
    "    # case: container\n",
    "    if hasattr(layer, 'layers'):\n",
    "        for l in layer.layers:\n",
    "            set_trainable(l, value)\n",
    "\n",
    "    # case: wrapper (which is a case not covered by the PR)\n",
    "    if hasattr(layer, 'layer'):\n",
    "        set_trainable(layer.layer, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# save np.load\n",
    "#np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "#np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 650, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (36255, 651, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-586-b339e4d1dee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (36255, 651, 4)"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = tf.keras.Sequential()\n",
    "# model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Concatenate())([merge1, aux_input])\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.43%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 17s 664us/sample - loss: 0.4726 - accuracy: 0.7660\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 15s 582us/sample - loss: 0.3136 - accuracy: 0.8726\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 14s 580us/sample - loss: 0.2572 - accuracy: 0.8997\n",
      "Accuracy: 86.34%\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Dropout for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.layers.convolutional'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-946ba871defd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.convolutional'"
     ]
    }
   ],
   "source": [
    "# LSTM and CNN for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "model.add(LSTM(64, dropout=0.7, recurrent_dropout=0.7))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   14,    6,  717],\n",
       "       [   0,    0,    0, ...,  125,    4, 3077],\n",
       "       [  33,    6,   58, ...,    9,   57,  975],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   21,  846,    2],\n",
       "       [   0,    0,    0, ..., 2302,    7,  470],\n",
       "       [   0,    0,    0, ...,   34, 2005, 2643]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-11fe80a1b124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# load the dataset b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# truncate and pad input sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# LSTM with Dropout for sequence classification in msd dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset b\n",
    " z\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "\n",
    "class RNNCell(object):\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        raise NotImplementedError(\"Abstract method\")\n",
    "    \n",
    "\n",
    "class LSTMCell(RNNCell):\n",
    "    \"\"\"Basic LSTM recurrent network cell.\n",
    "    The implementation is based on: http://arxiv.org/abs/1409.2329.\n",
    "    We add forget_bias (default: 1) to the biases of the forget gate in order to\n",
    "    reduce the scale of forgetting in the beginning of the training.\n",
    "    It does not allow cell clipping, a projection layer, and does not\n",
    "    use peep-hole connections: it is the basic baseline.\n",
    "    For advanced models, please use the full LSTMCell that follows.\n",
    "    \"\"\"  \n",
    "    def __init__(self, n_units, n_proj=None, forget_bias=0.0, input_size=None, activation=tanh):\n",
    "        self._n_units  = n_units\n",
    "        self._n_proj = n_proj\n",
    "        self._forget_bias = forget_bias\n",
    "        self._input_size = input_size\n",
    "        self._activation = activation\n",
    "\n",
    "        (self._state_size, \n",
    "         self._output_size) = ((LSTMStateTuple(n_units, n_proj) , n_units + n_proj)\n",
    "                            if n_proj else (LSTMStateTuple(n_units, n_units), 2*n_units))\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self. _output_size\n",
    "    \n",
    "    \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        \n",
    "        pass\n",
    "\n",
    "# class LSTM(LSTM):\n",
    "    \n",
    "    \n",
    "#     def __init__(self, ):\n",
    "#         pass\n",
    "    \n",
    "_LSTMStateTuple = collections.namedtuple(\"LSTMStateTuple\", (\"c\", \"h\"))\n",
    "\n",
    "class LSTMStateTuple(_LSTMStateTuple):\n",
    "  \n",
    "    \"\"\"Tuple used by LSTM Cells for `state_size`, `zero_state`, and output state.\n",
    "    Stores two elements: `(c, h)`, in that order.\n",
    "    Only used when `state_is_tuple=True`.\n",
    "    \"\"\"\n",
    "    __slots__ = ()\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        (c, h) = self\n",
    "        if not c.dtype == h.dtype:\n",
    "            raise TypeError(\"Inconsistent internal state: %s vs %s\" %\n",
    "                            (str(c.dtype), str(h.dtype)))\n",
    "    return c.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTMCell(50, 20, 1.0, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=50, h=20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'n_units'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ccebf5a8883c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'n_units'"
     ]
    }
   ],
   "source": [
    "x = LSTMCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
