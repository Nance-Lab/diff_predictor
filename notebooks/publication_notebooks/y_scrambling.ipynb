{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_predictor import data_process, predxgboost, spatial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, recall_score, precision_score, f1_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import operator\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from xgboost.training import CVPack\n",
    "from xgboost import callback\n",
    "from xgboost.core import CallbackEnv\n",
    "from xgboost.core import EarlyStopException\n",
    "from xgboost.core import STRING_TYPES\n",
    "\n",
    "from diff_classifier.features import alpha_calc, unmask_track\n",
    "from diff_predictor.utils import plot_msd_comparisons, plot_individual_msds, plot_particles_in_frame\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookDir = getcwd()\n",
    "\n",
    "print('Current Notebook Dir: ' + workbookDir)\n",
    "chdir(workbookDir) # Go to current workbook Dir\"\n",
    "chdir('..')        # Go up one\n",
    "print(f'Using current directory for loading data: {getcwd()}')\n",
    "workbookDir = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load paths to data\n",
    "\n",
    "age_feature_path = workbookDir + '/Data/feature_data_age/'\n",
    "age_feature_filelist = [f for f in listdir(age_feature_path) if isfile(join(age_feature_path, f)) and 'feat' in f]\n",
    "print(len(age_feature_filelist))\n",
    "\n",
    "age_msd_path = workbookDir + '/raw_data_age/'\n",
    "age_msd_filelist = [f for f in listdir(age_msd_path) if isfile(join(age_msd_path, f)) and 'msd' in f]\n",
    "print(len(age_msd_filelist))\n",
    "\n",
    "region_dataset_path = workbookDir + '/data/region_feature_folder/'\n",
    "region_filelist = [f for f in listdir(region_dataset_path) if isfile(join(region_dataset_path, f)) and 'feat' in f]\n",
    "print(len(region_filelist))\n",
    "\n",
    "treatment_dataset_path = workbookDir + '/data/ecm_feature_folder/'\n",
    "treatment_filelist = [f for f in listdir(treatment_dataset_path) if isfile(join(treatment_dataset_path, f)) and 'msd' in f]\n",
    "print(len(treatment_filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_age = data_process.generate_fullstats(age_feature_path, age_feature_filelist, ['P14','P35', 'P70'], 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    'alpha', # Fitted anomalous diffusion alpha exponenet\n",
    "    'D_fit', # Fitted anomalous diffusion coefficient\n",
    "    'kurtosis', # Kurtosis of track\n",
    "    'asymmetry1', # Asymmetry of trajecory (0 for circular symmetric, 1 for linear)\n",
    "    'asymmetry2', # Ratio of the smaller to larger principal radius of gyration\n",
    "    'asymmetry3', # An asymmetric feature that accnts for non-cylindrically symmetric pt distributions\n",
    "    'AR', # Aspect ratio of long and short side of trajectory's minimum bounding rectangle\n",
    "    'elongation', # Est. of amount of extension of trajectory from centroid\n",
    "    'boundedness', # How much a particle with Deff is restricted by a circular confinement of radius r\n",
    "    'fractal_dim', # Measure of how complicated a self similar figure is\n",
    "    'trappedness', # Probability that a particle with Deff is trapped in a region\n",
    "    'efficiency', # Ratio of squared net displacement to the sum of squared step lengths\n",
    "    'straightness', # Ratio of net displacement to the sum of squared step lengths\n",
    "    'MSD_ratio', # MSD ratio of the track\n",
    "#     'frames', # Number of frames the track spans\n",
    "    'Deff1', # Effective diffusion coefficient at 0.33 s\n",
    "    'Deff2', # Effective diffusion coefficient at 3.3 s\n",
    "    #'angle_mean', # Mean turning angle which is counterclockwise angle from one frame point to another\n",
    "    #'angle_mag_mean', # Magnitude of the turning angle mean\n",
    "    #'angle_var', # Variance of the turning angle\n",
    "    #'dist_tot', # Total distance of the trajectory\n",
    "    #'dist_net', # Net distance from first point to last point\n",
    "    #'progression', # Ratio of the net distance traveled and the total distance\n",
    "    'Mean alpha', \n",
    "    'Mean D_fit', \n",
    "    'Mean kurtosis', \n",
    "    'Mean asymmetry1', \n",
    "    'Mean asymmetry2',\n",
    "    'Mean asymmetry3', \n",
    "    'Mean AR',\n",
    "    'Mean elongation', \n",
    "    'Mean boundedness',\n",
    "    'Mean fractal_dim', \n",
    "    'Mean trappedness', \n",
    "    'Mean efficiency',\n",
    "    'Mean straightness', \n",
    "    'Mean MSD_ratio', \n",
    "    'Mean Deff1', \n",
    "    'Mean Deff2',\n",
    "    ]\n",
    "\n",
    "target = 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm = fstats_tot_age[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preprocess(ecm, balanced=True, target=None):\n",
    "\n",
    "    rand_state = np.random.randint(1, 2000)\n",
    "    if balanced:\n",
    "        bal_ecm = data_process.balance_data(ecm, target, random_state=rand_state)\n",
    "        bal_ecm = bal_ecm.reset_index(drop=True)\n",
    "        #sampled_df = bal_ecm.sample(frac=0.5)\n",
    "        sampled_df = data_process.bin_data(bal_ecm)\n",
    "    else:\n",
    "        sampled_df = data_process.bin_data(ecm)\n",
    "\n",
    "    label_df = bal_ecm[target].copy()\n",
    "    features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "    features = features_df.columns\n",
    "\n",
    "    # label_df = sampled_df[target]\n",
    "    # features_df = sampled_df.drop([target, 'X', 'Y', 'binx', 'biny', 'bins', 'Track_ID'], axis=1)\n",
    "    # features = features_df.columns\n",
    "\n",
    "    from numpy.random import permutation\n",
    "    perm = permutation(len(label_df))\n",
    "    label_shuffled = label_df[perm]\n",
    "\n",
    "    seed = rand_state\n",
    "    np.random.seed(seed)\n",
    "    train_split = 0.8\n",
    "    test_split = 0.5\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    sampled_df['encoded_target'] = le.fit_transform(label_shuffled)\n",
    "\n",
    "\n",
    "    training_bins = np.random.choice(sampled_df['bins'].unique(), int(len(sampled_df['bins'].unique())*train_split), replace=False)\n",
    "\n",
    "    X_train = sampled_df[sampled_df['bins'].isin(training_bins)]\n",
    "    X_test_val = sampled_df[~sampled_df['bins'].isin(training_bins)]\n",
    "    X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "    y_train = X_train['encoded_target']\n",
    "    y_test = X_test['encoded_target']\n",
    "    y_val = X_val['encoded_target']\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "    dval = xgb.DMatrix(X_val[features], label=y_val)\n",
    "    return dtrain, dtest, dval, X_train, X_test, y_train, y_test, le\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 4, 'eta': 0.1, 'min_child_weight': 1, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 3, 'silent': 'True', 'gamma': 1.0, 'subsample': 0.5, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss'}\n",
    "\n",
    "models_to_run = 50\n",
    "\n",
    "target = 'age'\n",
    "age_tot_acc_vals = np.zeros(models_to_run)\n",
    "age_tot_prec_vals = np.zeros(models_to_run)\n",
    "age_tot_rec_vals = np.zeros(models_to_run)\n",
    "age_tot_f1_vals = np.zeros(models_to_run)\n",
    "\n",
    "age_booster_list = list(range(models_to_run))\n",
    "age_truelabels_list = list(range(models_to_run))\n",
    "age_preds_list = list(range(models_to_run))\n",
    "\n",
    "P14_acc_vals = np.zeros(models_to_run)\n",
    "P35_acc_vals = np.zeros(models_to_run)\n",
    "P70_acc_vals = np.zeros(models_to_run)\n",
    "\n",
    "P14_prec_vals = np.zeros(models_to_run)\n",
    "P35_prec_vals = np.zeros(models_to_run)\n",
    "P70_prec_vals = np.zeros(models_to_run)\n",
    "\n",
    "P14_rec_vals = np.zeros(models_to_run)\n",
    "P35_rec_vals = np.zeros(models_to_run)\n",
    "P70_rec_vals = np.zeros(models_to_run)\n",
    "\n",
    "P14_f1_vals = np.zeros(models_to_run)\n",
    "P35_f1_vals = np.zeros(models_to_run)\n",
    "P70_f1_vals = np.zeros(models_to_run)\n",
    "\n",
    "P14_sup_vals = np.zeros(models_to_run)\n",
    "P35_sup_vals = np.zeros(models_to_run)\n",
    "P70_sup_vals = np.zeros(models_to_run)\n",
    "\n",
    "for i in range(models_to_run):\n",
    "    print(i)\n",
    "\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=804, verbose=False)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    age_tot_acc_vals[i] = accuracy_score(true_label, preds)\n",
    "    age_tot_prec_vals[i] = precision_score(true_label, preds, average='macro')\n",
    "    age_tot_rec_vals[i] = recall_score(true_label, preds, average='macro')\n",
    "    age_tot_f1_vals[i] = f1_score(true_label, preds, average='macro')\n",
    "\n",
    "    age_booster_list[i] = booster\n",
    "    age_truelabels_list[i] = true_label\n",
    "    age_preds_list[i] = preds\n",
    "\n",
    "    prec, rec, f1, sup = precision_recall_fscore_support(true_label, preds)\n",
    "\n",
    "    p14_idx = np.where(le.classes_=='P14')\n",
    "    p35_idx = np.where(le.classes_=='P35')\n",
    "    p70_idx = np.where(le.classes_=='P70')\n",
    "\n",
    "    p14_locs = np.where(true_label==p14_idx[0])\n",
    "    p35_locs = np.where(true_label==p35_idx[0])\n",
    "    p70_locs = np.where(true_label==p70_idx[0])\n",
    "\n",
    "    P14_acc_vals[i] = accuracy_score(true_label[p14_locs], preds[p14_locs])\n",
    "    P35_acc_vals[i] = accuracy_score(true_label[p35_locs], preds[p35_locs])\n",
    "    P70_acc_vals[i] = accuracy_score(true_label[p70_locs], preds[p70_locs])\n",
    "\n",
    "\n",
    "    P14_prec_vals[i] = prec[p14_idx]\n",
    "    P35_prec_vals[i] = prec[p35_idx]\n",
    "    P70_prec_vals[i] = prec[p70_idx]\n",
    "\n",
    "    P14_rec_vals[i] = rec[p14_idx]\n",
    "    P35_rec_vals[i] = rec[p35_idx]\n",
    "    P70_rec_vals[i] = rec[p70_idx]\n",
    "\n",
    "    P14_f1_vals[i] = f1[p14_idx]\n",
    "    P35_f1_vals[i] = f1[p35_idx]\n",
    "    P70_f1_vals[i] = f1[p70_idx]\n",
    "\n",
    "    P14_sup_vals[i] = sup[p14_idx]\n",
    "    P35_sup_vals[i] = sup[p35_idx]\n",
    "    P70_sup_vals[i] = sup[p70_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P35_acc_vals.mean())\n",
    "print(P35_acc_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_acc_vals.mean())\n",
    "print(age_tot_acc_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_prec_vals.mean())\n",
    "print(age_tot_prec_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_rec_vals.mean())\n",
    "print(age_tot_rec_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_f1_vals.mean())\n",
    "print(age_tot_f1_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P35_f1_vals.mean())\n",
    "print(P35_f1_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P14_prec_vals.mean())\n",
    "print(P14_prec_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(ecm, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = bal_ecm.reset_index(drop=True)\n",
    "bal_ecm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = bal_ecm[target].copy()\n",
    "features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "features = features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import permutation\n",
    "perm = permutation(len(label_df))\n",
    "label_shuffled = label_df[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(label_shuffled)\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 3,\n",
    "         'eta': 0.005,\n",
    "         'min_child_weight': 0,\n",
    "         'verbosity': 0,\n",
    "         'objective': 'multi:softprob',\n",
    "         'num_class': 3,\n",
    "         'silent': 'True',\n",
    "         'gamma': 5,\n",
    "         'subsample': 0.15,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'eval_metric': \"mlogloss\",\n",
    "#          # GPU integration will cut time in ~half:\n",
    "#          'gpu_id' : 0,\n",
    "#          'tree_method': 'gpu_hist',\n",
    "#          'predictor': 'gpu_predictor'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 4, 'eta': 0.1, 'min_child_weight': 1, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 3, 'silent': 'True', 'gamma': 1.0, 'subsample': 0.5, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=96, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_test, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region data y-scrambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_region = data_process.generate_fullstats(region_dataset_path, region_filelist, ['cortex', 'hippocampus', 'striatum'], 'region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'region'\n",
    "ecm = fstats_tot_region[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(ecm, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)\n",
    "bal_ecm = bal_ecm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = bal_ecm[target].copy()\n",
    "features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "features = features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import permutation\n",
    "perm = permutation(len(label_df))\n",
    "label_shuffled = label_df[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(label_shuffled)\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 4,\n",
    " 'eta': 0.005,\n",
    " 'min_child_weight': 0,\n",
    " 'verbosity': 0,\n",
    " 'objective': 'multi:softprob',\n",
    " 'num_class': 3,\n",
    " 'silent': 'True',\n",
    " 'gamma': 5,\n",
    " 'subsample': 0.6,\n",
    " 'colsample_bytree': 0.7,\n",
    " 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=1157, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_test, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cortex', 'striatum', 'hippocampus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test[features], max_display=None, title='Total SHAP Values')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_treatment = data_process.generate_fullstats(treatment_dataset_path, treatment_filelist, ['NT', 'ChABC'], 'treatment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'treatment'\n",
    "ecm = fstats_tot_treatment[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(ecm, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)\n",
    "bal_ecm = bal_ecm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = bal_ecm[target].copy()\n",
    "features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "features = features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import permutation\n",
    "perm = permutation(len(label_df))\n",
    "label_shuffled = label_df[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(label_shuffled)\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 5, 'eta': 0.05, 'min_child_weight': 0, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 2, 'silent': 'True', 'gamma': 2.0, 'subsample': 0.15, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss'}\n",
    "best_boost_rounds = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_test, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#fc8d59'\n",
    "#c_HYase = '#ffffbf'\n",
    "c_ChABC = '#91bfdb'\n",
    "\n",
    "colors = [c_ChABC, c_NT]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
