{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_predictor import data_process, predxgboost, spatial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from numpy.random import permutation\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, recall_score, precision_score, f1_score\n",
    "import operator\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from xgboost.training import CVPack\n",
    "from xgboost import callback\n",
    "from xgboost.core import CallbackEnv\n",
    "from xgboost.core import EarlyStopException\n",
    "from xgboost.core import STRING_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookDir = getcwd()\n",
    "\n",
    "print('Current Notebook Dir: ' + workbookDir)\n",
    "chdir(workbookDir) # Go to current workbook Dir\"\n",
    "chdir('..')        # Go up one\n",
    "chdir('..') \n",
    "chdir('..')        # Go up one\n",
    "print(f'Using current directory for loading data: {getcwd()}')\n",
    "workbookDir = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age_feature_path = workbookDir + '/data/raw_data_age/'\n",
    "region_feature_path = '/Users/nelsschimek/Documents/nancelab/Data/OGD_severity/'\n",
    "region_feature_filelist = [f for f in listdir(region_feature_path) if isfile(join(region_feature_path, f)) and 'feat' in f and 'cortex' in f]\n",
    "print(len(region_feature_filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_age = data_process.generate_fullstats(region_feature_path, region_feature_filelist, ['NT','1_5', '0_5'], 'OGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    'alpha', # Fitted anomalous diffusion alpha exponenet\n",
    "    'D_fit', # Fitted anomalous diffusion coefficient\n",
    "    'kurtosis', # Kurtosis of track\n",
    "    'asymmetry1', # Asymmetry of trajecory (0 for circular symmetric, 1 for linear)\n",
    "    'asymmetry2', # Ratio of the smaller to larger principal radius of gyration\n",
    "    'asymmetry3', # An asymmetric feature that accnts for non-cylindrically symmetric pt distributions\n",
    "    'AR', # Aspect ratio of long and short side of trajectory's minimum bounding rectangle\n",
    "    'elongation', # Est. of amount of extension of trajectory from centroid\n",
    "    'boundedness', # How much a particle with Deff is restricted by a circular confinement of radius r\n",
    "    'fractal_dim', # Measure of how complicated a self similar figure is\n",
    "    'trappedness', # Probability that a particle with Deff is trapped in a region\n",
    "    'efficiency', # Ratio of squared net displacement to the sum of squared step lengths\n",
    "    'straightness', # Ratio of net displacement to the sum of squared step lengths\n",
    "    'MSD_ratio', # MSD ratio of the track\n",
    "    'frames', # Number of frames the track spans\n",
    "    'Deff1', # Effective diffusion coefficient at 0.33 s\n",
    "    'Deff2', # Effective diffusion coefficient at 3.3 s\n",
    "    #'angle_mean', # Mean turning angle which is counterclockwise angle from one frame point to another\n",
    "    #'angle_mag_mean', # Magnitude of the turning angle mean\n",
    "    #'angle_var', # Variance of the turning angle\n",
    "    #'dist_tot', # Total distance of the trajectory\n",
    "    #'dist_net', # Net distance from first point to last point\n",
    "    #'progression', # Ratio of the net distance traveled and the total distance\n",
    "    'Mean alpha', \n",
    "    'Mean D_fit', \n",
    "    'Mean kurtosis', \n",
    "    'Mean asymmetry1', \n",
    "    'Mean asymmetry2',\n",
    "    'Mean asymmetry3', \n",
    "    'Mean AR',\n",
    "    'Mean elongation', \n",
    "    'Mean boundedness',\n",
    "    'Mean fractal_dim', \n",
    "    'Mean trappedness', \n",
    "    'Mean efficiency',\n",
    "    'Mean straightness', \n",
    "    'Mean MSD_ratio', \n",
    "    'Mean Deff1', \n",
    "    'Mean Deff2',\n",
    "    ]\n",
    "\n",
    "target = 'OGD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm = fstats_tot_age[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "#ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm = ecm[~ecm[list(set(feature_list))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm = ecm.drop_duplicates(subset=['Mean Deff1', 'Mean Deff2'], keep='first') # Remove duplicate track_IDs\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in feature_list:\n",
    "    #ecm[feat] = scale(ecm[feat].values)\n",
    "    print(ecm[feat].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm_filt = ecm[ecm['Mean Deff1'] < 50]\n",
    "ecm_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preprocess(ecm, balanced=True, y_scramble=False, target=None):\n",
    "\n",
    "    rand_state = np.random.randint(1, 2000)\n",
    "    if balanced:\n",
    "        bal_ecm = data_process.balance_data(ecm, target, random_state=rand_state)\n",
    "        bal_ecm = bal_ecm.reset_index(drop=True)\n",
    "        #sampled_df = bal_ecm.sample(frac=0.5)\n",
    "        sampled_df = data_process.bin_data(bal_ecm)\n",
    "    else:\n",
    "        sampled_df = data_process.bin_data(ecm)\n",
    "    label_df = sampled_df[target]\n",
    "    features_df = sampled_df.drop([target, 'X', 'Y', 'binx', 'biny', 'bins', 'Track_ID'], axis=1)\n",
    "    features = features_df.columns\n",
    "\n",
    "    if y_scramble:\n",
    "        perm = permutation(len(label_df))\n",
    "        label_shuffled = label_df[perm]\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        sampled_df['encoded_target'] = le.fit_transform(label_shuffled)\n",
    "    else:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        sampled_df['encoded_target'] = le.fit_transform(sampled_df[target])\n",
    "\n",
    "    seed = rand_state\n",
    "    np.random.seed(seed)\n",
    "    train_split = 0.7\n",
    "    test_split = 0.5\n",
    "\n",
    "\n",
    "    training_bins = np.random.choice(sampled_df['bins'].unique(), int(len(sampled_df['bins'].unique())*train_split), replace=False)\n",
    "\n",
    "    X_train = sampled_df[sampled_df['bins'].isin(training_bins)]\n",
    "    X_test_val = sampled_df[~sampled_df['bins'].isin(training_bins)]\n",
    "    X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "    y_train = X_train['encoded_target']\n",
    "    y_test = X_test['encoded_target']\n",
    "    y_val = X_val['encoded_target']\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "    dval = xgb.DMatrix(X_val[features], label=y_val)\n",
    "    return dtrain, dtest, dval, X_train, X_test, y_train, y_test, le\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 3,\n",
    "         'eta': 0.005,\n",
    "         'min_child_weight': 0,\n",
    "         'verbosity': 0,\n",
    "         'objective': 'multi:softprob',\n",
    "         'num_class': 3,\n",
    "         'silent': 'True',\n",
    "         'gamma': 5,\n",
    "         'subsample': 0.15,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'eval_metric': \"mlogloss\",\n",
    "#          # GPU integration will cut time in ~half:\n",
    "#          'gpu_id' : 0,\n",
    "#          'tree_method': 'gpu_hist',\n",
    "#          'predictor': 'gpu_predictor'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(ecm, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)\n",
    "label_df = bal_ecm[target]\n",
    "features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "features = features_df.columns\n",
    "\n",
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.8\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(bal_ecm[target])\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = predxgboost.xgb_paramsearch(X_train, y_train, feature_list, init_params=param, num_round=1000, nfold=5, early_stopping_rounds=10, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_cort = {'max_depth': 5, 'eta': 0.01, 'min_child_weight': 10, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 3, 'silent': 'True', 'gamma': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.9, 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_param = {'max_depth': 4, 'eta': 0.005, 'min_child_weight': 0, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 3, 'silent': 'True', 'gamma': 5.0, 'subsample': 0.6, 'colsample_bytree': 0.7, 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently using parameters found in the diff_mode analysis notebook for age\n",
    "booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=1042, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = le.classes_\n",
    "class_names = ['0.5h', '1.5h', 'HC']\n",
    "class_results = classification_report(true_label, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(true_label, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"axes.labelsize\"] = 12\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "plt.rcParams[\"legend.fontsize\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], X_test[feature_list], max_display=5, show=False, color_bar=True)\n",
    "plt.gcf().axes[-1].set_aspect(50)\n",
    "plt.gcf().axes[-1].set_box_aspect(50)\n",
    "plt.title(f'Top 5 Features for {class_names[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_test[feature_list], max_display=5, show=False, color_bar=True)\n",
    "plt.gcf().axes[-1].set_aspect(50)\n",
    "plt.gcf().axes[-1].set_box_aspect(50)\n",
    "plt.title(f'Top 5 Features for {class_names[1]}')\n",
    "#plt.savefig('striatum_shap_new.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[2], X_test[feature_list], max_display=5, show=False, color_bar=True)\n",
    "plt.gcf().axes[-1].set_aspect(50)\n",
    "plt.gcf().axes[-1].set_box_aspect(50)\n",
    "plt.title(f'Top 5 Features for {class_names[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "\n",
    "for i in range(3): \n",
    "    figsize = (7.5, 5)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    # ax = fig.gca()\n",
    "    print(f'Plotting SHAP values for {le.classes_[i]}')\n",
    "    shap.summary_plot(shap_values[i], X_test[feature_list], max_display=10, title=f'SHAP Values for {le.classes_[i]}', color=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0,:], X_test[features].iloc[0,:], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train[features].columns:\n",
    "    print(name)\n",
    "    if 'Mean' in name:\n",
    "        shap.dependence_plot(ind=name, shap_values=shap_values[0], features=X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = explainer.shap_interaction_values(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(ind='Mean Deff2', shap_values=shap_values[2], features=X_test[features], interaction_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(ind='Mean AR', shap_values=shap_values[0], features=X_test[features], interaction_index='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot((\"Mean Deff1\", \"Mean D_fit\"), shap_interaction_values[0], X_test[features])#, interaction_index=\"Mean elongation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_predictor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
