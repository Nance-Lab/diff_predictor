{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_predictor import data_process, predxgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import operator\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from xgboost.training import CVPack\n",
    "from xgboost import callback\n",
    "from xgboost.core import CallbackEnv\n",
    "from xgboost.core import EarlyStopException\n",
    "from xgboost.core import STRING_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, len(data)+1) / len(data)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookDir = getcwd()\n",
    "\n",
    "print('Current Notebook Dir: ' + workbookDir)\n",
    "chdir(workbookDir) # Go to current workbook Dir\"\n",
    "chdir('..')        # Go up one\n",
    "print(f'Using current directory for loading data: {getcwd()}')\n",
    "workbookDir = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_feature_path = workbookDir + '/data/raw_data_age/'\n",
    "age_feature_filelist = [f for f in listdir(age_feature_path) if isfile(join(age_feature_path, f)) and 'feat' in f]\n",
    "print(len(age_feature_filelist))\n",
    "\n",
    "age_msd_path = workbookDir + '/raw_data_age/'\n",
    "age_msd_filelist = [f for f in listdir(age_msd_path) if isfile(join(age_msd_path, f)) and 'msd' in f]\n",
    "print(len(age_msd_filelist))\n",
    "\n",
    "region_dataset_path = workbookDir + '/data/region_feature_folder/'\n",
    "region_filelist = [f for f in listdir(region_dataset_path) if isfile(join(region_dataset_path, f)) and 'feat' in f]\n",
    "print(len(region_filelist))\n",
    "\n",
    "treatment_dataset_path = workbookDir + '/data/ecm_feature_folder/'\n",
    "treatment_filelist = [f for f in listdir(treatment_dataset_path) if isfile(join(treatment_dataset_path, f))]# and 'feat' in f]\n",
    "print(len(treatment_filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into Age Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_age = data_process.generate_fullstats(age_feature_path, age_feature_filelist, ['P14', 'P35', 'P70'], 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_age = pd.DataFrame()\n",
    "total_particles_count = 0\n",
    "subset_particles_count = 0\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "for i in range(len(age_feature_filelist)):\n",
    "    df_features = pd.read_csv(age_feature_path + age_feature_filelist[i])\n",
    "    file_name = age_feature_filelist[i]\n",
    "    targets = ['P14', 'P35', 'P70']\n",
    "    if any(substring in file_name for substring in targets):\n",
    "        file_indicator = file_name[8:] # grabs the unique part of the file name only\n",
    "        msd_filename = 'msd' + file_indicator\n",
    "        target = file_name[9:12]\n",
    "\n",
    "        features_df = pd.read_csv(age_feature_path + file_name)\n",
    "        msd_df = pd.read_csv(age_msd_path + msd_filename)\n",
    "\n",
    "\n",
    "        msd_df['Track_ID'] = msd_df['Track_ID'] + frame_counter\n",
    "        # Remove particles that are in frame less than one second\n",
    "        cutoff_df = msd_df[(msd_df['Frame'] == 16) & (msd_df['MSDs'].notna())]\n",
    "        msd_df = msd_df[msd_df['Track_ID'].isin(set(cutoff_df['Track_ID'].unique()))]\n",
    "        features_subset_df = features_df[features_df['Track_ID'].isin(set(msd_df['Track_ID'].unique()))]\n",
    "        features_df['age'] = pd.Series(features_df.shape[0]*[target], index=features_df.index)\n",
    "        \n",
    "        features_df['Track_ID'] = features_df['Track_ID'] + frame_counter\n",
    "        fstats_tot_age = fstats_tot_age.append(features_df)\n",
    "        total_particles_count += len(features_df)\n",
    "        subset_particles_count += len(features_subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    'alpha', # Fitted anomalous diffusion alpha exponenet\n",
    "    'D_fit', # Fitted anomalous diffusion coefficient\n",
    "    'kurtosis', # Kurtosis of track\n",
    "    'asymmetry1', # Asymmetry of trajecory (0 for circular symmetric, 1 for linear)\n",
    "    'asymmetry2', # Ratio of the smaller to larger principal radius of gyration\n",
    "    'asymmetry3', # An asymmetric feature that accnts for non-cylindrically symmetric pt distributions\n",
    "    'AR', # Aspect ratio of long and short side of trajectory's minimum bounding rectangle\n",
    "    'elongation', # Est. of amount of extension of trajectory from centroid\n",
    "    'boundedness', # How much a particle with Deff is restricted by a circular confinement of radius r\n",
    "    'fractal_dim', # Measure of how complicated a self similar figure is\n",
    "    'trappedness', # Probability that a particle with Deff is trapped in a region\n",
    "    'efficiency', # Ratio of squared net displacement to the sum of squared step lengths\n",
    "    'straightness', # Ratio of net displacement to the sum of squared step lengths\n",
    "    'MSD_ratio', # MSD ratio of the track\n",
    "#     'frames', # Number of frames the track spans\n",
    "    'Deff1', # Effective diffusion coefficient at 0.33 s\n",
    "    'Deff2', # Effective diffusion coefficient at 3.3 s\n",
    "    #'angle_mean', # Mean turning angle which is counterclockwise angle from one frame point to another\n",
    "    #'angle_mag_mean', # Magnitude of the turning angle mean\n",
    "    #'angle_var', # Variance of the turning angle\n",
    "    #'dist_tot', # Total distance of the trajectory\n",
    "    #'dist_net', # Net distance from first point to last point\n",
    "    #'progression', # Ratio of the net distance traveled and the total distance\n",
    "    'Mean alpha', \n",
    "    'Mean D_fit', \n",
    "    'Mean kurtosis', \n",
    "    'Mean asymmetry1', \n",
    "    'Mean asymmetry2',\n",
    "    'Mean asymmetry3', \n",
    "    'Mean AR',\n",
    "    'Mean elongation', \n",
    "    'Mean boundedness',\n",
    "    'Mean fractal_dim', \n",
    "    'Mean trappedness', \n",
    "    'Mean efficiency',\n",
    "    'Mean straightness', \n",
    "    'Mean MSD_ratio', \n",
    "    'Mean Deff1', \n",
    "    'Mean Deff2',\n",
    "    ]\n",
    "\n",
    "target = 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm = fstats_tot_age[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm[target].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here are the cutoffs for different motion types\n",
    "\n",
    "### alpha > 1.25: Directed Motion\n",
    "### 1.25 ≥ alpha ≥ 0.75: Normal Diffusion\n",
    "### 0.75 > alpha: Anomalous Diffusion/Confined Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, sharey=True, figsize=(8,6))\n",
    "#plt.ylim([0, 250])\n",
    "\n",
    "\n",
    "for i, unique_class in enumerate(ecm[target].unique()):\n",
    "    labels = ['superdiffusive', 'brownian', 'subdiffusive']\n",
    "    percentages = []\n",
    "    #bins=200\n",
    "    # print(f'class {unique_class}')\n",
    "    df = ecm[ecm[target] == unique_class]\n",
    "\n",
    "    directed_df = df[df['alpha'] > 1.1]\n",
    "    percentages.append(len(directed_df)/len(df))\n",
    "    # axes[i].hist(directed_df['alpha'], bins=bins)\n",
    "    # print(len(directed_df))\n",
    "    # print(f'directed diffusion %: {len(directed_df)/len(df)}')\n",
    "\n",
    "    normal_df = df[(df['alpha'] <= 1.1) & (df['alpha'] >= 0.9)]\n",
    "    percentages.append(len(normal_df)/len(df))\n",
    "    # axes[i].hist(normal_df['alpha'], bins=bins)\n",
    "    # print(len(normal_df))\n",
    "    # print(f'normal diffusion %: {len(normal_df)/len(df)}')\n",
    "\n",
    "    constrained_df = df[(df['alpha'] < 0.9) & (df['alpha'] > 0.1)]\n",
    "    percentages.append(len(constrained_df)/len(df))\n",
    "    # axes[i].hist(confined_df['alpha'], bins=bins)\n",
    "    # print(len(confined_df))\n",
    "    # print(f'confined diffusion %: {len(confined_df)/len(df)}')\n",
    "\n",
    "    #hindered_df = df[(df['alpha'] <= 0.5) & (df['alpha'] > 0.2)]\n",
    "    #percentages.append(len(hindered_df)/len(df))\n",
    "    # axes[i].hist(hindered_df['alpha'], bins=bins)\n",
    "    # print(f'hindered diffusion %: {len(hindered_df)/len(df)}')\n",
    "\n",
    "    immobilized_df = df[(df['alpha'] <= 0.1)]\n",
    "    percentages.append(len(immobilized_df)/len(df))\n",
    "    # axes[i].hist(immobilized_df['alpha'], bins='doane')\n",
    "    # print(f'immobilized diffusion %: {len(immobilized_df)/len(df)}')\n",
    "    # print('')\n",
    "    # axes[i].hist((df['alpha']), bins=40)\n",
    "    #axes[i].vlines(([0.2, 0.5, 0.75, 1.25]), ymin=0, ymax=400, color='r')\n",
    "    \n",
    "    axes[i].bar(np.arange(len(percentages)), percentages)\n",
    "    axes[i].set_xticklabels(labels)\n",
    "    axes[i].set_xticks(np.arange(len(percentages)))\n",
    "    axes[i].set_title(unique_class)\n",
    "\n",
    "    #break\n",
    "\n",
    "#for ax in axes:\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_xlim([-1,1.4])\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,8))\n",
    "\n",
    "\n",
    "labels = ecm[target].unique()\n",
    "labels.sort()\n",
    "\n",
    "directed_percent = np.zeros(len(labels))\n",
    "normal_percent = np.zeros(len(labels))\n",
    "constrained_percent = np.zeros(len(labels))\n",
    "immobilized_percent = np.zeros(len(labels))\n",
    "\n",
    "for i, unique_class in enumerate(labels):\n",
    "    print(unique_class)\n",
    "    df = ecm[ecm[target] == unique_class]\n",
    "\n",
    "    directed_df = df[df['alpha'] > 1.1]\n",
    "    directed_percent[i] = (len(directed_df)/len(df))\n",
    "    print(directed_percent[i])\n",
    "\n",
    "    normal_df = df[(df['alpha'] <= 1.1) & (df['alpha'] >= 0.9)]\n",
    "    normal_percent[i] = (len(normal_df)/len(df))\n",
    "    print(normal_percent[i])\n",
    "    \n",
    "    constrained_df = df[(df['alpha'] < 0.9)]\n",
    "    constrained_percent[i] = (len(constrained_df)/len(df))\n",
    "    print(constrained_percent[i])\n",
    "    print()\n",
    "    \n",
    "    #immobilized_df = df[(df['alpha'] <= 0.1)]\n",
    "    #immobilized_percent[i] = (len(immobilized_df)/len(df))\n",
    "    \n",
    "    \n",
    "#plt.bar(labels, immobilized_percent, color='r', label='immobilized')\n",
    "bar_w = 0.5\n",
    "plt.bar(labels, constrained_percent, label='Subdiffusive', width=bar_w, color='#b7a57a')\n",
    "plt.bar(labels, normal_percent, bottom=constrained_percent+immobilized_percent, color='#999999', label='Brownian', width=bar_w)\n",
    "plt.bar(labels, directed_percent, bottom=constrained_percent+immobilized_percent+normal_percent, color='#4b2e83', label='Superdiffusive', width=bar_w)\n",
    "plt.ylim([0,1])\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.title('Percentage of Diffusion Modes per Age', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.yticks(fontsize=15, fontname='Arial', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = np.array(p70_ecm['alpha'])\n",
    "x = np.sort(mx)\n",
    "y = np.arange(1, len(mx)+1) / len(mx)\n",
    "x, y = ecdf(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "bin_num = 500\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].hist(np.array(p14_ecm['alpha']), bins=bin_num)\n",
    "ax[1].hist(np.array(p35_ecm['alpha']), bins=bin_num)\n",
    "ax[2].hist(np.array(p70_ecm['alpha']), bins=bin_num)\n",
    "#plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "for df in age_df_list:\n",
    "    mx = np.array(df['alpha'])\n",
    "    x = np.sort(mx)\n",
    "    y = np.arange(1, len(mx)+1) / len(mx)\n",
    "    plt.scatter(x, y, alpha=0.7, s=1, label=df['age'].unique()[0])\n",
    "plt.vlines([directed], 0, 1, label='normal diffusion cutoff', linestyles='dashed')\n",
    "plt.vlines(confined, 0, 1, label='confined diffusion cutoff', linestyles='dotted')\n",
    "plt.xlim([0,3])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confined_ecm = ecm[ecm['alpha'] < 0.75]\n",
    "# normal_ecm = ecm[(ecm['alpha'] >= 0.75) & (ecm['alpha'] <= 1.25)]\n",
    "# directed_ecm = ecm[ecm['alpha'] > 1.25]\n",
    "\n",
    "# directed_normal_ecm = ecm[ecm['alpha'] >= 0.75]\n",
    "# directed_confined_ecm = ecm[(ecm['alpha'] > 1.25) | (ecm['alpha'] < 0.75)]\n",
    "# normal_confined_ecm = ecm[ecm['alpha'] <= 1.25]\n",
    "\n",
    "# no_immobil = ecm[ecm['alpha'] > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preprocess(ecm, balanced=True, target=None):\n",
    "\n",
    "    rand_state = np.random.randint(1, 2000)\n",
    "    if balanced:\n",
    "        bal_ecm = data_process.balance_data(ecm, target, random_state=rand_state)\n",
    "        #sampled_df = bal_ecm.sample(frac=0.5)\n",
    "        sampled_df = data_process.bin_data(bal_ecm)\n",
    "    else:\n",
    "        sampled_df = data_process.bin_data(ecm)\n",
    "    label_df = sampled_df[target]\n",
    "    features_df = sampled_df.drop([target, 'X', 'Y', 'binx', 'biny', 'bins', 'Track_ID'], axis=1)\n",
    "    features = features_df.columns\n",
    "\n",
    "    seed = rand_state\n",
    "    np.random.seed(seed)\n",
    "    train_split = 0.8\n",
    "    test_split = 0.5\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    sampled_df['encoded_target'] = le.fit_transform(sampled_df[target])\n",
    "\n",
    "    training_bins = np.random.choice(sampled_df['bins'].unique(), int(len(sampled_df['bins'].unique())*train_split), replace=False)\n",
    "\n",
    "    X_train = sampled_df[sampled_df['bins'].isin(training_bins)]\n",
    "    X_test_val = sampled_df[~sampled_df['bins'].isin(training_bins)]\n",
    "    X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "    y_train = X_train['encoded_target']\n",
    "    y_test = X_test['encoded_target']\n",
    "    y_val = X_val['encoded_target']\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "    dval = xgb.DMatrix(X_val[features], label=y_val)\n",
    "    return dtrain, dtest, dval, X_train, X_test, y_train, y_test, le\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 3,\n",
    "         'eta': 0.005,\n",
    "         'min_child_weight': 0,\n",
    "         'verbosity': 0,\n",
    "         'objective': 'multi:softprob',\n",
    "         'num_class': 3,\n",
    "         'silent': 'True',\n",
    "         'gamma': 5,\n",
    "         'subsample': 0.15,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'eval_metric': \"mlogloss\",\n",
    "#          # GPU integration will cut time in ~half:\n",
    "#          'gpu_id' : 0,\n",
    "#          'tree_method': 'gpu_hist',\n",
    "#          'predictor': 'gpu_predictor'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confined_ecm = ecm[(ecm['alpha'] < 0.9) & (ecm['alpha'] > 0.1)]\n",
    "normal_ecm = ecm[(ecm['alpha'] >= 0.9) & (ecm['alpha'] <= 1.1)]\n",
    "directed_ecm = ecm[ecm['alpha'] > 1.1]\n",
    "\n",
    "#hindered_ecm = ecm[(ecm['alpha'] > 0.2) & (ecm['alpha'] <= 0.5)]\n",
    "#immobilized_ecm = ecm[ecm['alpha'] <= 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 4, 'eta': 0.1, 'min_child_weight': 1, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 3, 'silent': 'True', 'gamma': 1.0, 'subsample': 0.5, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'age'\n",
    "\n",
    "normal_acc_list = []\n",
    "confined_acc_list = []\n",
    "directed_acc_list = []\n",
    "all_acc_list = []\n",
    "#hindered_acc_list = []\n",
    "#immobilized_acc_list = []\n",
    "#no_imm_acc = []\n",
    "\n",
    "normal_shap_list = []\n",
    "confined_shap_list = []\n",
    "directed_shap_list = []\n",
    "all_shap_list = []\n",
    "#immobilized_shap_list = []\n",
    "\n",
    "def myfun(self=None):\n",
    "    return model_bytearray\n",
    "    \n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    # dtrain, dtest, dval, X_train, X_test, y_train, y_test = full_preprocess(normal_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # normal_acc_list.append(acc)\n",
    "    #model_bytearray = booster.save_raw()[4:]\n",
    "    #booster.save_raw = myfun\n",
    "    #explainer = shap.TreeExplainer(booster)\n",
    "    #shap_values = explainer.shap_values(X_test[features])\n",
    "    #normal_shap_list.append(shap_values)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(directed_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=76, verbose=False)\n",
    "    directed_acc_list.append(acc)\n",
    "    #model_bytearray = booster.save_raw()[4:]\n",
    "    #booster.save_raw = myfun\n",
    "    # explainer = shap.TreeExplainer(booster)\n",
    "    # shap_values = explainer.shap_values(X_test[features])\n",
    "    # directed_shap_list.append(shap_values)\n",
    "    \n",
    "\n",
    "    # dtrain, dtest, dval, X_train, X_test, y_train, y_test = full_preprocess(confined_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # confined_acc_list.append(acc)\n",
    "    # model_bytearray = booster.save_raw()[4:]\n",
    "    # booster.save_raw = myfun\n",
    "    # explainer = shap.TreeExplainer(booster)\n",
    "    # shap_values = explainer.shap_values(X_test[features])\n",
    "    # confined_shap_list.append(shap_values)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param_all, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    all_acc_list.append(acc)\n",
    "    # model_bytearray = booster.save_raw()[4:]\n",
    "    # booster.save_raw = myfun\n",
    "    # explainer = shap.TreeExplainer(booster)\n",
    "    # shap_values = explainer.shap_values(X_test[features])\n",
    "    # all_shap_list.append(shap_values)\n",
    "\n",
    "    # dtrain, dtest, dval, y_test= full_preprocess(hindered_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # hindered_acc_list.append(acc)\n",
    "\n",
    "    # dtrain, dtest, dval, X_train, X_test, y_train, y_test = full_preprocess(immobilized_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # immobilized_acc_list.append(acc)\n",
    "    # # model_bytearray = booster.save_raw()[4:]\n",
    "    # # booster.save_raw = myfun\n",
    "    # explainer = shap.TreeExplainer(booster)\n",
    "    # shap_values = explainer.shap_values(X_test[features])\n",
    "    # immobilized_shap_list.append(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_dict = {#'confined_acc': np.array(confined_acc_list),\n",
    "                  'directed_acc': np.array(directed_acc_list),\n",
    "                  #'normal_acc': np.array(normal_acc_list),\n",
    "                  #'hindered_acc': np.array(hindered_acc_list),\n",
    "                  #'immobilized_acc': np.array(immobilized_acc_list),\n",
    "                  'all_modes_acc': np.array(all_acc_list)\n",
    "                    }\n",
    "age_result_df = pd.DataFrame.from_dict(age_dict)\n",
    "age_result_df.to_csv('age_accuracies_v5.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_result_df = pd.read_csv('age_accuracies_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "conf_x, conf_y = ecdf(np.array(age_result_df['confined_acc']))\n",
    "dir_x, dir_y = ecdf(np.array(age_result_df['directed_acc']))\n",
    "norm_x, norm_y = ecdf(np.array(age_result_df['normal_acc']))\n",
    "all_x, all_y = ecdf(np.array(age_result_df['all_modes_acc']))\n",
    "#hind_x, hind_y = ecdf(np.array(hindered_acc_list))\n",
    "#imm_x, imm_y = ecdf(np.array(immobilized_acc_list))\n",
    "#no_imm_x, no_imm_y = ecdf(np.array(no_imm_acc))\n",
    "plt.scatter(dir_x, dir_y, label='Superdiffusive', s=7, c='#4b2e83')\n",
    "plt.scatter(conf_x, conf_y, label='Subdiffusive', s=7, c='#b7a57a')\n",
    "plt.scatter(norm_x, norm_y, label='Brownian', s=7, c='#999999')\n",
    "plt.plot(all_x, all_y, label='All modes', c='k')\n",
    "#plt.scatter(hind_x, hind_y, label='hindered', s=2)\n",
    "#plt.scatter(imm_x, imm_y, label='immobilized', s=2)\n",
    "#plt.scatter(no_imm_x, no_imm_y, label='no immobilized points', s=0.5)\n",
    "plt.legend(loc='upper left', markerscale=2.0, fontsize=14)\n",
    "plt.xlabel('Model Accuracy', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.ylabel('Percentage %', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.xlim([0.8, 0.9])\n",
    "plt.xticks(fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.yticks(fontsize=15, fontname='Arial', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "conf_x, conf_y = ecdf(np.array(confined_acc_list))\n",
    "dir_x, dir_y = ecdf(np.array(directed_acc_list))\n",
    "norm_x, norm_y = ecdf(np.array(normal_acc_list))\n",
    "all_x, all_y = ecdf(np.array(all_acc_list))\n",
    "#hind_x, hind_y = ecdf(np.array(hindered_acc_list))\n",
    "#imm_x, imm_y = ecdf(np.array(immobilized_acc_list))\n",
    "#no_imm_x, no_imm_y = ecdf(np.array(no_imm_acc))\n",
    "plt.scatter(dir_x, dir_y, label='Superdiffusive', s=2)\n",
    "plt.scatter(conf_x, conf_y, label='Subdiffusive', s=2)\n",
    "plt.scatter(norm_x, norm_y, label='Brownian', s=2)\n",
    "plt.scatter(all_x, all_y, label='All modes', s=2)\n",
    "#plt.scatter(hind_x, hind_y, label='hindered', s=2)\n",
    "#plt.scatter(imm_x, imm_y, label='immobilized', s=2)\n",
    "#plt.scatter(no_imm_x, no_imm_y, label='no immobilized points', s=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Model Accuracy')\n",
    "plt.ylabel('Percentage %')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes')\n",
    "plt.xlim([0.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dir_x, dir_y, label='directed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_acc_list = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, y_test= full_preprocess(directed_ecm, balanced=True)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    directed_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc_list = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, y_test= full_preprocess(ecm, balanced=True)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    all_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_acc_list = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, y_test= full_preprocess(normal_ecm, balanced=True)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    normal_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_ecm[target].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, target=target)\n",
    "(best_model, best_param, best_eval, best_boost_rounds) = predxgboost.xgb_paramsearch(X_train=X_train, y_train=X_train['encoded_target'], features=features, init_params=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_param)\n",
    "print(best_boost_rounds)\n",
    "print(best_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_param)\n",
    "print(best_boost_rounds)\n",
    "print(best_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_all = {'max_depth': 4, 'eta': 0.1, 'min_child_weight': 1, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 3, 'silent': 'True', 'gamma': 1.0, 'subsample': 0.5, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_param)\n",
    "print(best_boost_rounds)\n",
    "print(best_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_acc_list = []\n",
    "all_acc_list = []\n",
    "for i in range(100):\n",
    "\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, X_train, y_test= full_preprocess(ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=False)\n",
    "    all_acc_list.append(acc)\n",
    "\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, X_train, y_test= full_preprocess(directed_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=False)\n",
    "    directed_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "dir_x, dir_y = ecdf(np.array(directed_acc_list))\n",
    "\n",
    "no_imm_x, no_imm_y = ecdf(np.array(all_acc_list))\n",
    "plt.scatter(dir_x, dir_y, label='directed', s=2)\n",
    "#plt.hist(dir_x, bins=100)\n",
    "plt.scatter(no_imm_x, no_imm_y, label='all', s=0.5)\n",
    "#plt.hist(no_imm_x, bins=100)\n",
    "plt.legend()\n",
    "plt.xlabel('Model Accuracy')\n",
    "plt.ylabel('Percentage %')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into region data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_region = data_process.generate_fullstats(region_dataset_path, region_filelist, ['cortex', 'hippocampus', 'striatum'], 'region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'region'\n",
    "ecm = fstats_tot_region[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,8))\n",
    "\n",
    "\n",
    "labels = ecm[target].unique()\n",
    "labels.sort()\n",
    "\n",
    "directed_percent = np.zeros(len(labels))\n",
    "normal_percent = np.zeros(len(labels))\n",
    "constrained_percent = np.zeros(len(labels))\n",
    "immobilized_percent = np.zeros(len(labels))\n",
    "\n",
    "for i, unique_class in enumerate(labels):\n",
    "    \n",
    "    print(unique_class)\n",
    "    df = ecm[ecm[target] == unique_class]\n",
    "\n",
    "    directed_df = df[df['alpha'] > 1.1]\n",
    "    directed_percent[i] = (len(directed_df)/len(df))\n",
    "    print(directed_percent[i])\n",
    "\n",
    "    normal_df = df[(df['alpha'] <= 1.1) & (df['alpha'] >= 0.9)]\n",
    "    normal_percent[i] = (len(normal_df)/len(df))\n",
    "    print(normal_percent[i])\n",
    "    \n",
    "    constrained_df = df[(df['alpha'] < 0.9)]\n",
    "    constrained_percent[i] = (len(constrained_df)/len(df))\n",
    "    print(constrained_percent[i])\n",
    "    print()\n",
    "    \n",
    "    #immobilized_df = df[(df['alpha'] <= 0.1)]\n",
    "    #immobilized_percent[i] = (len(immobilized_df)/len(df))\n",
    "    \n",
    "    \n",
    "#plt.bar(labels, immobilized_percent, color='r', label='immobilized')\n",
    "bar_w = 0.5\n",
    "plt.bar(labels, constrained_percent, color='#b7a57a', label='Subdiffusive', width=bar_w)\n",
    "plt.bar(labels, normal_percent, bottom=constrained_percent+immobilized_percent, color='#999999', label='Brownian', width=bar_w)\n",
    "plt.bar(labels, directed_percent, bottom=constrained_percent+immobilized_percent+normal_percent, color='#4b2e83', label='Superdiffusive', width=bar_w)\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(rotation='45')\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.title('Percentage of Diffusion Modes per Region', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.yticks(fontsize=15, fontname='Arial', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hippo_ecm = ecm[ecm[target] == 'hippocampus']\n",
    "print(len(hippo_ecm))\n",
    "thala_ecm = ecm[ecm[target] == 'thalamus']\n",
    "print(len(thala_ecm))\n",
    "gangl_ecm = ecm[ecm[target] == 'ganglia']\n",
    "print(len(gangl_ecm))\n",
    "\n",
    "cortex_ecm = ecm[ecm[target] == 'cortex']\n",
    "print(len(cortex_ecm))\n",
    "\n",
    "striat_ecm = ecm[ecm[target] == 'striatum']\n",
    "print(len(striat_ecm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age_df_list = [hippo_ecm, thala_ecm, gangl_ecm, cortex_ecm, striat_ecm]\n",
    "fig, axes = plt.subplots(1,len(ecm[target].unique()), sharey=True, figsize=(8,6))\n",
    "#plt.ylim([0, 250])\n",
    "\n",
    "\n",
    "for i, unique_class in enumerate(ecm[target].unique()):\n",
    "    labels = ['directed', 'normal', 'confined', 'hindered', 'immobilized']\n",
    "    percentages = []\n",
    "    #bins=200\n",
    "    # print(f'class {unique_class}')\n",
    "    df = ecm[ecm[target] == unique_class]\n",
    "\n",
    "    directed_df = df[df['alpha'] > 1.25]\n",
    "    percentages.append(len(directed_df)/len(df))\n",
    "    # axes[i].hist(directed_df['alpha'], bins=bins)\n",
    "    # print(len(directed_df))\n",
    "    # print(f'directed diffusion %: {len(directed_df)/len(df)}')\n",
    "\n",
    "    normal_df = df[(df['alpha'] <= 1.25) & (df['alpha'] >= 0.75)]\n",
    "    percentages.append(len(normal_df)/len(df))\n",
    "    # axes[i].hist(normal_df['alpha'], bins=bins)\n",
    "    # print(len(normal_df))\n",
    "    # print(f'normal diffusion %: {len(normal_df)/len(df)}')\n",
    "\n",
    "    confined_df = df[(df['alpha'] < 0.75) & (df['alpha'] > 0.5)]\n",
    "    percentages.append(len(confined_df)/len(df))\n",
    "    # axes[i].hist(confined_df['alpha'], bins=bins)\n",
    "    # print(len(confined_df))\n",
    "    # print(f'confined diffusion %: {len(confined_df)/len(df)}')\n",
    "\n",
    "    hindered_df = df[(df['alpha'] <= 0.5) & (df['alpha'] > 0.2)]\n",
    "    percentages.append(len(hindered_df)/len(df))\n",
    "    # axes[i].hist(hindered_df['alpha'], bins=bins)\n",
    "    # print(f'hindered diffusion %: {len(hindered_df)/len(df)}')\n",
    "\n",
    "    immobilized_df = df[(df['alpha'] <= 0.2)]\n",
    "    percentages.append(len(immobilized_df)/len(df))\n",
    "    # axes[i].hist(immobilized_df['alpha'], bins='doane')\n",
    "    # print(f'immobilized diffusion %: {len(immobilized_df)/len(df)}')\n",
    "    # print('')\n",
    "    # axes[i].hist((df['alpha']), bins=40)\n",
    "    #axes[i].vlines(([0.2, 0.5, 0.75, 1.25]), ymin=0, ymax=400, color='r')\n",
    "    \n",
    "    axes[i].bar(np.arange(len(percentages)), percentages)\n",
    "    axes[i].set_xticklabels(labels)\n",
    "    axes[i].set_xticks(np.arange(len(percentages)))\n",
    "    axes[i].set_title(unique_class)\n",
    "\n",
    "    #break\n",
    "\n",
    "#for ax in axes:\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_xlim([-1,1.4])\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confined_ecm = ecm[(ecm['alpha'] < 0.9)]\n",
    "normal_ecm = ecm[(ecm['alpha'] >= 0.9) & (ecm['alpha'] <= 1.1)]\n",
    "directed_ecm = ecm[ecm['alpha'] > 1.1]\n",
    "\n",
    "#hindered_ecm = ecm[(ecm['alpha'] > 0.2) & (ecm['alpha'] <= 0.5)]\n",
    "#immobilized_ecm = ecm[ecm['alpha'] <= 0.1]\n",
    "\n",
    "#best_ecm = ecm[(ecm['alpha'] > 1.25) | (ecm['alpha'] <= 0.2)]\n",
    "#len(best_ecm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'region'\n",
    "\n",
    "normal_acc_list = []\n",
    "confined_acc_list = []\n",
    "directed_acc_list = []\n",
    "all_acc_list = []\n",
    "#hindered_acc_list = []\n",
    "immobilized_acc_list = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(normal_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    normal_acc_list.append(acc)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(directed_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    directed_acc_list.append(acc)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(confined_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    confined_acc_list.append(acc)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    all_acc_list.append(acc)\n",
    "\n",
    "    # dtrain, dtest, dval, X_train, y_test = full_preprocess(hindered_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # hindered_acc_list.append(acc)\n",
    "\n",
    "    # dtrain, dtest, dval, X_train, y_test = full_preprocess(immobilized_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # immobilized_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'region'\n",
    "dir_ecm_acc = []\n",
    "all_acc_list = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, X_train, y_test= full_preprocess(directed_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    dir_ecm_acc.append(acc)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, y_test= full_preprocess(ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param_all, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    all_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "#conf_x, conf_y = ecdf(np.array(confined_acc_list))\n",
    "dir_x, dir_y = ecdf(np.array(directed_acc_list))\n",
    "#norm_x, norm_y = ecdf(np.array(normal_acc_list))\n",
    "all_x, all_y = ecdf(np.array(all_acc_list))\n",
    "#hind_x, hind_y = ecdf(np.array(hindered_acc_list))\n",
    "#imm_x, imm_y = ecdf(np.array(immobilized_acc_list))\n",
    "#best_x, best_y = ecdf(np.array(best_ecm_acc))\n",
    "#no_norm_x, no_norm_y = ecdf(np.array(no_normal_acc))\n",
    "plt.scatter(dir_x, dir_y, label='Superdiffusive', s=2)\n",
    "#plt.scatter(conf_x, conf_y, label='Subdiffusive', s=2)\n",
    "#plt.scatter(norm_x, norm_y, label='Brownian', s=2)\n",
    "plt.plot(all_x, all_y, label='all modes', c='r')\n",
    "#plt.scatter(hind_x, hind_y, label='hindered', s=2)\n",
    "#plt.scatter(imm_x, imm_y, label='immobilized', s=2)\n",
    "#plt.scatter(no_norm_x, no_norm_y, label='no normal points', s=0.5)\n",
    "#plt.scatter(best_x, best_y, label='top two', s=2)\n",
    "plt.legend()\n",
    "plt.xlabel('Model Accuracy')\n",
    "plt.ylabel('Percentage %')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes')\n",
    "plt.xlim([0.85, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "conf_x, conf_y = ecdf(np.array(region_result_df['confined_acc']))\n",
    "dir_x, dir_y = ecdf(np.array(region_result_df['directed_acc']))\n",
    "norm_x, norm_y = ecdf(np.array(region_result_df['normal_acc']))\n",
    "all_x, all_y = ecdf(np.array(region_result_df['all_modes_acc']))\n",
    "#hind_x, hind_y = ecdf(np.array(hindered_acc_list))\n",
    "#imm_x, imm_y = ecdf(np.array(immobilized_acc_list))\n",
    "#no_imm_x, no_imm_y = ecdf(np.array(no_imm_acc))\n",
    "plt.scatter(dir_x, dir_y, label='Superdiffusive', s=7, c='#4b2e83')\n",
    "plt.scatter(conf_x, conf_y, label='Subdiffusive', s=7, c='#b7a57a')\n",
    "plt.scatter(norm_x, norm_y, label='Brownian', s=7, c='#999999')\n",
    "plt.plot(all_x, all_y, label='All modes', c='k')\n",
    "#plt.scatter(hind_x, hind_y, label='hindered', s=2)\n",
    "#plt.scatter(imm_x, imm_y, label='immobilized', s=2)\n",
    "#plt.scatter(no_imm_x, no_imm_y, label='no immobilized points', s=0.5)\n",
    "plt.legend(loc='upper left', markerscale=2.0, fontsize=14)\n",
    "plt.xlabel('Model Accuracy', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.ylabel('Percentage %', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.xticks(fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.yticks(fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.xlim([0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = {'confined_acc': np.array(confined_acc_list),\n",
    "                  'directed_acc': np.array(directed_acc_list),\n",
    "                  'normal_acc': np.array(normal_acc_list),\n",
    "                  #'hindered_acc': np.array(hindered_acc_list),\n",
    "                  #'immobilized_acc': np.array(immobilized_acc_list),\n",
    "                  'all_modes_acc': np.array(all_acc_list)\n",
    "                    }\n",
    "region_result_df = pd.DataFrame.from_dict(region_dict)\n",
    "region_result_df.to_csv('region_accuracies_V3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_result_df = pd.read_csv('region_accuracies_V2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 3,\n",
    "         'eta': 0.005,\n",
    "         'min_child_weight': 0,\n",
    "         'verbosity': 0,\n",
    "         'objective': 'multi:softprob',\n",
    "         'num_class': 5,\n",
    "         'silent': 'True',\n",
    "         'gamma': 5,\n",
    "         'subsample': 0.15,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'eval_metric': \"mlogloss\",\n",
    "#          # GPU integration will cut time in ~half:\n",
    "#          'gpu_id' : 0,\n",
    "#          'tree_method': 'gpu_hist',\n",
    "#          'predictor': 'gpu_predictor'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(directed_ecm, target=target)\n",
    "(best_model, best_param, best_eval, best_boost_rounds) = predxgboost.xgb_paramsearch(X_train=X_train, y_train=X_train['encoded_target'], features=features, init_params=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_all_ = {'max_depth': 4,\n",
    " 'eta': 0.005,\n",
    " 'min_child_weight': 0,\n",
    " 'verbosity': 0,\n",
    " 'objective': 'multi:softprob',\n",
    " 'num_class': 5,\n",
    " 'silent': 'True',\n",
    " 'gamma': 5,\n",
    " 'subsample': 0.6,\n",
    " 'colsample_bytree': 0.7,\n",
    " 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into treatment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_treatment = data_process.generate_fullstats(treatment_dataset_path, treatment_filelist, ['NT', 'ChABC'], 'treatment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'treatment'\n",
    "ecm = fstats_tot_treatment[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,8))\n",
    "\n",
    "\n",
    "labels = ecm[target].unique()\n",
    "\n",
    "directed_percent = np.zeros(len(labels))\n",
    "normal_percent = np.zeros(len(labels))\n",
    "constrained_percent = np.zeros(len(labels))\n",
    "immobilized_percent = np.zeros(len(labels))\n",
    "\n",
    "for i, unique_class in enumerate(ecm[target].unique()):\n",
    "    \n",
    "    print(unique_class)\n",
    "    df = ecm[ecm[target] == unique_class]\n",
    "\n",
    "    directed_df = df[df['alpha'] > 1.1]\n",
    "    directed_percent[i] = (len(directed_df)/len(df))\n",
    "    print(directed_percent[i])\n",
    "\n",
    "    normal_df = df[(df['alpha'] <= 1.1) & (df['alpha'] >= 0.9)]\n",
    "    normal_percent[i] = (len(normal_df)/len(df))\n",
    "    print(normal_percent[i])\n",
    "    \n",
    "    constrained_df = df[(df['alpha'] < 0.9)]\n",
    "    constrained_percent[i] = (len(constrained_df)/len(df))\n",
    "    print(constrained_percent[i])\n",
    "    print()\n",
    "    \n",
    "    #immobilized_df = df[(df['alpha'] <= 0.1)]\n",
    "    #immobilized_percent[i] = (len(immobilized_df)/len(df))\n",
    "    \n",
    "    \n",
    "#plt.bar(labels, immobilized_percent, color='r', label='immobilized')\n",
    "bar_w = 0.5\n",
    "plt.bar(labels, constrained_percent, color='#b7a57a', label='Subdiffusive', width=bar_w)\n",
    "plt.bar(labels, normal_percent, bottom=constrained_percent+immobilized_percent, color='#999999', label='Brownian', width=bar_w)\n",
    "plt.bar(labels, directed_percent, bottom=constrained_percent+immobilized_percent+normal_percent, color='#4b2e83', label='Superdiffusive', width=bar_w)\n",
    "plt.ylim([0,1])\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.title('Percentage of Diffusion Modes per Treatment Group', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.yticks(fontsize=15, fontname='Arial', fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age_df_list = [hippo_ecm, thala_ecm, gangl_ecm, cortex_ecm, striat_ecm]\n",
    "fig, axes = plt.subplots(1,len(ecm[target].unique()), sharey=True, figsize=(8,6))\n",
    "#plt.ylim([0, 250])\n",
    "\n",
    "\n",
    "for i, unique_class in enumerate(ecm[target].unique()):\n",
    "    labels = ['directed', 'normal', 'confined', 'hindered', 'immobilized']\n",
    "    percentages = []\n",
    "    #bins=200\n",
    "    # print(f'class {unique_class}')\n",
    "    df = ecm[ecm[target] == unique_class]\n",
    "\n",
    "    directed_df = df[df['alpha'] > 1.25]\n",
    "    percentages.append(len(directed_df)/len(df))\n",
    "    # axes[i].hist(directed_df['alpha'], bins=bins)\n",
    "    # print(len(directed_df))\n",
    "    # print(f'directed diffusion %: {len(directed_df)/len(df)}')\n",
    "\n",
    "    normal_df = df[(df['alpha'] <= 1.25) & (df['alpha'] >= 0.75)]\n",
    "    percentages.append(len(normal_df)/len(df))\n",
    "    # axes[i].hist(normal_df['alpha'], bins=bins)\n",
    "    # print(len(normal_df))\n",
    "    # print(f'normal diffusion %: {len(normal_df)/len(df)}')\n",
    "\n",
    "    confined_df = df[(df['alpha'] < 0.75) & (df['alpha'] > 0.5)]\n",
    "    percentages.append(len(confined_df)/len(df))\n",
    "    # axes[i].hist(confined_df['alpha'], bins=bins)\n",
    "    # print(len(confined_df))\n",
    "    # print(f'confined diffusion %: {len(confined_df)/len(df)}')\n",
    "\n",
    "    hindered_df = df[(df['alpha'] <= 0.5) & (df['alpha'] > 0.2)]\n",
    "    percentages.append(len(hindered_df)/len(df))\n",
    "    # axes[i].hist(hindered_df['alpha'], bins=bins)\n",
    "    # print(f'hindered diffusion %: {len(hindered_df)/len(df)}')\n",
    "\n",
    "    immobilized_df = df[(df['alpha'] <= 0.2)]\n",
    "    percentages.append(len(immobilized_df)/len(df))\n",
    "    # axes[i].hist(immobilized_df['alpha'], bins='doane')\n",
    "    # print(f'immobilized diffusion %: {len(immobilized_df)/len(df)}')\n",
    "    # print('')\n",
    "    # axes[i].hist((df['alpha']), bins=40)\n",
    "    #axes[i].vlines(([0.2, 0.5, 0.75, 1.25]), ymin=0, ymax=400, color='r')\n",
    "    \n",
    "    axes[i].bar(np.arange(len(percentages)), percentages)\n",
    "    axes[i].set_xticklabels(labels)\n",
    "    axes[i].set_xticks(np.arange(len(percentages)))\n",
    "    axes[i].set_title(unique_class)\n",
    "\n",
    "    #break\n",
    "\n",
    "#for ax in axes:\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_xlim([-1,1.4])\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confined_ecm = ecm[(ecm['alpha'] < 0.9)]\n",
    "normal_ecm = ecm[(ecm['alpha'] >= 0.9) & (ecm['alpha'] <= 1.1)]\n",
    "directed_ecm = ecm[ecm['alpha'] > 1.1]\n",
    "\n",
    "#hindered_ecm = ecm[(ecm['alpha'] > 0.2) & (ecm['alpha'] <= 0.5)]\n",
    "#immobilized_ecm = ecm[ecm['alpha'] <= 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'treatment'\n",
    "\n",
    "normal_acc_list = []\n",
    "confined_acc_list = []\n",
    "directed_acc_list = []\n",
    "all_acc_list = []\n",
    "#hindered_acc_list = []\n",
    "#immobilized_acc_list = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(normal_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    normal_acc_list.append(acc)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(directed_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    directed_acc_list.append(acc)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(confined_ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    confined_acc_list.append(acc)\n",
    "\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    all_acc_list.append(acc)\n",
    "\n",
    "    # dtrain, dtest, dval, y_test= full_preprocess(hindered_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # hindered_acc_list.append(acc)\n",
    "\n",
    "    # dtrain, dtest, dval, x_train, y_test= full_preprocess(immobilized_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=200, verbose=False)\n",
    "    # immobilized_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "conf_x, conf_y = ecdf(np.array(confined_acc_list))\n",
    "dir_x, dir_y = ecdf(np.array(directed_acc_list))\n",
    "norm_x, norm_y = ecdf(np.array(normal_acc_list))\n",
    "all_x, all_y = ecdf(np.array(all_acc_list))\n",
    "#hind_x, hind_y = ecdf(np.array(hindered_acc_list))\n",
    "#imm_x, imm_y = ecdf(np.array(immobilized_acc_list))\n",
    "plt.scatter(dir_x, dir_y, label='Superdiffusive', s=2)\n",
    "plt.scatter(conf_x, conf_y, label='Subdiffusive', s=2)\n",
    "plt.scatter(norm_x, norm_y, label='Brownian', s=2)\n",
    "plt.plot(all_x, all_y, label='All modes', c='r')\n",
    "#plt.scatter(hind_x, hind_y, label='hindered', s=2)\n",
    "#plt.scatter(imm_x, imm_y, label='immobilized', s=2)\n",
    "plt.legend()\n",
    "plt.xlabel('Model Accuracy')\n",
    "plt.ylabel('Percentage %')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes')\n",
    "plt.xlim([.65, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_dict = {'confined_acc': np.array(confined_acc_list),\n",
    "                  'directed_acc': np.array(directed_acc_list),\n",
    "                  'normal_acc': np.array(normal_acc_list),\n",
    "                  #'hindered_acc': np.array(hindered_acc_list),\n",
    "                  #'#immobilized_acc': np.array(immobilized_acc_list),\n",
    "                  'all_modes_acc': np.array(all_acc_list)\n",
    "                    }\n",
    "treatment_result_df = pd.DataFrame.from_dict(treatment_dict)\n",
    "treatment_result_df.to_csv('treatment_accuracies_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_result_df = pd.read_csv('treatment_accuracies_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "conf_x, conf_y = ecdf(np.array(treatment_result_df['confined_acc']))\n",
    "dir_x, dir_y = ecdf(np.array(treatment_result_df['directed_acc']))\n",
    "norm_x, norm_y = ecdf(np.array(treatment_result_df['normal_acc']))\n",
    "all_x, all_y = ecdf(np.array(treatment_result_df['all_modes_acc']))\n",
    "#hind_x, hind_y = ecdf(np.array(hindered_acc_list))\n",
    "#imm_x, imm_y = ecdf(np.array(immobilized_acc_list))\n",
    "#no_imm_x, no_imm_y = ecdf(np.array(no_imm_acc))\n",
    "plt.scatter(dir_x, dir_y, label='Superdiffusive', s=7, c='#4b2e83')\n",
    "plt.scatter(conf_x, conf_y, label='Subdiffusive', s=7, c='#b7a57a')\n",
    "plt.scatter(norm_x, norm_y, label='Brownian', s=7, c='#999999')\n",
    "plt.plot(all_x, all_y, label='All modes', c='k')\n",
    "#plt.scatter(hind_x, hind_y, label='hindered', s=2)\n",
    "#plt.scatter(imm_x, imm_y, label='immobilized', s=2)\n",
    "#plt.scatter(no_imm_x, no_imm_y, label='no immobilized points', s=0.5)\n",
    "plt.xlim([0.65, 0.75])\n",
    "plt.legend(loc='upper left', markerscale=2.0, fontsize=14)\n",
    "plt.xlabel('Model Accuracy', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.ylabel('Percentage %', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes', fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.xticks(fontsize=15, fontname='Arial', fontweight='bold')\n",
    "plt.yticks(fontsize=15, fontname='Arial', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 3,\n",
    "         'eta': 0.005,\n",
    "         'min_child_weight': 0,\n",
    "         'verbosity': 0,\n",
    "         'objective': 'binary:hinge',\n",
    "         #'num_class': 2,\n",
    "         'silent': 'True',\n",
    "         'gamma': 5,\n",
    "         'subsample': 0.15,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'eval_metric': \"logloss\",\n",
    "#          # GPU integration will cut time in ~half:\n",
    "#          'gpu_id' : 0,\n",
    "#          'tree_method': 'gpu_hist',\n",
    "#          'predictor': 'gpu_predictor'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, target=target)\n",
    "#(best_model, best_param, best_eval, best_boost_rounds) = predxgboost.xgb_paramsearch(X_train=X_train, y_train=X_train['encoded_target'], features=feature_list, init_params=param, metrics=['error', 'logloss', 'auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_param)\n",
    "print(best_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_boost_rounds = 57\n",
    "best_param = {'max_depth': 5, 'eta': 0.05, 'min_child_weight': 0, 'verbosity': 0, 'objective': 'binary:logitraw', 'silent': 'True', 'gamma': 2, 'subsample': 0.15, 'colsample_bytree': 0.8, 'eval_metric': 'error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_test, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#E69F00'\n",
    "#c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_alldata = {'max_depth': 5, 'eta': 0.05, 'min_child_weight': 0, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 2, 'silent': 'True', 'gamma': 2.0, 'subsample': 0.15, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss'}\n",
    "best_boost_rounds_alldata = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directed_acc_list = []\n",
    "all_acc_list = []\n",
    "#hindered_acc_list = []\n",
    "#immobilized_acc_list = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, balanced=True, target=target)\n",
    "    booster, acc, true_label, preds = predxgboost.train(best_param_alldata, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=57, verbose=False)\n",
    "    all_acc_list.append(acc)\n",
    "\n",
    "    # dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(directed_ecm, balanced=True, target=target)\n",
    "    # booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=False)\n",
    "    # directed_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()#figsize=(4,8))\n",
    "dir_x, dir_y = ecdf(np.array(directed_acc_list))\n",
    "all_x, all_y = ecdf(np.array(all_acc_list))\n",
    "#hind_x, hind_y = ecdf(np.array(hindered_acc_list))\n",
    "#imm_x, imm_y = ecdf(np.array(immobilized_acc_list))\n",
    "plt.scatter(dir_x, dir_y, label='Superdiffusive', s=2)\n",
    "plt.plot(all_x, all_y, label='All modes', c='r')\n",
    "#plt.scatter(hind_x, hind_y, label='hindered', s=2)\n",
    "#plt.scatter(imm_x, imm_y, label='immobilized', s=2)\n",
    "plt.legend()\n",
    "plt.xlabel('Model Accuracy')\n",
    "plt.ylabel('Percentage %')\n",
    "plt.title('ECDF of Model Accuracy for different diffusion modes')\n",
    "plt.xlim([.65, .75])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
