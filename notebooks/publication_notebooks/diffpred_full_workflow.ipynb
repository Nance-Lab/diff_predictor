{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_predictor import data_process, predxgboost, spatial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from numpy.random import permutation\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, recall_score, precision_score, f1_score\n",
    "import operator\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from xgboost.training import CVPack\n",
    "from xgboost import callback\n",
    "from xgboost.core import CallbackEnv\n",
    "from xgboost.core import EarlyStopException\n",
    "from xgboost.core import STRING_TYPES\n",
    "\n",
    "from diff_classifier.features import alpha_calc, unmask_track\n",
    "from diff_predictor.utils import plot_msd_comparisons, plot_individual_msds, plot_particles_in_frame\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookDir = getcwd()\n",
    "\n",
    "print('Current Notebook Dir: ' + workbookDir)\n",
    "chdir(workbookDir) # Go to current workbook Dir\"\n",
    "chdir('..')        # Go up one\n",
    "chdir('..') \n",
    "print(f'Using current directory for loading data: {getcwd()}')\n",
    "workbookDir = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load paths to data\n",
    "\n",
    "age_feature_path = workbookDir + '/data/raw_data_age/'\n",
    "age_feature_filelist = [f for f in listdir(age_feature_path) if isfile(join(age_feature_path, f)) and 'feat' in f]\n",
    "print(len(age_feature_filelist))\n",
    "\n",
    "# age_msd_path = workbookDir + '/raw_data_age/'\n",
    "# age_msd_filelist = [f for f in listdir(age_msd_path) if isfile(join(age_msd_path, f)) and 'msd' in f]\n",
    "# print(len(age_msd_filelist))\n",
    "\n",
    "region_dataset_path = workbookDir + '/data/region_feature_folder/'\n",
    "region_filelist = [f for f in listdir(region_dataset_path) if isfile(join(region_dataset_path, f)) and 'feat' in f]\n",
    "print(len(region_filelist))\n",
    "\n",
    "# treatment_dataset_path = workbookDir + '/data/ecm_feature_folder/'\n",
    "# treatment_filelist = [f for f in listdir(treatment_dataset_path) if isfile(join(treatment_dataset_path, f)) and 'msd' in f]\n",
    "# print(len(treatment_filelist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of age dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_age = data_process.generate_fullstats(age_feature_path, age_feature_filelist, ['P14','P35', 'P70'], 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    'alpha', # Fitted anomalous diffusion alpha exponenet\n",
    "    'D_fit', # Fitted anomalous diffusion coefficient\n",
    "    'kurtosis', # Kurtosis of track\n",
    "    'asymmetry1', # Asymmetry of trajecory (0 for circular symmetric, 1 for linear)\n",
    "    'asymmetry2', # Ratio of the smaller to larger principal radius of gyration\n",
    "    'asymmetry3', # An asymmetric feature that accnts for non-cylindrically symmetric pt distributions\n",
    "    'AR', # Aspect ratio of long and short side of trajectory's minimum bounding rectangle\n",
    "    'elongation', # Est. of amount of extension of trajectory from centroid\n",
    "    'boundedness', # How much a particle with Deff is restricted by a circular confinement of radius r\n",
    "    'fractal_dim', # Measure of how complicated a self similar figure is\n",
    "    'trappedness', # Probability that a particle with Deff is trapped in a region\n",
    "    'efficiency', # Ratio of squared net displacement to the sum of squared step lengths\n",
    "    'straightness', # Ratio of net displacement to the sum of squared step lengths\n",
    "    'MSD_ratio', # MSD ratio of the track\n",
    "#     'frames', # Number of frames the track spans\n",
    "    'Deff1', # Effective diffusion coefficient at 0.33 s\n",
    "    'Deff2', # Effective diffusion coefficient at 3.3 s\n",
    "    #'angle_mean', # Mean turning angle which is counterclockwise angle from one frame point to another\n",
    "    #'angle_mag_mean', # Magnitude of the turning angle mean\n",
    "    #'angle_var', # Variance of the turning angle\n",
    "    #'dist_tot', # Total distance of the trajectory\n",
    "    #'dist_net', # Net distance from first point to last point\n",
    "    #'progression', # Ratio of the net distance traveled and the total distance\n",
    "    'Mean alpha', \n",
    "    'Mean D_fit', \n",
    "    'Mean kurtosis', \n",
    "    'Mean asymmetry1', \n",
    "    'Mean asymmetry2',\n",
    "    'Mean asymmetry3', \n",
    "    'Mean AR',\n",
    "    'Mean elongation', \n",
    "    'Mean boundedness',\n",
    "    'Mean fractal_dim', \n",
    "    'Mean trappedness', \n",
    "    'Mean efficiency',\n",
    "    'Mean straightness', \n",
    "    'Mean MSD_ratio', \n",
    "    'Mean Deff1', \n",
    "    'Mean Deff2',\n",
    "    ]\n",
    "\n",
    "target = 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecm = fstats_tot_age[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(ecm, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)\n",
    "label_df = bal_ecm[target]\n",
    "features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "features = features_df.columns\n",
    "\n",
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.7\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(bal_ecm[target])\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preprocess(ecm, balanced=True, y_scramble=False, target=None):\n",
    "\n",
    "    rand_state = np.random.randint(1, 2000)\n",
    "    if balanced:\n",
    "        bal_ecm = data_process.balance_data(ecm, target, random_state=rand_state)\n",
    "        bal_ecm = bal_ecm.reset_index(drop=True)\n",
    "        #sampled_df = bal_ecm.sample(frac=0.5)\n",
    "        sampled_df = data_process.bin_data(bal_ecm)\n",
    "    else:\n",
    "        sampled_df = data_process.bin_data(ecm)\n",
    "    label_df = sampled_df[target]\n",
    "    features_df = sampled_df.drop([target, 'X', 'Y', 'binx', 'biny', 'bins', 'Track_ID'], axis=1)\n",
    "    features = features_df.columns\n",
    "\n",
    "    if y_scramble:\n",
    "        perm = permutation(len(label_df))\n",
    "        label_shuffled = label_df[perm]\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        sampled_df['encoded_target'] = le.fit_transform(label_shuffled)\n",
    "    else:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        sampled_df['encoded_target'] = le.fit_transform(sampled_df[target])\n",
    "\n",
    "    seed = rand_state\n",
    "    np.random.seed(seed)\n",
    "    train_split = 0.7\n",
    "    test_split = 0.5\n",
    "\n",
    "\n",
    "    training_bins = np.random.choice(sampled_df['bins'].unique(), int(len(sampled_df['bins'].unique())*train_split), replace=False)\n",
    "\n",
    "    X_train = sampled_df[sampled_df['bins'].isin(training_bins)]\n",
    "    X_test_val = sampled_df[~sampled_df['bins'].isin(training_bins)]\n",
    "    X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "    y_train = X_train['encoded_target']\n",
    "    y_test = X_test['encoded_target']\n",
    "    y_val = X_val['encoded_target']\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "    dval = xgb.DMatrix(X_val[features], label=y_val)\n",
    "    return dtrain, dtest, dval, X_train, X_test, y_train, y_test, le\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.get_lengths(bal_ecm, X_train, X_test, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 3,\n",
    "         'eta': 0.005,\n",
    "         'min_child_weight': 0,\n",
    "         'verbosity': 0,\n",
    "         'objective': 'multi:softprob',\n",
    "         'num_class': 3,\n",
    "         'silent': 'True',\n",
    "         'gamma': 5,\n",
    "         'subsample': 0.15,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'eval_metric': \"mlogloss\",\n",
    "#          # GPU integration will cut time in ~half:\n",
    "#          'gpu_id' : 0,\n",
    "#          'tree_method': 'gpu_hist',\n",
    "#          'predictor': 'gpu_predictor'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predxgboost.train(param, dtrain, dtest, dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(best_model, best_param, best_eval, best_boost_rounds) = predxgboost.xgb_paramsearch(X_train=X_train, y_train=X_train['encoded_target'], features=features, init_params=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 4, 'eta': 0.1, 'min_child_weight': 1, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 3, 'silent': 'True', 'gamma': 1.0, 'subsample': 0.5, 'colsample_bytree': 0.6, 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 4, 'eta': 0.01, 'min_child_weight': 2, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 5, 'silent': 'True', 'gamma': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.5, 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multimodel_averages(target_column, classes, data, params, num_boost_rounds, balanced=True, y_scramble=False, models_to_run=50):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    results_dict = {\n",
    "        'tot_acc_vals': np.zeros(models_to_run),\n",
    "        'tot_prec_vals': np.zeros(models_to_run),\n",
    "        'tot_rec_vals': np.zeros(models_to_run),\n",
    "        'tot_f1_vals': np.zeros(models_to_run),\n",
    "        'booster_list': list(range(models_to_run)),\n",
    "        'truelabels_list': list(range(models_to_run)),\n",
    "        'preds_list': list(range(models_to_run)),\n",
    "        'xtest_list': list(range(models_to_run))\n",
    "    }\n",
    "\n",
    "\n",
    "    for class_name in classes:\n",
    "        key_name_acc = class_name + '_acc_vals'\n",
    "        results_dict[key_name_acc] = np.zeros(models_to_run)\n",
    "\n",
    "        key_name_prec = class_name + '_prec_vals'\n",
    "        results_dict[key_name_prec] = np.zeros(models_to_run)\n",
    "\n",
    "        key_name_rec = class_name + '_rec_vals'\n",
    "        results_dict[key_name_rec] = np.zeros(models_to_run)\n",
    "\n",
    "        key_name_f1 = class_name + '_f1_vals'\n",
    "        results_dict[key_name_f1] = np.zeros(models_to_run)\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(models_to_run):\n",
    "        print(i)\n",
    "\n",
    "        dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, balanced=balanced, target=target_column, y_scramble=y_scramble)\n",
    "        booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=num_boost_rounds, verbose=False)\n",
    "\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        results_dict['tot_acc_vals'][i] = accuracy_score(true_label, preds)\n",
    "        results_dict['tot_prec_vals'][i] = precision_score(true_label, preds, average='macro')\n",
    "        results_dict['tot_rec_vals'][i] = recall_score(true_label, preds, average='macro')\n",
    "        results_dict['tot_f1_vals'][i] = f1_score(true_label, preds, average='macro')\n",
    "\n",
    "        results_dict['xtest_list'][i] = X_test\n",
    "\n",
    "        results_dict['booster_list'][i] = booster\n",
    "        results_dict['truelabels_list'][i] = true_label\n",
    "        results_dict['preds_list'][i] = preds\n",
    "\n",
    "        prec, rec, f1, sup = precision_recall_fscore_support(true_label, preds)\n",
    "\n",
    "        for class_name in classes:\n",
    "            class_label = np.where(le.classes_ == class_name)\n",
    "            class_idx = np.where(true_label == class_label[0])\n",
    "\n",
    "            key_name_acc = class_name + '_acc_vals'\n",
    "            results_dict[key_name_acc][i] = accuracy_score(true_label[class_idx], preds[class_idx])\n",
    "\n",
    "            key_name_prec = class_name + '_prec_vals'\n",
    "            results_dict[key_name_prec][i] = prec[class_label]\n",
    "\n",
    "            key_name_rec = class_name + '_rec_vals'\n",
    "            results_dict[key_name_rec][i] = rec[class_label]\n",
    "\n",
    "            key_name_f1 = class_name + '_f1_vals'\n",
    "            results_dict[key_name_f1][i] = f1[class_label]\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_results_dict_100models = get_multimodel_averages('age', ecm['age'].unique(), ecm, best_param, 767, models_to_run=10, y_scramble=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in age_results_dict_100models.keys():\n",
    "    value = age_results_dict_100models[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        # fig = plt.figure()\n",
    "        # plt.hist(value, bins=25)\n",
    "        # plt.title(f'age, {key}')\n",
    "        print(f'age, {key}')\n",
    "        print(np.median(value))\n",
    "        print(stats.iqr(value, interpolation='midpoint'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in age_results_dict.keys():\n",
    "    value = age_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        fig = plt.figure()\n",
    "        plt.hist(value, bins=25)\n",
    "        plt.title(f'age, {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_yscramb_results_dict = get_multimodel_averages('age', ecm['age'].unique(), ecm, best_param, 804, models_to_run=50, y_scramble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in age_yscramb_results_dict.keys():\n",
    "    value = age_yscramb_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic)):\n",
    "        fig = plt.figure()\n",
    "        plt.hist(value, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_multimodel_averages(target, models_to_run=50, )\n",
    "\n",
    "#     age_tot_acc_vals = np.zeros(models_to_run)\n",
    "#     age_tot_prec_vals = np.zeros(models_to_run)\n",
    "#     age_tot_rec_vals = np.zeros(models_to_run)\n",
    "#     age_tot_f1_vals = np.zeros(models_to_run)\n",
    "\n",
    "#     age_booster_list = list(range(models_to_run))\n",
    "#     age_truelabels_list = list(range(models_to_run))\n",
    "#     age_preds_list = list(range(models_to_run))\n",
    "#     age_xtest_list = list(range(models_to_run))\n",
    "\n",
    "#     P14_acc_vals = np.zeros(models_to_run)\n",
    "#     P35_acc_vals = np.zeros(models_to_run)\n",
    "#     P70_acc_vals = np.zeros(models_to_run)\n",
    "\n",
    "#     P14_prec_vals = np.zeros(models_to_run)\n",
    "#     P35_prec_vals = np.zeros(models_to_run)\n",
    "#     P70_prec_vals = np.zeros(models_to_run)\n",
    "\n",
    "#     P14_rec_vals = np.zeros(models_to_run)\n",
    "#     P35_rec_vals = np.zeros(models_to_run)\n",
    "#     P70_rec_vals = np.zeros(models_to_run)\n",
    "\n",
    "#     P14_f1_vals = np.zeros(models_to_run)\n",
    "#     P35_f1_vals = np.zeros(models_to_run)\n",
    "#     P70_f1_vals = np.zeros(models_to_run)\n",
    "\n",
    "#     P14_sup_vals = np.zeros(models_to_run)\n",
    "#     P35_sup_vals = np.zeros(models_to_run)\n",
    "#     P70_sup_vals = np.zeros(models_to_run)\n",
    "\n",
    "#     for i in range(models_to_run):\n",
    "#         print(i)\n",
    "\n",
    "\n",
    "#         dtrain, dtest, dval, X_train, X_test, y_train, y_test, le = full_preprocess(ecm, balanced=True, target=target)\n",
    "#         booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=804, verbose=False)\n",
    "\n",
    "#         preds = np.array(preds)\n",
    "\n",
    "#         age_tot_acc_vals[i] = accuracy_score(true_label, preds)\n",
    "#         age_tot_prec_vals[i] = precision_score(true_label, preds, average='macro')\n",
    "#         age_tot_rec_vals[i] = recall_score(true_label, preds, average='macro')\n",
    "#         age_tot_f1_vals[i] = f1_score(true_label, preds, average='macro')\n",
    "\n",
    "#         age_xtest_list[i] = X_test\n",
    "\n",
    "#         age_booster_list[i] = booster\n",
    "#         age_truelabels_list[i] = true_label\n",
    "#         age_preds_list[i] = preds\n",
    "\n",
    "#         prec, rec, f1, sup = precision_recall_fscore_support(true_label, preds)\n",
    "\n",
    "#         p14_idx = np.where(le.classes_=='P14')\n",
    "#         p35_idx = np.where(le.classes_=='P35')\n",
    "#         p70_idx = np.where(le.classes_=='P70')\n",
    "\n",
    "#         p14_locs = np.where(true_label==p14_idx[0])\n",
    "#         p35_locs = np.where(true_label==p35_idx[0])\n",
    "#         p70_locs = np.where(true_label==p70_idx[0])\n",
    "\n",
    "#         P14_acc_vals[i] = accuracy_score(true_label[p14_locs], preds[p14_locs])\n",
    "#         P35_acc_vals[i] = accuracy_score(true_label[p35_locs], preds[p35_locs])\n",
    "#         P70_acc_vals[i] = accuracy_score(true_label[p70_locs], preds[p70_locs])\n",
    "\n",
    "\n",
    "#         P14_prec_vals[i] = prec[p14_idx]\n",
    "#         P35_prec_vals[i] = prec[p35_idx]\n",
    "#         P70_prec_vals[i] = prec[p70_idx]\n",
    "\n",
    "#         P14_rec_vals[i] = rec[p14_idx]\n",
    "#         P35_rec_vals[i] = rec[p35_idx]\n",
    "#         P70_rec_vals[i] = rec[p70_idx]\n",
    "\n",
    "#         P14_f1_vals[i] = f1[p14_idx]\n",
    "#         P35_f1_vals[i] = f1[p35_idx]\n",
    "#         P70_f1_vals[i] = f1[p70_idx]\n",
    "\n",
    "#         P14_sup_vals[i] = sup[p14_idx]\n",
    "#         P35_sup_vals[i] = sup[p35_idx]\n",
    "#         P70_sup_vals[i] = sup[p70_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label[p14_locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P70_acc_vals.mean())\n",
    "print(P70_acc_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_acc_vals.mean())\n",
    "print(age_tot_acc_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_prec_vals.mean())\n",
    "print(age_tot_prec_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_rec_vals.mean())\n",
    "print(age_tot_rec_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_tot_f1_vals.mean())\n",
    "print(age_tot_f1_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P14_sup_vals.mean())\n",
    "print(P14_sup_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P35_f1_vals.mean())\n",
    "print(P35_f1_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P70_f1_vals.mean())\n",
    "print(P70_f1_vals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(P14_acc_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medIdx = list(age_tot_acc_vals).index(np.percentile(age_tot_acc_vals,50,interpolation='nearest'))\n",
    "medIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = np.argsort(age_yscramb_results_dict['tot_acc_vals'])[len(age_yscramb_results_dict['tot_acc_vals'])//2]\n",
    "med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_idx = np.argsort(age_tot_acc_vals)[0]\n",
    "max_idx = np.argsort(age_tot_acc_vals)[-1]\n",
    "print(min_idx)\n",
    "print(max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_yscramb_results_dict['booster_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = age_yscramb_results_dict['booster_list'][med]\n",
    "class_names = le.classes_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_yscramb_results_dict['xtest_list'][med]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_xtest_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(age_yscramb_results_dict['xtest_list'][med])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[feature_list], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5): \n",
    "    figsize = (7.5, 5)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.gca()\n",
    "    shap.summary_plot(shap_values[i], X_test[feature_list], max_display=5, show=False)\n",
    "    ax.set_title(f'Top 5 Features for {le.classes_[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently using parameters found in the diff_mode analysis notebook for age\n",
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=804, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(true_label, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(true_label, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed bc of this issue: https://github.com/slundberg/shap/issues/1215\n",
    "\n",
    "# model_bytearray = booster.save_raw()[4:]\n",
    "# def myfun(self=None):\n",
    "#     return model_bytearray\n",
    "\n",
    "# booster.save_raw = myfun\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_df_filled = ecm[features].fillna(0)\n",
    "scaled_df = scaler.fit_transform(features_df_filled)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_filled['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = r_pca.R_pca(scaled_df).fit(max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_array = np.absolute(S.values)\n",
    "S_array\n",
    "\n",
    "S_magnitudes = np.zeros(len(S))\n",
    "for i in range(len(S)):\n",
    "    abs_sum = np.sum(S_array[i])\n",
    "    S_magnitudes[i] = abs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(S_magnitudes, bins=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((S_magnitudes), bins=5000)\n",
    "plt.vlines((S_magnitudes).mean()+((S_magnitudes).std()*3), ymin=0, ymax=40, color='r')\n",
    "plt.vlines((S_magnitudes).mean()-((S_magnitudes).std()*3), ymin=0, ymax=40, color='r')\n",
    "plt.title('Distrubution of Sparse Matrix Magnitudes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(S_magnitudes), bins=5000)\n",
    "plt.vlines(np.log(S_magnitudes).mean()+(np.log(S_magnitudes).std()*4), ymin=0, ymax=40, color='r')\n",
    "plt.vlines(np.log(S_magnitudes).mean()-(np.log(S_magnitudes).std()*4), ymin=0, ymax=40, color='r')\n",
    "plt.title('Distrubution of Sparse Matrix Magnitudes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_outlier_cutoff = np.log(S_magnitudes).mean()+(np.log(S_magnitudes).std()*5)\n",
    "S_mag_log = np.log(S_magnitudes)\n",
    "outliers = S_mag_log[S_mag_log > upper_outlier_cutoff]\n",
    "print(len(outliers))\n",
    "outlier_inds = np.where(S_mag_log > upper_outlier_cutoff)\n",
    "normal_inds = np.where(S_mag_log <= upper_outlier_cutoff)\n",
    "outlier_df = ecm.iloc[outlier_inds[0]]\n",
    "normal_df = ecm.iloc[normal_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(normal_df, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(bal_ecm[target])\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently using parameters found in the diff_mode analysis notebook for age\n",
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=96, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_test, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_out = preprocessing.LabelEncoder()\n",
    "outlier_df['encoded_target'] = le_out.fit_transform(outlier_df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_outlier = outlier_df['encoded_target']\n",
    "d_outliers = xgb.DMatrix(outlier_df[features], label=y_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = d_outliers.get_label()\n",
    "ypred = booster.predict(d_outliers)\n",
    "preds = [np.where(x == np.max(x))[0][0] for x in ypred]\n",
    "acc = accuracy_score(true_label, preds)\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds\n",
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_outlier, preds, digits=4, target_names=le.classes_)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_outlier, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_outlier, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(outlier_df[features])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, outlier_df[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perr_alph = []\n",
    "perr_dcoef = []\n",
    "\n",
    "for i in range(len(age_msd_filelist)):\n",
    "\n",
    "    \n",
    "    msd_df = pd.read_csv(age_msd_path + age_msd_filelist[i])\n",
    "    trackids = msd_df['Track_ID'].unique()\n",
    "    partcount = trackids.shape[0]\n",
    "    for particle in range(0, partcount):\n",
    "\n",
    "        single_track_masked = msd_df.loc[msd_df['Track_ID'] == trackids[particle]].sort_values(['Track_ID', 'Frame'], ascending=[1,1]).reset_index(drop=True)\n",
    "        single_track = unmask_track(single_track_masked)\n",
    "        xpos = single_track['MSDs']\n",
    "        ypos = single_track['Frame']\n",
    "\n",
    "        def msd_alpha(xpos, alph, dcoef):\n",
    "                return 4*dcoef*(xpos**alph)\n",
    "\n",
    "        try:\n",
    "            popt, pcov = curve_fit(msd_alpha, xpos, ypos)\n",
    "            alph = popt[0]\n",
    "            dcoef = popt[1]\n",
    "            perr = np.sqrt(np.diag(pcov))\n",
    "            perr_alph.append(perr[0])\n",
    "            perr_dcoef.append(perr[1])\n",
    "        except RuntimeError:\n",
    "            print('Optimal parameters not found. Print NaN instead.')\n",
    "            alph = np.nan\n",
    "            dcoef = np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perr_alph_arr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perr_alph_arr = np.array(perr_alph)\n",
    "perr_alph_arr = perr_alph_arr[perr_alph_arr != np.inf]\n",
    "perr_alph_arr = perr_alph_arr[perr_alph_arr != np.nan]\n",
    "\n",
    "plt.hist(perr_alph_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perr_dcoef_arr = np.array(perr_dcoef)\n",
    "perr_dcoef_arr = perr_dcoef_arr[perr_dcoef_arr != np.inf]\n",
    "plt.hist(perr_dcoef_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_region = data_process.generate_fullstats(region_dataset_path, region_filelist, ['cortex', 'striatum', 'hippocampus',], 'region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'region'\n",
    "ecm = fstats_tot_region[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_results_dict = get_multimodel_averages('region', ecm['region'].unique(), ecm, best_param, 1157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in region_results_dict.keys():\n",
    "    value = region_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        fig = plt.figure()\n",
    "        plt.hist(value)\n",
    "        plt.title(f'region, {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in region_results_dict.keys():\n",
    "    value = region_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        print(f'region, {key}')\n",
    "        print(np.median(value))\n",
    "        print(stats.iqr(value, interpolation= 'midpoint'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_yscramb_results_dict = get_multimodel_averages('region', ecm['region'].unique(), ecm, best_param, 200, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in region_yscramb_results_dict.keys():\n",
    "    value = region_yscramb_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        fig = plt.figure()\n",
    "        plt.hist(value, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_results_dict = results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(region_results_dict['tot_acc_vals'], bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(ecm, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)\n",
    "bal_ecm = bal_ecm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = bal_ecm[target].copy()\n",
    "features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "features = features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(label_df)\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 4,\n",
    " 'eta': 0.005,\n",
    " 'min_child_weight': 0,\n",
    " 'verbosity': 0,\n",
    " 'objective': 'multi:softprob',\n",
    " 'num_class': 5,\n",
    " 'silent': 'True',\n",
    " 'gamma': 5,\n",
    " 'subsample': 0.6,\n",
    " 'colsample_bytree': 0.7,\n",
    " 'eval_metric': 'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=1157, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_test, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap=\"YlGnBu\")\n",
    "# ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#E69F00'\n",
    "c_HYase = '#56B4E9'\n",
    "c_ChABC = '#009E73'\n",
    "\n",
    "colors = [c_NT, c_HYase, c_ChABC]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_df_filled = ecm[features].fillna(0)\n",
    "scaled_df = scaler.fit_transform(features_df_filled)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = r_pca.R_pca(scaled_df).fit(max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_array = np.absolute(S.values)\n",
    "S_array\n",
    "\n",
    "S_magnitudes = np.zeros(len(S))\n",
    "for i in range(len(S)):\n",
    "    abs_sum = np.sum(S_array[i])\n",
    "    S_magnitudes[i] = abs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(S_magnitudes, bins=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(S_magnitudes), bins=5000)\n",
    "plt.vlines(np.log(S_magnitudes).mean()+(np.log(S_magnitudes).std()*3), ymin=0, ymax=40, color='r')\n",
    "plt.vlines(np.log(S_magnitudes).mean()-(np.log(S_magnitudes).std()*3), ymin=0, ymax=40, color='r')\n",
    "plt.title('Distrubution of Sparse Matrix Magnitudes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_outlier_cutoff = np.log(S_magnitudes).mean()+(np.log(S_magnitudes).std()*5)\n",
    "S_mag_log = np.log(S_magnitudes)\n",
    "outliers = S_mag_log[S_mag_log > upper_outlier_cutoff]\n",
    "print(len(outliers))\n",
    "outlier_inds = np.where(S_mag_log > upper_outlier_cutoff)\n",
    "normal_inds = np.where(S_mag_log <= upper_outlier_cutoff)\n",
    "outlier_inds[0]\n",
    "outlier_df = ecm.iloc[outlier_inds[0]]\n",
    "normal_df = ecm.iloc[normal_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(normal_df, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(bal_ecm[target])\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_out = preprocessing.LabelEncoder()\n",
    "outlier_df['encoded_target'] = le_out.fit_transform(outlier_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_outlier = outlier_df['encoded_target']\n",
    "d_outliers = xgb.DMatrix(outlier_df[features], label=y_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = d_outliers.get_label()\n",
    "ypred = booster.predict(d_outliers)\n",
    "preds = [np.where(x == np.max(x))[0][0] for x in ypred]\n",
    "acc = accuracy_score(true_label, preds)\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(true_label, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot_treatment = data_process.generate_fullstats(treatment_dataset_path, treatment_filelist, ['NT', 'ChABC'], 'treatment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'treatment'\n",
    "ecm = fstats_tot_treatment[feature_list + [target, 'Track_ID', 'X', 'Y']] #dont think i need these rn\n",
    "print(ecm.shape)\n",
    "ecm = ecm[~ecm[list(set(feature_list) - set(['Deff2', 'Mean Deff2']))].isin([np.nan, np.inf, -np.inf]).any(1)]       # Removing nan and inf data points\n",
    "ecm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'max_depth': 5, 'eta': 0.05, 'min_child_weight': 0, 'verbosity': 0, 'objective': 'multi:softprob', 'num_class': 2, 'silent': 'True', 'gamma': 2.0, 'subsample': 0.15, 'colsample_bytree': 0.8, 'eval_metric': 'mlogloss'}\n",
    "best_boost_rounds = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_results_dict = get_multimodel_averages('treatment', ecm['treatment'].unique(), ecm, best_param, 57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in treatment_results_dict.keys():\n",
    "    value = treatment_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        print(key)\n",
    "        print(np.median(value))\n",
    "        print(stats.iqr(value, interpolation = 'midpoint'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_results_dict_binary = get_multimodel_averages('treatment', ecm['treatment'].unique(), ecm, best_param, 57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_yscramb_results_dict = get_multimodel_averages('treatment', ecm['treatment'].unique(), ecm, best_param, 57, True, True, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in treatment_yscramb_results_dict.keys():\n",
    "    value = treatment_yscramb_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        print(key)\n",
    "        print(np.median(value))\n",
    "        print(stats.iqr(value, interpolation = 'midpoint'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in treatment_yscramb_results_dict.keys():\n",
    "    value = treatment_yscramb_results_dict[key]\n",
    "    if isinstance(value, (np.ndarray, np.generic) ):\n",
    "        fig = plt.figure()\n",
    "        plt.hist(value, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(ecm, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)\n",
    "label_df = bal_ecm[target]\n",
    "features_df = bal_ecm.drop([target, 'Track_ID', 'X', 'Y', 'binx', 'biny', 'bins'], axis=1)\n",
    "features = features_df.columns\n",
    "\n",
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(bal_ecm[target])\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(y_test, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_array = metrics.confusion_matrix(y_test, preds)\n",
    "df_cm = pd.DataFrame(cm_array, index = class_names, columns = class_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "ax = sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"YlGnBu\")\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "explainer = shap.TreeExplainer(booster)\n",
    "shap_values = explainer.shap_values(X_test[features])\n",
    "c_NT = '#fc8d59'\n",
    "#c_HYase = '#ffffbf'\n",
    "c_ChABC = '#91bfdb'\n",
    "\n",
    "colors = [c_ChABC, c_NT]\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])\n",
    "shap.summary_plot(shap_values, X_test[features], class_names=np.array(class_names), max_display=15, title='Total SHAP Values', color=cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(S_magnitudes), bins=5000)\n",
    "plt.vlines(np.log(S_magnitudes).mean()+(np.log(S_magnitudes).std()*3), ymin=0, ymax=40, color='r')\n",
    "plt.vlines(np.log(S_magnitudes).mean()-(np.log(S_magnitudes).std()*3), ymin=0, ymax=40, color='r')\n",
    "plt.title('Distrubution of Sparse Matrix Magnitudes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_outlier_cutoff = np.log(S_magnitudes).mean()+(np.log(S_magnitudes).std()*5.7)\n",
    "S_mag_log = np.log(S_magnitudes)\n",
    "outliers = S_mag_log[S_mag_log > upper_outlier_cutoff]\n",
    "print(len(outliers))\n",
    "outlier_inds = np.where(S_mag_log > upper_outlier_cutoff)\n",
    "normal_inds = np.where(S_mag_log <= upper_outlier_cutoff)\n",
    "outlier_inds[0]\n",
    "outlier_df = ecm.iloc[outlier_inds[0]]\n",
    "normal_df = ecm.iloc[normal_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_ecm = data_process.balance_data(normal_df, target, random_state=1)\n",
    "bal_ecm = data_process.bin_data(bal_ecm, resolution=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular split\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "train_split = 0.5\n",
    "test_split = 0.5\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bal_ecm['encoded_target'] = le.fit_transform(bal_ecm[target])\n",
    "\n",
    "training_bins = np.random.choice(bal_ecm.bins.unique(), int(len(bal_ecm.bins.unique())*train_split), replace=False)\n",
    "\n",
    "X_train = bal_ecm[bal_ecm.bins.isin(training_bins)]\n",
    "X_test_val = bal_ecm[~bal_ecm.bins.isin(training_bins)]\n",
    "X_val, X_test = train_test_split(X_test_val, test_size=test_split, random_state=seed)\n",
    "\n",
    "y_train = X_train['encoded_target']\n",
    "y_test = X_test['encoded_target']\n",
    "y_val = X_val['encoded_target']\n",
    "\n",
    "# dtrain = X_train[features]\n",
    "# dtest = X_test[features]\n",
    "# dval = X_val[features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], label=y_train)\n",
    "dtest = xgb.DMatrix(X_test[features], label=y_test)\n",
    "dval = xgb.DMatrix(X_val[features], label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "outlier_df['encoded_target'] = le.fit_transform(outlier_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_outlier = outlier_df['encoded_target']\n",
    "d_outliers = xgb.DMatrix(outlier_df[features], label=y_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster, acc, true_label, preds = predxgboost.train(best_param, dtrain, dtest, dval, evals=[(dtrain, 'train'), (dval, 'eval')], num_round=best_boost_rounds, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = d_outliers.get_label()\n",
    "ypred = booster.predict(d_outliers)\n",
    "preds = [np.where(x == np.max(x))[0][0] for x in ypred]\n",
    "acc = accuracy_score(true_label, preds)\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = le.classes_\n",
    "class_results = classification_report(true_label, preds, digits=4, target_names = class_names)\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
