{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- added to file ----\n",
    "# Takes in a String, \"bucket_name\", a string, \"remote_folder\",\n",
    "# and a list of strings or a single string, \"keywords\". Gets all\n",
    "# s3 keys for bucket_name/remote_folder. Uses a list convention\n",
    "# to go through keywords (i.e): ['a', 'b', 'c OR d OR e'] will \n",
    "# find all files containing 'a' and 'b' and either 'c', 'd', or 'e'.\n",
    "# Using '' will return every file key in folder.\n",
    "def get_s3_keys(bucket_name, remote_folder, keywords=''):\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    obj_list = []\n",
    "    keywords = [i.split('OR') for i in list(keywords)]\n",
    "    keywords = [list(map(lambda x:x.strip(), i)) for i in keywords]\n",
    "    for object in bucket.objects.all():\n",
    "        filename = object.key.split(\"/\")[-1]\n",
    "        kwds_in = all(any(k in filename for k in ([keyword]*isinstance(keyword, str) or keyword)) for keyword in keywords)\n",
    "        if remote_folder in object.key and kwds_in:\n",
    "            obj_list.append(s3.Object(object.bucket_name, object.key))\n",
    "    return obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Takes in a path and list of keywords. Returns a list of filenames\n",
    "# that are within the path that contain one of the keyword in the list.\n",
    "# Set keyword to \"\" to get all files in the path.\n",
    "def get_files(path, keywords = [\"features_ OR msd_\"]):\n",
    "    \"\"\"\n",
    "    Takes in a path and list of keywords. Returns a list of filenames\n",
    "    that are within the path that contain one of the keyword in the list.\n",
    "    Set keyword to \"\" to get all files in the path.\n",
    "    \"\"\"\n",
    "    keywords = [i.split('OR') for i in list(keywords)]\n",
    "    keywords = [list(map(lambda x:x.strip(), i)) for i in keywords]\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    file_list = []\n",
    "    for filename in files:\n",
    "        kwds_in = all(any(k in filename for k in ([keyword]*isinstance(keyword, str) or keyword)) for keyword in keywords)\n",
    "        if (kwds_in):\n",
    "            file_list.append(filename)\n",
    "    return file_list\n",
    "\n",
    "# Pre: Both files must exhist; Feature must be in the feature file\n",
    "# Throws a FileNotFoundError exception if preconditions not met\n",
    "#\n",
    "# Adds a feature from produced features file to the track file.\n",
    "def combine_track(trackFile, feature=None, featureDF=None):\n",
    "    '''\n",
    "    Adds a feature or set of feature to the corresponding track file\n",
    "    Preconditions: Both files must exhist; Feature(s) must be in the \n",
    "    feature file. \n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    trackFile : string :\n",
    "        The file location of the dataframe \n",
    "    feature : list : string : tuple :\n",
    "        feature or set of features to attach to track dataframe\n",
    "    Output:\n",
    "    -------\n",
    "    trackDF : pd.DataFrame :\n",
    "        DataFrame of the combined tracks\n",
    "    '''\n",
    "    if isinstance(trackFile, str):\n",
    "        try:\n",
    "            trackDF = pd.read_csv(trackFile)\n",
    "        except FileNotFoundError:\n",
    "            raise(\"DataFrame cannot be located\")\n",
    "    else:\n",
    "        trackDF = trackFile\n",
    "    if featureDF is None:\n",
    "        featureDF = find_pair(trackFile)\n",
    "    if feature is None:\n",
    "        feature = np.setdiff1d(featureDF.columns.values, trackDF.columns.values)\n",
    "    elif isinstance(feature, str):\n",
    "        feature = [feature]\n",
    "    elif isinstance(feature, tuple):\n",
    "        feature = list(feature)\n",
    "    trackDF = trackDF.reindex(columns=[*trackDF.columns.tolist()] + [*feature], fill_value=np.nan)\n",
    "    maxFrames = int(trackDF[\"Frame\"].max())\n",
    "    maxTracks = int(trackDF[\"Track_ID\"].max())\n",
    "    for i in range(int(maxTracks)+1):\n",
    "        for feat in feature:\n",
    "            trackFeature = featureDF.loc[i, feat]\n",
    "            trackDF.loc[(maxFrames)*(i+1) + i, feat] = trackFeature\n",
    "    return trackDF\n",
    "\n",
    "# Trys to find the feature file pair for either the msd_ or Traj_\n",
    "# Returns the pd.DataFrame of that pair if found.\n",
    "def find_pair(filename):\n",
    "    \"\"\"\n",
    "    Trys to find the feature file pair for either the msd_ or traj_ df,\n",
    "    or the Traj_ or msd_ file for input feauture_ file.\n",
    "    Returns the pd.DataFrame of that pair if found.\n",
    "    \"\"\"\n",
    "    if \"msd_\" in filename:\n",
    "        try:\n",
    "            filename = filename.replace(\"msd_\", \"\").replace(\"Traj_\", \"\")\n",
    "            filename = filename.split(\"/\")\n",
    "            filename[-1] = \"features_\" + filename[-1]\n",
    "            featureFile = \"/\".join(filename)\n",
    "            return pd.read_csv(featureFile)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File pair could not be found\")  \n",
    "    elif \"features_\" in filename:\n",
    "        try:\n",
    "            filename = filename.replace(\"features_\", \"\")\n",
    "            filename = filename.split(\"/\")\n",
    "            filename[-1] = \"msd_\" + filename[-1]\n",
    "            featureFile = \"/\".join(filename)\n",
    "            return pd.read_csv(featureFile)\n",
    "        except:\n",
    "            try:\n",
    "                filename = filename.replace(\"features_\", \"\")\n",
    "                filename = filename.split(\"/\")\n",
    "                filename[-1] = \"Traj_\" + filename[-1]\n",
    "                featureFile = \"/\".join(filename)\n",
    "                return pd.read_csv(featureFile)\n",
    "            except FileNotFoundError:\n",
    "                print(\"File pair could not be found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Notebook Dir: C:\\Users\\david\\Documents\n"
     ]
    }
   ],
   "source": [
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = getcwd()\n",
    "print('Current Notebook Dir: ' + workbookDir)\n",
    "chdir(workbookDir) # Go to current workbook Dir\n",
    "chdir('..')        # Go up one\n",
    "print(f'Using current directory for loading data: {getcwd()}')\n",
    "workbookDir = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './raw_data_region_cortex_striatum/'\n",
    "track_file_list = get_files(dataset_path, keywords=['msd_'])\n",
    "feature_file_list = get_files(dataset_path, ['features_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/david/Documents/nancework/source/diff_predictor\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for filename in feature_file_list:\n",
    "    tstats = pd.read_csv(dataset_path + '/' + filename, encoding = \"ISO-8859-1\", index_col='Unnamed: 0')\n",
    "    lengths.append(len(tstats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100699"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lengths).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_NT_brain_2_slice_1_vid_1.csv size: (416, 23)\n",
      "features_NT_brain_2_slice_1_vid_2.csv size: (833, 91)\n",
      "features_NT_brain_2_slice_1_vid_3.csv size: (1017, 91)\n",
      "features_NT_brain_2_slice_1_vid_4.csv size: (878, 91)\n",
      "features_NT_brain_2_slice_1_vid_5.csv size: (467, 91)\n",
      "features_NT_brain_2_slice_2_vid_1.csv size: (2488, 91)\n",
      "features_NT_brain_2_slice_2_vid_2.csv size: (2322, 91)\n",
      "features_NT_brain_2_slice_2_vid_3.csv size: (1735, 91)\n",
      "features_NT_brain_2_slice_2_vid_4.csv size: (1650, 91)\n",
      "features_NT_brain_2_slice_2_vid_5.csv size: (2100, 91)\n",
      "features_NT_brain_2_slice_3_vid_1.csv size: (562, 91)\n",
      "features_NT_brain_2_slice_3_vid_2.csv size: (853, 91)\n",
      "features_NT_brain_2_slice_3_vid_3.csv size: (817, 91)\n",
      "features_NT_brain_2_slice_3_vid_4.csv size: (598, 23)\n",
      "features_NT_brain_2_slice_3_vid_5.csv size: (1062, 91)\n",
      "features_P14_40nm_s1_v1.csv size: (793, 91)\n",
      "features_P14_40nm_s1_v2.csv size: (1356, 91)\n",
      "features_P14_40nm_s1_v3.csv size: (519, 91)\n",
      "features_P14_40nm_s1_v4.csv size: (140, 91)\n",
      "features_P14_40nm_s1_v5.csv size: (268, 91)\n",
      "features_P14_40nm_s2_v1.csv size: (568, 91)\n",
      "features_P14_40nm_s2_v2.csv size: (938, 91)\n",
      "features_P14_40nm_s2_v3.csv size: (220, 91)\n",
      "features_P14_40nm_s2_v4.csv size: (162, 91)\n",
      "features_P14_40nm_s2_v5.csv size: (258, 91)\n",
      "features_P14_40nm_s3_v1.csv size: (151, 91)\n",
      "features_P14_40nm_s3_v2.csv size: (243, 91)\n",
      "features_P14_40nm_s3_v3.csv size: (323, 91)\n",
      "features_P14_40nm_s3_v4.csv size: (113, 91)\n",
      "features_P14_40nm_s3_v5.csv size: (389, 91)\n",
      "features_P21_40nm_s1_v1.csv size: (807, 91)\n",
      "features_P21_40nm_s1_v2.csv size: (2481, 91)\n",
      "features_P21_40nm_s1_v3.csv size: (1330, 91)\n",
      "features_P21_40nm_s1_v4.csv size: (1294, 91)\n",
      "features_P21_40nm_s1_v5.csv size: (2540, 91)\n",
      "features_P21_40nm_s2_v1.csv size: (2584, 91)\n",
      "features_P21_40nm_s2_v2.csv size: (846, 91)\n",
      "features_P21_40nm_s2_v3.csv size: (435, 91)\n",
      "features_P21_40nm_s2_v4.csv size: (1506, 91)\n",
      "features_P21_40nm_s2_v5.csv size: (2884, 91)\n",
      "features_P21_40nm_s3_v1.csv size: (1086, 91)\n",
      "features_P21_40nm_s3_v2.csv size: (679, 91)\n",
      "features_P21_40nm_s3_v3.csv size: (456, 91)\n",
      "features_P21_40nm_s3_v4.csv size: (1417, 91)\n",
      "features_P21_40nm_s3_v5.csv size: (915, 91)\n",
      "features_P28_40nm_s1_v1.csv size: (679, 91)\n",
      "features_P28_40nm_s1_v2.csv size: (480, 91)\n",
      "features_P28_40nm_s1_v3.csv size: (195, 91)\n",
      "features_P28_40nm_s1_v4.csv size: (699, 91)\n",
      "features_P28_40nm_s1_v5.csv size: (457, 91)\n",
      "features_P28_40nm_s2_v1.csv size: (500, 91)\n",
      "features_P28_40nm_s2_v2.csv size: (610, 91)\n",
      "features_P28_40nm_s2_v3.csv size: (494, 91)\n",
      "features_P28_40nm_s2_v4.csv size: (703, 91)\n",
      "features_P28_40nm_s2_v5.csv size: (372, 91)\n",
      "features_P28_40nm_s3_v1.csv size: (203, 91)\n",
      "features_P28_40nm_s3_v2.csv size: (306, 91)\n",
      "features_P28_40nm_s3_v3.csv size: (326, 91)\n",
      "features_P28_40nm_s3_v4.csv size: (75, 91)\n",
      "features_P28_40nm_s3_v5.csv size: (195, 91)\n"
     ]
    }
   ],
   "source": [
    "fstats_tot = None\n",
    "video_num = 0\n",
    "for filename in feature_file_list:\n",
    "    try:\n",
    "        fstats = pd.read_csv(dataset_path + '/' + filename, encoding = \"ISO-8859-1\", index_col='Unnamed: 0')\n",
    "        tstats = find_pair(dataset_path + '/' + filename)\n",
    "        print('{} size: {}'.format(filename, fstats.shape))\n",
    "        if 'P14' in filename:\n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[14], index=fstats.index)\n",
    "        elif 'P21' in filename: \n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[21], index=fstats.index)\n",
    "        elif 'P28' in filename:\n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[28], index=fstats.index)\n",
    "        elif 'NT_brain_2' in filename:\n",
    "            fstats['age'] = pd.Series(fstats.shape[0]*[35], index=fstats.index)\n",
    "        else:\n",
    "            print('Error, no target')\n",
    "        fstats['Video Number'] = pd.Series(fstats.shape[0]*[video_num], index=fstats.index)\n",
    "        fstats = combine_track(tstats, np.append(feat, ['age']), featureDF=fstats)\n",
    "        if fstats_tot is None:\n",
    "            fstats_tot = fstats\n",
    "        else:\n",
    "            fstats_tot = fstats_tot.append(fstats, ignore_index=True)\n",
    "        video_num += 1\n",
    "    except Exception:\n",
    "        print('Skipped!: {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fstats_tot.to_csv('saved_datasets/P14_P21_P28_P32_featuresandtracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot = pd.read_csv('saved_datasets/P14_P21_P28_P32_featuresandtracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.array(['AR', 'D_fit', 'Deff1', 'Deff2', 'MSD_ratio', 'alpha',\n",
    "       'asymmetry1', 'asymmetry2', 'asymmetry3', 'boundedness',\n",
    "       'efficiency', 'elongation', 'fractal_dim', 'frames', 'kurtosis',\n",
    "       'straightness', 'trappedness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_df(df, col, res=(0, 651)):\n",
    "    '''\n",
    "    Zeros a single dataframe column so that the first value will be\n",
    "    located at the start of the track.\n",
    "    '''\n",
    "    try:\n",
    "        shift_val = df.iloc[res[0]:res[1]][col].reset_index().dropna().index[0]\n",
    "    except:\n",
    "        shift_val = res[0]-res[1]-1\n",
    "    return df.iloc[res[0]:res[1]][col].reset_index().shift(-shift_val, fill_value=np.nan)[col]\n",
    "\n",
    "def get_zeroed_tracks(df, col, res=650):\n",
    "    '''\n",
    "    Creates an array of all the tracks for a single column in a file\n",
    "    in which the value is zeroed to frame = 0\n",
    "    '''\n",
    "    lower = 0\n",
    "    upper = res+1\n",
    "    value = []\n",
    "    while (upper <= len(df)):\n",
    "        value.append(list(zero_df(df, col=col, res=[lower, upper])))\n",
    "        lower = upper\n",
    "        upper = lower + res + 1\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Creates x and y datasets for LSTM based off of input\n",
    "# track_df data\n",
    "def get_xy_data(df, target, feat=None, use_feat=False, res=650):\n",
    "    n_tracks = int((len(df))/(res+1))\n",
    "    frame = get_zeroed_tracks(df, 'Frame', res=res)\n",
    "    X = get_zeroed_tracks(df, 'X', res=res)\n",
    "    Y = get_zeroed_tracks(df, 'Y', res=res)\n",
    "    MSDs = get_zeroed_tracks(df, 'MSDs', res=res)\n",
    "    trgt = df[target]\n",
    "    datax = []\n",
    "    datay = []\n",
    "    datafeat = []\n",
    "    print(n_tracks)\n",
    "    for j in range(n_tracks):\n",
    "        trackx = []\n",
    "        tracky = []\n",
    "        trackfeat = []\n",
    "        for i in range(res+1):\n",
    "            trackx.append([int(frame[j][i]), X[j][i], Y[j][i], MSDs[j][i]])\n",
    "        datax.append(trackx)\n",
    "        del(trackx)\n",
    "        tracky.append(trgt[(res+1)*(j+1)-1])\n",
    "        datay.append(tracky)\n",
    "        del(tracky)\n",
    "        if use_feat is True:\n",
    "            trackfeat.append(list(df.loc[(res+1)*(j+1)-1, feat]))\n",
    "        datafeat.append(trackfeat)\n",
    "        del(trackfeat)\n",
    "    del(df, frame, X, Y, MSDs, trgt)\n",
    "    datax = np.array(datax)\n",
    "    datax = datax.reshape(n_tracks, res+1, 4)\n",
    "    datay = np.array(datay)\n",
    "    datay = datay.reshape(n_tracks, 1)\n",
    "    datafeat = np.array(datafeat)\n",
    "    datafeat = datafeat.reshape(n_tracks, len(feat))\n",
    "    result = [datax, datay]\n",
    "    if use_feat is True:\n",
    "        result += [datafeat]\n",
    "    return tuple(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(datax, datay, datafeat) = get_xy_data(fstats_tot, 'age', feat, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track(df, track, res):\n",
    "    return df.loc[(res+1)*(track):(res+1)*(track+1)-1]\n",
    "\n",
    "def get_feat(df, track, res, feat):\n",
    "    return df.loc[(res+1)*(track+1)-1, feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./saved_datasets/RNN_datax', datax)\n",
    "# np.save('./saved_datasets/RNN_datay', datay)\n",
    "# np.save('./saved_datasets/RNN_datafeat', datafeat)\n",
    "datax = np.load('./saved_datasets/RNN_datax.npy')\n",
    "datay = np.load('./saved_datasets/RNN_datay.npy')\n",
    "datafeat = np.load('./saved_datasets/RNN_datafeat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1010\n",
    "np.random.seed(seed)\n",
    "split = 0.8\n",
    "train_index = np.random.choice(np.arange(0, len(datax)), int(len(datax)*split), replace=False)\n",
    "test_index = np.setdiff1d(np.arange(0, len(datax)), train_index)\n",
    "datax = np.nan_to_num(datax, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "datay = np.nan_to_num(datay, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "datafeat = np.nan_to_num(datafeat, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "X_train = datax[train_index]\n",
    "y_train = datay[train_index]\n",
    "feat_train = datafeat[train_index]\n",
    "X_test = datax[test_index]\n",
    "y_test = datay[test_index]\n",
    "feat_test = datafeat[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41434, 651, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numpy_one_hot_encode(mat, encoder=None):\n",
    "    if encoder is None:\n",
    "        encoder = np.unique(mat)\n",
    "    mat = np.array(encoder == mat).astype(int)\n",
    "    return mat, encoder\n",
    "y_train, encoder = numpy_one_hot_encode(y_train)\n",
    "y_test, encoder = numpy_one_hot_encode(y_test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_decode(mat, encoder):\n",
    "    return np.array([i[i!=0] for i in mat * encoder])\n",
    "# y_train = numpy_decode(y_train, encoder)\n",
    "# y_test = numpy_decode(y_test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26452152, 14.82302878, -1.        , ...,  1.78059403,\n",
       "         0.34533962, -0.15742109],\n",
       "       [ 4.93337269, 12.36510785, -1.        , ...,  7.45517275,\n",
       "         0.42748064, -0.20779744],\n",
       "       [ 3.90237424,  1.30709157,  9.18849923, ...,  2.14101599,\n",
       "         0.80377365, -0.21617611],\n",
       "       ...,\n",
       "       [ 2.74396357, 10.80650455, 42.81441741, ...,  2.10793702,\n",
       "         0.51037026, -0.20056959],\n",
       "       [ 2.44894041,  9.81796146,  1.53650495, ...,  2.83867407,\n",
       "         0.16486803, -0.20086897],\n",
       "       [ 1.61204306, 10.97800038,  2.08129815, ...,  1.88583633,\n",
       "         0.10717225, -0.19117296]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, 4, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41434, 17)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, n_feat_size = feat_train.shape\n",
    "(n_samples, n_feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kera libraries\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Concatenate, Flatten, TimeDistributed\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM without dropout for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "def rnn_clsfy(X_train, y_train, n_timesteps, n_features, n_outputs, epochs=15, batch_size=64, verbose=0, **kwargs):\n",
    "    if 'dropout' not in kwargs:\n",
    "        dropout = 0.5\n",
    "    else:\n",
    "        dropout = kwargs['dropout']\n",
    "    if 'seed' not in kwargs:\n",
    "        seed = 123\n",
    "    else:\n",
    "        seed = kwargs['seed']\n",
    "    if 'metrics' not in kwargs:\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        metrics = kwargs['metrics']\n",
    "    if 'n_rnnnodes' not in kwargs:\n",
    "        n_rnnnodes = 100\n",
    "    else:\n",
    "        n_rnnnodes = kwargs['n_rnnnodes']\n",
    "    if 'n_nnnodes' not in kwargs:\n",
    "        n_rnnnodes = 100\n",
    "    else:\n",
    "        n_rnnnodes = kwargs['n_nnnodes']\n",
    "    if 'reg' not in kwargs:\n",
    "        reg = L1L2(l1=0.0, l2=0.0)\n",
    "    else:\n",
    "        reg = kwargs['reg']\n",
    "        \n",
    "    # create the model\n",
    "    numpy.random.seed(seed)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_rnnnodes, input_shape=(n_timesteps, n_features), bias_regularizer=reg, return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "                                    name='Adam', clipvalue=0.1)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metrics)\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.33)\n",
    "    # Final evaluation:\n",
    "    score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(f'Accuracy: {score[1]}')\n",
    "    return model, score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{score1[1]}, {score2[1]}, {score3[1]}, {score4[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 100)               42000     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 72,704\n",
      "Trainable params: 72,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 27760 samples, validate on 13674 samples\n",
      "Epoch 1/50\n",
      "27760/27760 [==============================] - 89s 3ms/sample - loss: 80.7668 - accuracy: 0.4285 - val_loss: 70.6538 - val_accuracy: 0.4710\n",
      "Epoch 2/50\n",
      "27760/27760 [==============================] - 95s 3ms/sample - loss: 61.8835 - accuracy: 0.4702 - val_loss: 53.5032 - val_accuracy: 0.4694\n",
      "Epoch 3/50\n",
      "27760/27760 [==============================] - 90s 3ms/sample - loss: 46.2645 - accuracy: 0.4748 - val_loss: 39.3804 - val_accuracy: 0.4737\n",
      "Epoch 4/50\n",
      "27760/27760 [==============================] - 104s 4ms/sample - loss: 33.4936 - accuracy: 0.4767 - val_loss: 27.9185 - val_accuracy: 0.4782\n",
      "Epoch 5/50\n",
      "27760/27760 [==============================] - 91s 3ms/sample - loss: 23.2030 - accuracy: 0.4788 - val_loss: 18.7700 - val_accuracy: 0.4767\n",
      "Epoch 6/50\n",
      "27760/27760 [==============================] - 93s 3ms/sample - loss: 15.0540 - accuracy: 0.4784 - val_loss: 11.6018 - val_accuracy: 0.4735\n",
      "Epoch 7/50\n",
      "27760/27760 [==============================] - 93s 3ms/sample - loss: 8.7350 - accuracy: 0.4796 - val_loss: 6.1080 - val_accuracy: 0.4539\n",
      "Epoch 8/50\n",
      "27760/27760 [==============================] - 102s 4ms/sample - loss: 3.9382 - accuracy: 0.4802 - val_loss: 1.9677 - val_accuracy: 0.4753\n",
      "Epoch 9/50\n",
      "27760/27760 [==============================] - 107s 4ms/sample - loss: 1.2843 - accuracy: 0.4793 - val_loss: 1.1895 - val_accuracy: 0.4748\n",
      "Epoch 10/50\n",
      "27760/27760 [==============================] - 110s 4ms/sample - loss: 1.1861 - accuracy: 0.4833 - val_loss: 1.2006 - val_accuracy: 0.4737\n",
      "Epoch 11/50\n",
      "27760/27760 [==============================] - 105s 4ms/sample - loss: 1.1872 - accuracy: 0.4819 - val_loss: 1.1833 - val_accuracy: 0.4833\n",
      "Epoch 12/50\n",
      "27760/27760 [==============================] - 121s 4ms/sample - loss: 1.1814 - accuracy: 0.4852 - val_loss: 1.1773 - val_accuracy: 0.4853\n",
      "Epoch 13/50\n",
      "27760/27760 [==============================] - 116s 4ms/sample - loss: 1.1765 - accuracy: 0.4899 - val_loss: 1.1730 - val_accuracy: 0.4881\n",
      "Epoch 14/50\n",
      "27760/27760 [==============================] - 121s 4ms/sample - loss: 1.1689 - accuracy: 0.4921 - val_loss: 1.1688 - val_accuracy: 0.4899\n",
      "Epoch 15/50\n",
      "27760/27760 [==============================] - 128s 5ms/sample - loss: 1.1672 - accuracy: 0.4901 - val_loss: 1.1690 - val_accuracy: 0.4821\n",
      "Epoch 16/50\n",
      "27760/27760 [==============================] - 105s 4ms/sample - loss: 1.1665 - accuracy: 0.4916 - val_loss: 1.1682 - val_accuracy: 0.4876\n",
      "Epoch 17/50\n",
      "27760/27760 [==============================] - 114s 4ms/sample - loss: 1.1656 - accuracy: 0.4916 - val_loss: 1.1614 - val_accuracy: 0.4934\n",
      "Epoch 18/50\n",
      "27760/27760 [==============================] - 26s 929us/sample - loss: 1.1635 - accuracy: 0.4928 - val_loss: 1.1609 - val_accuracy: 0.4922\n",
      "Epoch 19/50\n",
      "27760/27760 [==============================] - 11s 398us/sample - loss: 1.1641 - accuracy: 0.4959 - val_loss: 1.1576 - val_accuracy: 0.4950\n",
      "Epoch 20/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1620 - accuracy: 0.4924 - val_loss: 1.1624 - val_accuracy: 0.4892\n",
      "Epoch 21/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1601 - accuracy: 0.4954 - val_loss: 1.1644 - val_accuracy: 0.4879\n",
      "Epoch 22/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1625 - accuracy: 0.4938 - val_loss: 1.1614 - val_accuracy: 0.4926\n",
      "Epoch 23/50\n",
      "27760/27760 [==============================] - 11s 390us/sample - loss: 1.1591 - accuracy: 0.4949 - val_loss: 1.1672 - val_accuracy: 0.4830\n",
      "Epoch 24/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1606 - accuracy: 0.4967 - val_loss: 1.1613 - val_accuracy: 0.4914\n",
      "Epoch 25/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1607 - accuracy: 0.4981 - val_loss: 1.1622 - val_accuracy: 0.4905\n",
      "Epoch 26/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1589 - accuracy: 0.4981 - val_loss: 1.1732 - val_accuracy: 0.4898\n",
      "Epoch 27/50\n",
      "27760/27760 [==============================] - 11s 392us/sample - loss: 1.1595 - accuracy: 0.4959 - val_loss: 1.1659 - val_accuracy: 0.4910\n",
      "Epoch 28/50\n",
      "27760/27760 [==============================] - 11s 389us/sample - loss: 1.1592 - accuracy: 0.4967 - val_loss: 1.1554 - val_accuracy: 0.4977\n",
      "Epoch 29/50\n",
      "27760/27760 [==============================] - 11s 388us/sample - loss: 1.1569 - accuracy: 0.4973 - val_loss: 1.1633 - val_accuracy: 0.4988\n",
      "Epoch 30/50\n",
      "27760/27760 [==============================] - 11s 390us/sample - loss: 1.1557 - accuracy: 0.4986 - val_loss: 1.1610 - val_accuracy: 0.5004\n",
      "Epoch 31/50\n",
      "27760/27760 [==============================] - 11s 388us/sample - loss: 1.1552 - accuracy: 0.4981 - val_loss: 1.1748 - val_accuracy: 0.4826\n",
      "Epoch 32/50\n",
      "27760/27760 [==============================] - 11s 388us/sample - loss: 1.1571 - accuracy: 0.5000 - val_loss: 1.1682 - val_accuracy: 0.4933\n",
      "Epoch 33/50\n",
      "27760/27760 [==============================] - 11s 390us/sample - loss: 1.1572 - accuracy: 0.4988 - val_loss: 1.1581 - val_accuracy: 0.4966\n",
      "Epoch 34/50\n",
      "27760/27760 [==============================] - 11s 389us/sample - loss: 1.1556 - accuracy: 0.5004 - val_loss: 1.1565 - val_accuracy: 0.4999\n",
      "Epoch 35/50\n",
      "27760/27760 [==============================] - 11s 389us/sample - loss: 1.1545 - accuracy: 0.5016 - val_loss: 1.1563 - val_accuracy: 0.4981\n",
      "Epoch 36/50\n",
      "27760/27760 [==============================] - 11s 396us/sample - loss: 1.1556 - accuracy: 0.5000 - val_loss: 1.1540 - val_accuracy: 0.4982\n",
      "Epoch 37/50\n",
      "27760/27760 [==============================] - 11s 394us/sample - loss: 1.1536 - accuracy: 0.5014 - val_loss: 1.1561 - val_accuracy: 0.4978\n",
      "Epoch 38/50\n",
      "27760/27760 [==============================] - 11s 394us/sample - loss: 1.1548 - accuracy: 0.5006 - val_loss: 1.1590 - val_accuracy: 0.4977\n",
      "Epoch 39/50\n",
      "27760/27760 [==============================] - 11s 392us/sample - loss: 1.1516 - accuracy: 0.5050 - val_loss: 1.1533 - val_accuracy: 0.4999\n",
      "Epoch 40/50\n",
      "27760/27760 [==============================] - 11s 394us/sample - loss: 1.1511 - accuracy: 0.5049 - val_loss: 1.1589 - val_accuracy: 0.4982\n",
      "Epoch 41/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1520 - accuracy: 0.5022 - val_loss: 1.1599 - val_accuracy: 0.4963\n",
      "Epoch 42/50\n",
      "27760/27760 [==============================] - 11s 391us/sample - loss: 1.1504 - accuracy: 0.5015 - val_loss: 1.1670 - val_accuracy: 0.4939\n",
      "Epoch 43/50\n",
      "27760/27760 [==============================] - 11s 392us/sample - loss: 1.1517 - accuracy: 0.5050 - val_loss: 1.1542 - val_accuracy: 0.5023\n",
      "Epoch 44/50\n",
      "27760/27760 [==============================] - 11s 392us/sample - loss: 1.1513 - accuracy: 0.5027 - val_loss: 1.1559 - val_accuracy: 0.4984\n",
      "Epoch 45/50\n",
      "27760/27760 [==============================] - 11s 394us/sample - loss: 1.1477 - accuracy: 0.5093 - val_loss: 1.1565 - val_accuracy: 0.4978\n",
      "Epoch 46/50\n",
      "27760/27760 [==============================] - 11s 395us/sample - loss: 1.1481 - accuracy: 0.5057 - val_loss: 1.1596 - val_accuracy: 0.4938\n",
      "Epoch 47/50\n",
      "27760/27760 [==============================] - 11s 395us/sample - loss: 1.1512 - accuracy: 0.5037 - val_loss: 1.1579 - val_accuracy: 0.4955\n",
      "Epoch 48/50\n",
      "27760/27760 [==============================] - 11s 401us/sample - loss: 1.1497 - accuracy: 0.5036 - val_loss: 1.1612 - val_accuracy: 0.4952\n",
      "Epoch 49/50\n",
      "27760/27760 [==============================] - 11s 394us/sample - loss: 1.1490 - accuracy: 0.5043 - val_loss: 1.1567 - val_accuracy: 0.4982\n",
      "Epoch 50/50\n",
      "27760/27760 [==============================] - 11s 392us/sample - loss: 1.1500 - accuracy: 0.5026 - val_loss: 1.1682 - val_accuracy: 0.4992\n",
      "Accuracy: 0.4969591796398163\n",
      "WARNING:tensorflow:From C:\\Users\\david\\.conda\\envs\\tf-gpu-2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: .\\saved_models\\LSTM_RNN_MODEL_0.8_SPLIT_P14_P21_P28_P35_TARGET_AUG0220_DATE_50_EPOCHS_175_batch_0.0_DROPOUT_0.4_L1_0.5_L2_10_seed_SHACK\\assets\n"
     ]
    }
   ],
   "source": [
    "split = split\n",
    "epochs = 50\n",
    "batch_size = 175\n",
    "verbose = 0\n",
    "dropout = 0.0\n",
    "seed = 10\n",
    "l1 = 0.40\n",
    "l2 = 0.50\n",
    "reg = L1L2(l1=l1, l2=l2)\n",
    "DATE = 'AUG0220'\n",
    "name = 'SHACK'\n",
    "\n",
    "model1, score1 = rnn_clsfy(X_train, y_train, n_timesteps, n_features, n_outputs, epochs=epochs, batch_size=batch_size, verbose=0, dropout=dropout, seed=seed, metrics = ['accuracy'], reg=reg)\n",
    "model1.save(f'.\\saved_models\\LSTM_RNN_MODEL_{split}_SPLIT_P14_P21_P28_P35_TARGET_{DATE}_DATE_{epochs}_EPOCHS_{batch_size}_batch_{dropout}_DROPOUT_{l1}_L1_{l2}_L2_{seed}_seed_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('.\\saved_models\\LSTM_RNN_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_AUG0120_DATE_250_EPOCHS_100_batch_40_DROPOUT_0.00_L1_0.10_L2_100_batch_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 100)               42000     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 52,504\n",
      "Trainable params: 52,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_clsfy_aux(X_train, aux_train, y_train, n_timesteps, n_features, n_outputs, n_feat_size, epochs=15, dropout=0.4, batch_size=64, verbose=0, **kwargs):\n",
    "    if 'dropout' not in kwargs:\n",
    "        dropout = 0.0\n",
    "    else:\n",
    "        dropout = kwargs['dropout']\n",
    "    if 'seed' not in kwargs:\n",
    "        seed = 123\n",
    "    else:\n",
    "        seed = kwargs['seed']\n",
    "    if 'metrics' not in kwargs:\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        metrics = kwargs['metrics']\n",
    "    if 'n_rnnnodes' not in kwargs:\n",
    "        n_rnnnodes = 100\n",
    "    else:\n",
    "        n_rnnnodes = kwargs['n_rnnnodes']\n",
    "    if 'reg' not in kwargs:\n",
    "        reg = L1L2(l1=0.0, l2=0.0)\n",
    "    else:\n",
    "        reg = kwargs['reg']\n",
    "\n",
    "    t_input = Input(shape=(n_timesteps, n_features), dtype='float32', name='TimeSeries')\n",
    "    aux_input = Input(shape=(n_feat_size), dtype='float32', name='SpatialFeatures')\n",
    "    \n",
    "    lstm = LSTM(n_rnnnodes, bias_regularizer=reg, return_sequences=False)(t_input) # First LSTM value\n",
    "    drpout = Dropout(dropout)(lstm)\n",
    "    dense = Dense(100, activation='tanh')(drpout)\n",
    "    \n",
    "    input_2 = Dense(100, activation='sigmoid')(aux_input)\n",
    "    \n",
    "    merge = Concatenate()([dense, input_2]) # add merge 1 here\n",
    "    \n",
    "    \n",
    "    hidden = Dense(100, activation='sigmoid')(merge)\n",
    "    hidden = Dense(100, activation='sigmoid')(hidden)\n",
    "    hidden = Dense(100, activation='sigmoid')(hidden)\n",
    "    hidden = Dense(100, activation='sigmoid')(hidden)\n",
    "    output = Dense(n_outputs, activation='softmax')(hidden)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "                                    name='Adam', clipvalue=0.1)\n",
    "    \n",
    "    model = Model(inputs=[t_input, aux_input], outputs = output)\n",
    "    model.compile(loss='kullback_leibler_divergence', optimizer=opt, metrics=metrics)\n",
    "    print(model.summary())\n",
    "    model.fit([X_train, aux_train], y_train, epochs=epochs, batch_size=batch_size, validation_split=0.33)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TimeSeries (InputLayer)         [(None, 651, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_53 (LSTM)                  (None, 300)          366000      TimeSeries[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 300)          0           lstm_53[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "SpatialFeatures (InputLayer)    [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_221 (Dense)               (None, 100)          30100       dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_222 (Dense)               (None, 100)          1800        SpatialFeatures[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 200)          0           dense_221[0][0]                  \n",
      "                                                                 dense_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_223 (Dense)               (None, 100)          20100       concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_224 (Dense)               (None, 100)          10100       dense_223[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_225 (Dense)               (None, 100)          10100       dense_224[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_226 (Dense)               (None, 100)          10100       dense_225[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_227 (Dense)               (None, 4)            404         dense_226[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 448,704\n",
      "Trainable params: 448,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 27760 samples, validate on 13674 samples\n",
      "Epoch 1/50\n",
      "27760/27760 [==============================] - 51s 2ms/sample - loss: 234.8627 - accuracy: 0.4620 - val_loss: 200.1471 - val_accuracy: 0.4820\n",
      "Epoch 2/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 170.6658 - accuracy: 0.4891 - val_loss: 142.7547 - val_accuracy: 0.4826\n",
      "Epoch 3/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 119.3397 - accuracy: 0.4873 - val_loss: 97.3109 - val_accuracy: 0.4865\n",
      "Epoch 4/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 79.0604 - accuracy: 0.4907 - val_loss: 62.0379 - val_accuracy: 0.4838\n",
      "Epoch 5/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 48.1453 - accuracy: 0.4914 - val_loss: 35.2990 - val_accuracy: 0.4866\n",
      "Epoch 6/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 25.0239 - accuracy: 0.4912 - val_loss: 15.6091 - val_accuracy: 0.4887\n",
      "Epoch 7/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 8.2544 - accuracy: 0.4938 - val_loss: 1.5941 - val_accuracy: 0.4863\n",
      "Epoch 8/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 1.2083 - accuracy: 0.4948 - val_loss: 1.1860 - val_accuracy: 0.4893\n",
      "Epoch 9/50\n",
      "27760/27760 [==============================] - 49s 2ms/sample - loss: 1.1994 - accuracy: 0.4943 - val_loss: 1.2056 - val_accuracy: 0.4917\n",
      "Epoch 10/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.2030 - accuracy: 0.4951 - val_loss: 1.2065 - val_accuracy: 0.4889\n",
      "Epoch 11/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 1.2030 - accuracy: 0.4941 - val_loss: 1.2076 - val_accuracy: 0.4924\n",
      "Epoch 12/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.2032 - accuracy: 0.4990 - val_loss: 1.2042 - val_accuracy: 0.4931\n",
      "Epoch 13/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.2006 - accuracy: 0.4951 - val_loss: 1.2113 - val_accuracy: 0.4866\n",
      "Epoch 14/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.2012 - accuracy: 0.4959 - val_loss: 1.2036 - val_accuracy: 0.4879\n",
      "Epoch 15/50\n",
      "27760/27760 [==============================] - 46s 2ms/sample - loss: 1.2016 - accuracy: 0.4969 - val_loss: 1.2012 - val_accuracy: 0.4948\n",
      "Epoch 16/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.2017 - accuracy: 0.4992 - val_loss: 1.2058 - val_accuracy: 0.4929\n",
      "Epoch 17/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.2016 - accuracy: 0.4973 - val_loss: 1.2030 - val_accuracy: 0.4923\n",
      "Epoch 18/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1982 - accuracy: 0.4995 - val_loss: 1.2032 - val_accuracy: 0.4892\n",
      "Epoch 19/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1973 - accuracy: 0.5001 - val_loss: 1.2107 - val_accuracy: 0.4862\n",
      "Epoch 20/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 1.1966 - accuracy: 0.4995 - val_loss: 1.2116 - val_accuracy: 0.4849\n",
      "Epoch 21/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1963 - accuracy: 0.4999 - val_loss: 1.2056 - val_accuracy: 0.4884\n",
      "Epoch 22/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1980 - accuracy: 0.4981 - val_loss: 1.2003 - val_accuracy: 0.4943\n",
      "Epoch 23/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1965 - accuracy: 0.5002 - val_loss: 1.2002 - val_accuracy: 0.4965\n",
      "Epoch 24/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1937 - accuracy: 0.5017 - val_loss: 1.2048 - val_accuracy: 0.4882\n",
      "Epoch 25/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1942 - accuracy: 0.5027 - val_loss: 1.1993 - val_accuracy: 0.4941\n",
      "Epoch 26/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1928 - accuracy: 0.5043 - val_loss: 1.1983 - val_accuracy: 0.4954\n",
      "Epoch 27/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1919 - accuracy: 0.5045 - val_loss: 1.2011 - val_accuracy: 0.4939\n",
      "Epoch 28/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 1.1915 - accuracy: 0.5042 - val_loss: 1.2026 - val_accuracy: 0.4898\n",
      "Epoch 29/50\n",
      "27760/27760 [==============================] - 46s 2ms/sample - loss: 1.1926 - accuracy: 0.5036 - val_loss: 1.1997 - val_accuracy: 0.4944\n",
      "Epoch 30/50\n",
      "27760/27760 [==============================] - 49s 2ms/sample - loss: 1.1905 - accuracy: 0.5057 - val_loss: 1.1964 - val_accuracy: 0.4946\n",
      "Epoch 31/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 1.1912 - accuracy: 0.5044 - val_loss: 1.1976 - val_accuracy: 0.4982\n",
      "Epoch 32/50\n",
      "27760/27760 [==============================] - 46s 2ms/sample - loss: 1.1885 - accuracy: 0.5070 - val_loss: 1.1980 - val_accuracy: 0.4979\n",
      "Epoch 33/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1876 - accuracy: 0.5072 - val_loss: 1.2028 - val_accuracy: 0.4978\n",
      "Epoch 34/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 1.1884 - accuracy: 0.5061 - val_loss: 1.1983 - val_accuracy: 0.4966\n",
      "Epoch 35/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1861 - accuracy: 0.5085 - val_loss: 1.2041 - val_accuracy: 0.5019\n",
      "Epoch 36/50\n",
      "27760/27760 [==============================] - 46s 2ms/sample - loss: 1.1850 - accuracy: 0.5103 - val_loss: 1.1935 - val_accuracy: 0.4989\n",
      "Epoch 37/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1831 - accuracy: 0.5098 - val_loss: 1.2047 - val_accuracy: 0.4952\n",
      "Epoch 38/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1851 - accuracy: 0.5103 - val_loss: 1.1957 - val_accuracy: 0.4987\n",
      "Epoch 39/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1838 - accuracy: 0.5101 - val_loss: 1.1987 - val_accuracy: 0.5009\n",
      "Epoch 40/50\n",
      "27760/27760 [==============================] - 49s 2ms/sample - loss: 1.1837 - accuracy: 0.5100 - val_loss: 1.2006 - val_accuracy: 0.4922\n",
      "Epoch 41/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1910 - accuracy: 0.5031 - val_loss: 1.2023 - val_accuracy: 0.4955\n",
      "Epoch 42/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1871 - accuracy: 0.5079 - val_loss: 1.1981 - val_accuracy: 0.4961\n",
      "Epoch 43/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1873 - accuracy: 0.5044 - val_loss: 1.2022 - val_accuracy: 0.4971\n",
      "Epoch 44/50\n",
      "27760/27760 [==============================] - 48s 2ms/sample - loss: 1.1868 - accuracy: 0.5071 - val_loss: 1.2036 - val_accuracy: 0.4969\n",
      "Epoch 45/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1828 - accuracy: 0.5093 - val_loss: 1.2042 - val_accuracy: 0.4939\n",
      "Epoch 46/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1839 - accuracy: 0.5112 - val_loss: 1.2013 - val_accuracy: 0.4964\n",
      "Epoch 47/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1818 - accuracy: 0.5117 - val_loss: 1.2120 - val_accuracy: 0.4933\n",
      "Epoch 48/50\n",
      "27760/27760 [==============================] - 46s 2ms/sample - loss: 1.1827 - accuracy: 0.5109 - val_loss: 1.1972 - val_accuracy: 0.4992\n",
      "Epoch 49/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1820 - accuracy: 0.5096 - val_loss: 1.1943 - val_accuracy: 0.4988\n",
      "Epoch 50/50\n",
      "27760/27760 [==============================] - 47s 2ms/sample - loss: 1.1799 - accuracy: 0.5107 - val_loss: 1.1990 - val_accuracy: 0.4955\n",
      "Accuracy: 0.5011101365089417\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "model1 = rnn_clsfy_aux(X_train, feat_train, y_train, n_timesteps, n_features, n_outputs, n_feat_size, n_rnnnodes=300, epochs=50, batch_size=150, verbose=0, dropout=0.4, seed=1, metrics = ['accuracy'], reg=L1L2(l1=0.40, l2=0.50))\n",
    "score = model1.evaluate([X_test, feat_test], y_test, batch_size=100, verbose=0)\n",
    "print(f'Accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = rnn_clsfy_aux(X_train, feat_train, y_train, n_timesteps, n_features, n_outputs, n_feat_size, n_rnnnodes=300, epochs=50, batch_size=150, verbose=0, dropout=0.4, seed=1, metrics = ['accuracy'], reg=L1L2(l1=0.40, l2=0.50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5057438015937805\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate([X_test, feat_test], y_test, batch_size=100, verbose=0)\n",
    "print(f'Accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\saved_models\\LSTM_AUX_RNN_MODEL_0.8_SPLIT_P14_P21_P28_P35_TARGET_AUG0220_DATE_50_EPOCHS_150_batch_0.4_DROPOUT_0.4_L1_0.5_L2_10_seed_SHACK\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save(f'.\\saved_models\\LSTM_AUX_RNN_MODEL_{split}_SPLIT_P14_P21_P28_P35_TARGET_{DATE}_DATE_{epochs}_EPOCHS_{150}_batch_{0.4}_DROPOUT_{l1}_L1_{l2}_L2_{seed}_seed_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model2\n",
    "acc2 = []\n",
    "for i in range(50):\n",
    "    seed = 1010\n",
    "    np.random.seed(seed)\n",
    "    datax = np.load('./saved_datasets/RNN_datax.npy')\n",
    "    datay = np.load('./saved_datasets/RNN_datay.npy')\n",
    "    datafeat = np.load('./saved_datasets/RNN_datafeat.npy')\n",
    "    split = 0.8\n",
    "    train_index = np.random.choice(np.arange(0, len(datax)), int(len(datax)*split), replace=False)\n",
    "    test_val_index = np.setdiff1d(np.arange(0, len(datax)), train_index)\n",
    "    seed+=i\n",
    "    np.random.seed(seed)\n",
    "    test_index = np.random.choice(test_val_index, int(len(test_val_index)*0.25), replace=False)\n",
    "    datax = np.nan_to_num(datax, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "    datay = np.nan_to_num(datay, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "    datafeat = np.nan_to_num(datafeat, copy=True, nan=-1.0, posinf=-1.0, neginf=-1.0)\n",
    "    X_train = datax[train_index]\n",
    "    y_train = datay[train_index]\n",
    "    feat_train = datafeat[train_index]\n",
    "    X_test = datax[test_index]\n",
    "    y_test = datay[test_index]\n",
    "    feat_test = datafeat[test_index]\n",
    "    y_test, encoder = numpy_one_hot_encode(y_test, encoder)\n",
    "#     ypred1 = mod.predict(X_test, batch_size = 100)\n",
    "    ypred1 = mod.predict([X_test, feat_test], batch_size = 100)\n",
    "    pred=np.array([x == np.max(x) for x in ypred1]).astype(int)\n",
    "    y_true = numpy_decode(y_test, encoder)\n",
    "    y_pred = numpy_decode(pred, encoder)\n",
    "    acc2.append(metrics.accuracy_score(y_true, y_pred))\n",
    "acc2 = np.array(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4991425260718424"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01080506083180325"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48821939, 0.50405562, 0.50714562, 0.50405562, 0.49092314,\n",
       "       0.50019312, 0.49903438, 0.51178061, 0.49324063, 0.50521437,\n",
       "       0.50560062, 0.5210506 , 0.50444187, 0.51062186, 0.51371186,\n",
       "       0.49285438, 0.49826188, 0.47315566, 0.49555813, 0.49517188,\n",
       "       0.49864813, 0.48744689, 0.50521437, 0.50289687, 0.49092314,\n",
       "       0.50521437, 0.48551564, 0.51448436, 0.4789494 , 0.48397065,\n",
       "       0.50753187, 0.49439938, 0.49710313, 0.48783314, 0.49748938,\n",
       "       0.49517188, 0.48010815, 0.5195056 , 0.50019312, 0.49710313,\n",
       "       0.48010815, 0.51564311, 0.50251062, 0.50289687, 0.5171881 ,\n",
       "       0.51255311, 0.50057937, 0.49169564, 0.49092314, 0.49903438])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.506882966396292"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009287173461871377"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50057937, 0.50830436, 0.50405562, 0.51371186, 0.49130939,\n",
       "       0.49826188, 0.50869061, 0.51602935, 0.50289687, 0.51487061,\n",
       "       0.51911935, 0.5225956 , 0.51139436, 0.5195056 , 0.51448436,\n",
       "       0.50598687, 0.51834685, 0.48667439, 0.49942063, 0.50212437,\n",
       "       0.50482812, 0.50096562, 0.5187331 , 0.51216686, 0.49671688,\n",
       "       0.50984936, 0.49980688, 0.51834685, 0.48860564, 0.50366937,\n",
       "       0.50560062, 0.49517188, 0.50289687, 0.50753187, 0.49748938,\n",
       "       0.50714562, 0.48976439, 0.51564311, 0.5179606 , 0.50212437,\n",
       "       0.49903438, 0.51834685, 0.50791812, 0.50444187, 0.52375435,\n",
       "       0.52298185, 0.50869061, 0.50444187, 0.49594438, 0.50521437])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 100)               42000     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 72,704\n",
      "Trainable params: 72,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TimeSeries (InputLayer)         [(None, 651, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_47 (LSTM)                  (None, 300)          366000      TimeSeries[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 300)          0           lstm_47[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_188 (Dense)               (None, 100)          30100       dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "SpatialFeatures (InputLayer)    [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 117)          0           dense_188[0][0]                  \n",
      "                                                                 SpatialFeatures[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_189 (Dense)               (None, 100)          11800       concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_190 (Dense)               (None, 100)          10100       dense_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_191 (Dense)               (None, 4)            404         dense_190[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 418,404\n",
      "Trainable params: 418,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [[0.48821939, 0.50405562, 0.50714562, 0.50405562, 0.49092314,\n",
    "         0.50019312, 0.49903438, 0.51178061, 0.49324063, 0.50521437,\n",
    "         0.50560062, 0.5210506 , 0.50444187, 0.51062186, 0.51371186,\n",
    "         0.49285438, 0.49826188, 0.47315566, 0.49555813, 0.49517188,\n",
    "         0.49864813, 0.48744689, 0.50521437, 0.50289687, 0.49092314,\n",
    "         0.50521437, 0.48551564, 0.51448436, 0.4789494 , 0.48397065,\n",
    "         0.50753187, 0.49439938, 0.49710313, 0.48783314, 0.49748938,\n",
    "         0.49517188, 0.48010815, 0.5195056 , 0.50019312, 0.49710313,\n",
    "         0.48010815, 0.51564311, 0.50251062, 0.50289687, 0.5171881 ,\n",
    "         0.51255311, 0.50057937, 0.49169564, 0.49092314, 0.49903438],\n",
    "        [0.50057937, 0.50830436, 0.50405562, 0.51371186, 0.49130939,\n",
    "         0.49826188, 0.50869061, 0.51602935, 0.50289687, 0.51487061,\n",
    "         0.51911935, 0.5225956 , 0.51139436, 0.5195056 , 0.51448436,\n",
    "         0.50598687, 0.51834685, 0.48667439, 0.49942063, 0.50212437,\n",
    "         0.50482812, 0.50096562, 0.5187331 , 0.51216686, 0.49671688,\n",
    "         0.50984936, 0.49980688, 0.51834685, 0.48860564, 0.50366937,\n",
    "         0.50560062, 0.49517188, 0.50289687, 0.50753187, 0.49748938,\n",
    "         0.50714562, 0.48976439, 0.51564311, 0.5179606 , 0.50212437,\n",
    "         0.49903438, 0.51834685, 0.50791812, 0.50444187, 0.52375435,\n",
    "         0.52298185, 0.50869061, 0.50444187, 0.49594438, 0.50521437],\n",
    "        [0.55100049, 0.54367984, 0.54742151, 0.54693346, 0.54807223,\n",
    "         0.5457947 , 0.54075159, 0.53570848, 0.54026354, 0.54156499,\n",
    "         0.54807223, 0.54823491, 0.54725883, 0.53749797, 0.55360338,\n",
    "         0.54725883, 0.5397755 , 0.55897186, 0.54286644, 0.54693346,\n",
    "         0.55148853, 0.55116317, 0.53879941, 0.54888564, 0.54856027,\n",
    "         0.54742151, 0.53619652, 0.54449325, 0.54514397, 0.54709614,\n",
    "         0.54042622, 0.55116317, 0.54189035, 0.54335448, 0.53733529,\n",
    "         0.54872295, 0.54725883, 0.54367984, 0.54986172, 0.54725883,\n",
    "         0.55100049, 0.54270376, 0.54270376, 0.54774687, 0.54969904,\n",
    "         0.54433057, 0.54286644, 0.54546933, 0.54742151, 0.54286644],\n",
    "        [0.52968928, 0.53196681, 0.53261754, 0.5329429 , 0.53554579,\n",
    "         0.53261754, 0.5295266 , 0.52301936, 0.53391898, 0.52838783,\n",
    "         0.52838783, 0.53505775, 0.53245486, 0.52367008, 0.54140231,\n",
    "         0.53131609, 0.53017732, 0.54107695, 0.52936392, 0.53034   ,\n",
    "         0.53766065, 0.53749797, 0.52562225, 0.54091427, 0.53619652,\n",
    "         0.54107695, 0.52155523, 0.52773711, 0.52741175, 0.54058891,\n",
    "         0.52562225, 0.53814869, 0.53619652, 0.52757443, 0.51846429,\n",
    "         0.53456971, 0.5329429 , 0.52545957, 0.53863673, 0.53456971,\n",
    "         0.53684724, 0.53310558, 0.53066537, 0.53391898, 0.53131609,\n",
    "         0.52659834, 0.53229218, 0.53001464, 0.53798601, 0.52659834]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Performance of Predictive Models')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "# figure = plt.figure(figsize=(10,8))\n",
    "# Make the figures big enough for the optically challenged.\n",
    "#pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "# We start by making a copy of the original data frame, minus the sex attribute.\n",
    "#replot\n",
    "\n",
    "# plt.xticks([1, 2, 3, 4], ['Regular\\nLSTM', 'Modified LSTM', 'XGBoost', 'Random Forest'],ha='right')\n",
    "\n",
    "# Create a figure instance\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "# Create an axes instance\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Create the boxplot\n",
    "bp = ax.boxplot(accs)\n",
    "\n",
    "for box in bp['boxes']:\n",
    "    # change outline color\n",
    "    box.set(linewidth=2, color='#4169E1')\n",
    "    # change fill color\n",
    "#     box.set( facecolor = '#1b9e77' )\n",
    "\n",
    "## change color and linewidth of the whiskers\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(linewidth=2, color='#4169E1', linestyle='--')\n",
    "\n",
    "## change color and linewidth of the caps\n",
    "for cap in bp['caps']:\n",
    "    cap.set(linewidth=2, color='#4169E1')\n",
    "\n",
    "## change color and linewidth of the medians\n",
    "for median in bp['medians']:\n",
    "    median.set(linewidth=2)\n",
    "\n",
    "## change the style of fliers and their fill\n",
    "for flier in bp['fliers']:\n",
    "    flier.set(marker='o',alpha=0.5)\n",
    "    \n",
    "ax.set_xticklabels(['Regular\\nLSTM', 'Modified\\nLSTM', 'XGBoost', 'Random\\nForest'])\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left()\n",
    "plt.rc('font', size=10)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('axes', titlesize=20)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=12)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "\n",
    "plt.ylabel((\"Accuracy\"))\n",
    "plt.title('Accuracy Performance of Predictive Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = model1.predict(X_test, batch_size=100, verbose=0)\n",
    "pred=np.array([x == np.max(x) for x in ypred1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         P14     0.3629    0.1461    0.2083       308\n",
      "         P21     0.5007    0.6540    0.5672      1078\n",
      "         P28     0.0000    0.0000    0.0000       298\n",
      "         P35     0.5279    0.6166    0.5688       905\n",
      "\n",
      "    accuracy                         0.5052      2589\n",
      "   macro avg     0.3479    0.3542    0.3361      2589\n",
      "weighted avg     0.4362    0.5052    0.4598      2589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\.conda\\envs\\tf-gpu-2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class_names = ['P14', 'P21', 'P28', 'P35']\n",
    "y_true = numpy_decode(y_test, encoder)\n",
    "y_pred = numpy_decode(pred, encoder)\n",
    "class_results = classification_report(y_true, y_pred, digits=4, target_names = ['P14', 'P21', 'P28', 'P35'])\n",
    "print(str(class_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2572"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33153,  6843, 35039, ..., 23063, 29869, 33693])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(test_index, int(len(test_index)*0.5), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = py.figure(figsize=(18,5))\n",
    "ax = f.add_subplot(121)\n",
    "ax.plot(model1.history.history['loss'], label='train')\n",
    "ax.plot(model1.history.history['val_loss'], label='test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.set_title('Loss Function vs. Epochs')\n",
    "\n",
    "ax2 = f.add_subplot(122)\n",
    "ax2.plot(model1.history.history['accuracy'], label='train')\n",
    "ax2.plot(model1.history.history['val_accuracy'], label='test')\n",
    "ax2.legend()\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_xlabel('Number of Epochs')\n",
    "ax2.set_title('Accuracy vs. Epochs')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.\\saved_models\\LSTM_RNN_AUX_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_AUG0120_DATE_250_EPOCHS_40_DROPOUT_0.00_L1_0.10_L2_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('.\\saved_models\\LSTM_RNN_AUX_MODEL_80_20_SPLIT_P14_P21_P28_P35_TARGET_AUG0120_DATE_250_EPOCHS_40_DROPOUT_0.00_L1_0.10_L2_SHACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for filename in filenames:\n",
    "    if tag:\n",
    "        file_tag = next(tag)\n",
    "    else:\n",
    "        file_tag = None\n",
    "    try:\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        print(file_path)\n",
    "        file_data = pd.read_csv(file_path, encoding = \"utf-8\", delimiter = 'sep')\n",
    "        if file_tag:\n",
    "            size = file_data.shape[0]\n",
    "            file_data['Tag'] = pd.Series(size*[file_tag], index=file_data.index)\n",
    "        data = pd.concat([data, file_data])\n",
    "    except IOError as err:\n",
    "        print(f'Skipped!: {filename} {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 64)      64000       input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 64)      64000       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 200)          212000      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 200)          212000      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500)          0           concatenate[0][0]                \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 40)           20040       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 40)           1640        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            41          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 573,721\n",
      "Trainable params: 573,721\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x2eac3c88b08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_clsfy(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import MAX_NB_VARIABLES, MAX_TIMESTEPS_LIST\n",
    "from utils.generic_utils import load_dataset_at, calculate_dataset_metrics, cutoff_choice, \\\n",
    "    cutoff_sequence\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Permute\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "def multi_label_log_loss(y_pred, y_true):\n",
    "    return K.sum(K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "\n",
    "\n",
    "def _average_gradient_norm(model, X_train, y_train, batch_size):\n",
    "    # just checking if the model was already compiled\n",
    "    if not hasattr(model, \"train_function\"):\n",
    "        raise RuntimeError(\"You must compile your model before using it.\")\n",
    "\n",
    "    weights = model.trainable_weights  # weight tensors\n",
    "\n",
    "    get_gradients = model.optimizer.get_gradients(\n",
    "        model.total_loss, weights)  # gradient tensors\n",
    "\n",
    "    input_tensors = [\n",
    "        # input data\n",
    "        model.inputs[0],\n",
    "        # how much to weight each sample by\n",
    "        model.sample_weights[0],\n",
    "        # labels\n",
    "        model.targets[0],\n",
    "        # train or test mode\n",
    "        K.learning_phase()\n",
    "    ]\n",
    "\n",
    "    grad_fct = K.function(inputs=input_tensors, outputs=get_gradients)\n",
    "\n",
    "    steps = 0\n",
    "    total_norm = 0\n",
    "    s_w = None\n",
    "\n",
    "    nb_steps = X_train.shape[0] // batch_size\n",
    "\n",
    "    if X_train.shape[0] % batch_size == 0:\n",
    "        pad_last = False\n",
    "    else:\n",
    "        pad_last = True\n",
    "\n",
    "    def generator(X_train, y_train, pad_last):\n",
    "        for i in range(nb_steps):\n",
    "            X = X_train[i * batch_size: (i + 1) * batch_size, ...]\n",
    "            y = y_train[i * batch_size: (i + 1) * batch_size, ...]\n",
    "\n",
    "            yield (X, y)\n",
    "\n",
    "        if pad_last:\n",
    "            X = X_train[nb_steps * batch_size:, ...]\n",
    "            y = y_train[nb_steps * batch_size:, ...]\n",
    "\n",
    "            yield (X, y)\n",
    "\n",
    "    datagen = generator(X_train, y_train, pad_last)\n",
    "\n",
    "    while steps < nb_steps:\n",
    "        X, y = next(datagen)\n",
    "        # set sample weights to one\n",
    "        # for every input\n",
    "        if s_w is None:\n",
    "            s_w = np.ones(X.shape[0])\n",
    "\n",
    "        gradients = grad_fct([X, s_w, y, 0])\n",
    "        total_norm += np.sqrt(np.sum([np.sum(np.square(g))\n",
    "                                      for g in gradients]))\n",
    "        steps += 1\n",
    "\n",
    "    if pad_last:\n",
    "        X, y = next(datagen)\n",
    "        # set sample weights to one\n",
    "        # for every input\n",
    "        if s_w is None:\n",
    "            s_w = np.ones(X.shape[0])\n",
    "\n",
    "        gradients = grad_fct([X, s_w, y, 0])\n",
    "        total_norm += np.sqrt(np.sum([np.sum(np.square(g))\n",
    "                                      for g in gradients]))\n",
    "        steps += 1\n",
    "\n",
    "    return total_norm / float(steps)\n",
    "\n",
    "\n",
    "def rnn_train_model(model: Model, \n",
    "                    train_dataset, \n",
    "                    eval_dataset,\n",
    "                    folds=5, \n",
    "                    epochs=50, \n",
    "                    batch_size=128, \n",
    "                    val_subset=None,\n",
    "                    cutoff=None,  \n",
    "                    learning_rate=1e-3, \n",
    "                    monitor='loss', \n",
    "                    optimization_mode='auto', \n",
    "                    compile_model=True):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, is_timeseries = load_dataset_at(dataset_id,\n",
    "                                                                      fold_index=dataset_fold_id,\n",
    "                                                                      normalize_timeseries=normalize_timeseries)\n",
    "    max_timesteps, max_nb_variables = calculate_dataset_metrics(X_train)\n",
    "\n",
    "    if max_nb_variables != MAX_NB_VARIABLES[dataset_id]:\n",
    "        if cutoff is None:\n",
    "            choice = cutoff_choice(dataset_id, max_nb_variables)\n",
    "        else:\n",
    "            assert cutoff in [\n",
    "                'pre', 'post'], 'Cutoff parameter value must be either \"pre\" or \"post\"'\n",
    "            choice = cutoff\n",
    "\n",
    "        if choice not in ['pre', 'post']:\n",
    "            return\n",
    "        else:\n",
    "            X_train, X_test = cutoff_sequence(\n",
    "                X_train, X_test, choice, dataset_id, max_nb_variables)\n",
    "            \n",
    "    classes = np.unique(y_train)\n",
    "    le = LabelEncoder()\n",
    "    y_ind = le.fit_transform(y_train.ravel())\n",
    "    recip_freq = len(y_train) / (len(le.classes_) *\n",
    "                                 np.bincount(y_ind).astype(np.float64))\n",
    "    class_weight = recip_freq[le.transform(classes)]\n",
    "\n",
    "    print(\"Class weights : \", class_weight)\n",
    "\n",
    "    y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
    "    y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
    "\n",
    "    if is_timeseries:\n",
    "        factor = 1./np.cbrt(2)\n",
    "    else:\n",
    "        factor = 1./np.sqrt(2)\n",
    "\n",
    "    if dataset_fold_id is None:\n",
    "        weight_fn = \"./weights/%s_weights.h5\" % dataset_prefix\n",
    "    else:\n",
    "        weight_fn = \"./weights/%s_fold_%d_weights.h5\" % (\n",
    "            dataset_prefix, dataset_fold_id)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(weight_fn, verbose=1, mode=optimization_mode,\n",
    "                                       monitor=monitor, save_best_only=True, save_weights_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=monitor, patience=100, mode=optimization_mode,\n",
    "                                  factor=factor, cooldown=0, min_lr=1e-4, verbose=2)\n",
    "    callback_list = [model_checkpoint, reduce_lr]\n",
    "\n",
    "    optm = Adam(lr=learning_rate)\n",
    "\n",
    "    if compile_model:\n",
    "        model.compile(optimizer=optm,\n",
    "                      loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if val_subset is not None:\n",
    "        X_test = X_test[:val_subset]\n",
    "        y_test = y_test[:val_subset]\n",
    "\n",
    "    model.fit([X_train, ], y_train, batch_size=batch_size, epochs=epochs, callbacks=callback_list,\n",
    "              class_weight=class_weight, verbose=2, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "def evaluate_model(model: Model, dataset_id, dataset_prefix, dataset_fold_id=None, batch_size=128, test_data_subset=None,\n",
    "                   cutoff=None, normalize_timeseries=False):\n",
    "    _, _, X_test, y_test, is_timeseries = load_dataset_at(dataset_id,\n",
    "                                                          fold_index=dataset_fold_id,\n",
    "                                                          normalize_timeseries=normalize_timeseries)\n",
    "    max_timesteps, max_nb_variables = calculate_dataset_metrics(X_test)\n",
    "\n",
    "    if max_nb_variables != MAX_NB_VARIABLES[dataset_id]:\n",
    "        if cutoff is None:\n",
    "            choice = cutoff_choice(dataset_id, max_nb_variables)\n",
    "        else:\n",
    "            assert cutoff in [\n",
    "                'pre', 'post'], 'Cutoff parameter value must be either \"pre\" or \"post\"'\n",
    "            choice = cutoff\n",
    "\n",
    "        if choice not in ['pre', 'post']:\n",
    "            return\n",
    "        else:\n",
    "            _, X_test = cutoff_sequence(\n",
    "                None, X_test, choice, dataset_id, max_nb_variables)\n",
    "\n",
    "    if not is_timeseries:\n",
    "        X_test = pad_sequences(\n",
    "            X_test, maxlen=MAX_NB_VARIABLES[dataset_id], padding='post', truncating='post')\n",
    "    y_test = to_categorical(y_test, len(np.unique(y_test)))\n",
    "\n",
    "    optm = Adam(lr=1e-3)\n",
    "    model.compile(optimizer=optm, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if dataset_fold_id is None:\n",
    "        weight_fn = \"./weights/%s_weights.h5\" % dataset_prefix\n",
    "    else:\n",
    "        weight_fn = \"./weights/%s_fold_%d_weights.h5\" % (\n",
    "            dataset_prefix, dataset_fold_id)\n",
    "    model.load_weights(weight_fn)\n",
    "\n",
    "    if test_data_subset is not None:\n",
    "        X_test = X_test[:test_data_subset]\n",
    "        y_test = y_test[:test_data_subset]\n",
    "\n",
    "    print(\"\\nEvaluating : \")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print()\n",
    "    print(\"Final Accuracy : \", accuracy)\n",
    "\n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def set_trainable(layer, value):\n",
    "    layer.trainable = value\n",
    "\n",
    "    # case: container\n",
    "    if hasattr(layer, 'layers'):\n",
    "        for l in layer.layers:\n",
    "            set_trainable(l, value)\n",
    "\n",
    "    # case: wrapper (which is a case not covered by the PR)\n",
    "    if hasattr(layer, 'layer'):\n",
    "        set_trainable(layer.layer, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# save np.load\n",
    "#np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "#np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 650, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (36255, 651, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-586-b339e4d1dee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (36255, 651, 4)"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = tf.keras.Sequential()\n",
    "# model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Concatenate())([merge1, aux_input])\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.43%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 17s 664us/sample - loss: 0.4726 - accuracy: 0.7660\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 15s 582us/sample - loss: 0.3136 - accuracy: 0.8726\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 14s 580us/sample - loss: 0.2572 - accuracy: 0.8997\n",
      "Accuracy: 86.34%\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Dropout for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.layers.convolutional'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-946ba871defd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.convolutional'"
     ]
    }
   ],
   "source": [
    "# LSTM and CNN for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "model.add(LSTM(64, dropout=0.7, recurrent_dropout=0.7))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   14,    6,  717],\n",
       "       [   0,    0,    0, ...,  125,    4, 3077],\n",
       "       [  33,    6,   58, ...,    9,   57,  975],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   21,  846,    2],\n",
       "       [   0,    0,    0, ..., 2302,    7,  470],\n",
       "       [   0,    0,    0, ...,   34, 2005, 2643]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-11fe80a1b124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# load the dataset b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# truncate and pad input sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# LSTM with Dropout for sequence classification in msd dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset b\n",
    " z\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "\n",
    "class RNNCell(object):\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        raise NotImplementedError(\"Abstract method\")\n",
    "    \n",
    "\n",
    "class LSTMCell(RNNCell):\n",
    "    \"\"\"Basic LSTM recurrent network cell.\n",
    "    The implementation is based on: http://arxiv.org/abs/1409.2329.\n",
    "    We add forget_bias (default: 1) to the biases of the forget gate in order to\n",
    "    reduce the scale of forgetting in the beginning of the training.\n",
    "    It does not allow cell clipping, a projection layer, and does not\n",
    "    use peep-hole connections: it is the basic baseline.\n",
    "    For advanced models, please use the full LSTMCell that follows.\n",
    "    \"\"\"  \n",
    "    def __init__(self, n_units, n_proj=None, forget_bias=0.0, input_size=None, activation=tanh):\n",
    "        self._n_units  = n_units\n",
    "        self._n_proj = n_proj\n",
    "        self._forget_bias = forget_bias\n",
    "        self._input_size = input_size\n",
    "        self._activation = activation\n",
    "\n",
    "        (self._state_size, \n",
    "         self._output_size) = ((LSTMStateTuple(n_units, n_proj) , n_units + n_proj)\n",
    "                            if n_proj else (LSTMStateTuple(n_units, n_units), 2*n_units))\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self. _output_size\n",
    "    \n",
    "    \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        \n",
    "        pass\n",
    "\n",
    "# class LSTM(LSTM):\n",
    "    \n",
    "    \n",
    "#     def __init__(self, ):\n",
    "#         pass\n",
    "    \n",
    "_LSTMStateTuple = collections.namedtuple(\"LSTMStateTuple\", (\"c\", \"h\"))\n",
    "\n",
    "class LSTMStateTuple(_LSTMStateTuple):\n",
    "  \n",
    "    \"\"\"Tuple used by LSTM Cells for `state_size`, `zero_state`, and output state.\n",
    "    Stores two elements: `(c, h)`, in that order.\n",
    "    Only used when `state_is_tuple=True`.\n",
    "    \"\"\"\n",
    "    __slots__ = ()\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        (c, h) = self\n",
    "        if not c.dtype == h.dtype:\n",
    "            raise TypeError(\"Inconsistent internal state: %s vs %s\" %\n",
    "                            (str(c.dtype), str(h.dtype)))\n",
    "    return c.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTMCell(50, 20, 1.0, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=50, h=20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'n_units'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ccebf5a8883c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'n_units'"
     ]
    }
   ],
   "source": [
    "x = LSTMCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
