{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries used\n",
    "import boto3\n",
    "import diff_classifier.aws as aws\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from diff_classifier.features import calculate_features\n",
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "from matplotlib import colors as plt_colors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, DBSCAN, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Notebook Dir: /Users/nelsschimek/Documents/Nance Lab/diff_predictor/notebooks\nUsing current directory for loading data: /Users/nelsschimek/Documents/Nance Lab/diff_predictor\n"
     ]
    }
   ],
   "source": [
    "workbookDir = getcwd()\n",
    "print('Current Notebook Dir: ' + workbookDir)\n",
    "chdir(workbookDir) # Go to current workbook Dir\n",
    "chdir('..')        # Go up one\n",
    "print(f'Using current directory for loading data: {getcwd()}')\n",
    "workbookDir = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['feat_NT_slice_2_striatum_vid_4.csv',\n",
       " 'feat_NT_slice_2_striatum_vid_5.csv',\n",
       " 'feat_NT_slice_1_striatum_vid_1.csv',\n",
       " 'feat_NT_slice_2_cortex_vid_4.csv',\n",
       " 'feat_NT_slice_1_striatum_vid_3.csv',\n",
       " 'feat_NT_slice_1_cortex_vid_10.csv',\n",
       " 'feat_NT_slice_1_striatum_vid_2.csv',\n",
       " 'feat_NT_slice_2_cortex_vid_5.csv',\n",
       " 'feat_NT_slice_2_cortex_vid_1.csv',\n",
       " 'feat_NT_slice_2_hippocampus_vid_2.csv',\n",
       " 'feat_NT_slice_2_striatum_vid_2.csv',\n",
       " 'feat_NT_slice_2_striatum_vid_3.csv',\n",
       " 'feat_NT_slice_2_hippocampus_vid_3.csv',\n",
       " 'feat_NT_slice_2_cortex_vid_2.csv',\n",
       " 'feat_NT_slice_1_cortex_vid_8.csv',\n",
       " 'feat_NT_slice_1_striatum_vid_5.csv',\n",
       " 'feat_NT_slice_2_hippocampus_vid_1.csv',\n",
       " 'feat_NT_slice_2_striatum_vid_1.csv',\n",
       " 'feat_NT_slice_1_striatum_vid_4.csv',\n",
       " 'feat_NT_slice_1_cortex_vid_9.csv',\n",
       " 'feat_NT_slice_2_cortex_vid_3.csv',\n",
       " 'feat_NT_slice_1_hippocampus_vid_1.csv',\n",
       " 'feat_NT_slice_1_hippocampus_vid_3.csv',\n",
       " 'feat_NT_slice_1_hippocampus_vid_2.csv',\n",
       " 'feat_NT_slice_2_ganglia_vid_3.csv',\n",
       " 'feat_NT_slice_2_ganglia_vid_2.csv',\n",
       " 'feat_NT_slice_2_ganglia_vid_1.csv',\n",
       " 'feat_NT_slice_1_thalamus_vid_3.csv',\n",
       " 'feat_NT_slice_1_ganglia_vid_3.csv',\n",
       " 'feat_NT_slice_1_ganglia_vid_2.csv',\n",
       " 'feat_NT_slice_1_thalamus_vid_2.csv',\n",
       " 'feat_NT_slice_1_cortex_vid_7.csv',\n",
       " 'feat_NT_slice_1_cortex_vid_6.csv',\n",
       " 'feat_NT_slice_1_ganglia_vid_1.csv',\n",
       " 'feat_NT_slice_1_thalamus_vid_1.csv',\n",
       " 'feat_NT_slice_2_thalamus_vid_1.csv',\n",
       " 'feat_NT_slice_2_thalamus_vid_2.csv',\n",
       " 'feat_NT_slice_2_thalamus_vid_3.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset_path = workbookDir + '/region_feature_folder/'\n",
    "filelist = [f for f in listdir(dataset_path) if isfile(join(dataset_path, f)) and 'feat' in f]\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "feat_NT_slice_2_striatum_vid_4.csv size: (10237, 67)\n",
      "feat_NT_slice_2_striatum_vid_5.csv size: (13938, 67)\n",
      "feat_NT_slice_1_striatum_vid_1.csv size: (2431, 67)\n",
      "feat_NT_slice_2_cortex_vid_4.csv size: (1429, 67)\n",
      "feat_NT_slice_1_striatum_vid_3.csv size: (1536, 67)\n",
      "feat_NT_slice_1_cortex_vid_10.csv size: (4832, 67)\n",
      "feat_NT_slice_1_striatum_vid_2.csv size: (2240, 67)\n",
      "feat_NT_slice_2_cortex_vid_5.csv size: (2210, 67)\n",
      "feat_NT_slice_2_cortex_vid_1.csv size: (1388, 67)\n",
      "feat_NT_slice_2_hippocampus_vid_2.csv size: (46, 67)\n",
      "feat_NT_slice_2_striatum_vid_2.csv size: (10500, 67)\n",
      "feat_NT_slice_2_striatum_vid_3.csv size: (11355, 67)\n",
      "feat_NT_slice_2_hippocampus_vid_3.csv size: (307, 67)\n",
      "feat_NT_slice_2_cortex_vid_2.csv size: (1784, 67)\n",
      "feat_NT_slice_1_cortex_vid_8.csv size: (1984, 67)\n",
      "feat_NT_slice_1_striatum_vid_5.csv size: (2169, 67)\n",
      "feat_NT_slice_2_hippocampus_vid_1.csv size: (250, 67)\n",
      "feat_NT_slice_2_striatum_vid_1.csv size: (8314, 67)\n",
      "feat_NT_slice_1_striatum_vid_4.csv size: (2177, 67)\n",
      "feat_NT_slice_1_cortex_vid_9.csv size: (6506, 67)\n",
      "feat_NT_slice_2_cortex_vid_3.csv size: (3520, 67)\n",
      "feat_NT_slice_1_hippocampus_vid_1.csv size: (4149, 67)\n",
      "feat_NT_slice_1_hippocampus_vid_3.csv size: (3519, 67)\n",
      "feat_NT_slice_1_hippocampus_vid_2.csv size: (2148, 67)\n",
      "feat_NT_slice_2_ganglia_vid_3.csv size: (473, 67)\n",
      "feat_NT_slice_2_ganglia_vid_2.csv size: (216, 67)\n",
      "feat_NT_slice_2_ganglia_vid_1.csv size: (908, 67)\n",
      "feat_NT_slice_1_thalamus_vid_3.csv size: (1894, 67)\n",
      "feat_NT_slice_1_ganglia_vid_3.csv size: (514, 67)\n",
      "feat_NT_slice_1_ganglia_vid_2.csv size: (533, 67)\n",
      "feat_NT_slice_1_thalamus_vid_2.csv size: (3429, 67)\n",
      "feat_NT_slice_1_cortex_vid_7.csv size: (4159, 67)\n",
      "feat_NT_slice_1_cortex_vid_6.csv size: (7990, 67)\n",
      "feat_NT_slice_1_ganglia_vid_1.csv size: (313, 67)\n",
      "feat_NT_slice_1_thalamus_vid_1.csv size: (1423, 67)\n",
      "feat_NT_slice_2_thalamus_vid_1.csv size: (1955, 67)\n",
      "feat_NT_slice_2_thalamus_vid_2.csv size: (1534, 67)\n",
      "feat_NT_slice_2_thalamus_vid_3.csv size: (1106, 67)\n"
     ]
    }
   ],
   "source": [
    "fstats_tot = None\n",
    "video_num = 0\n",
    "for filename in filelist:\n",
    "#     try:\n",
    "        fstats = pd.read_csv(dataset_path + filename, encoding = \"ISO-8859-1\", index_col='Unnamed: 0')\n",
    "        print('{} size: {}'.format(filename, fstats.shape))\n",
    "        if 'cortex' in filename:\n",
    "            fstats['region'] = pd.Series(fstats.shape[0]*['cortex'], index=fstats.index)\n",
    "        elif 'striatum' in filename:\n",
    "            fstats['region'] = pd.Series(fstats.shape[0]*['striatum'], index=fstats.index)\n",
    "        elif 'ganglia' in filename:\n",
    "            fstats['region'] = pd.Series(fstats.shape[0]*['ganglia'], index=fstats.index)\n",
    "        elif 'thalamus' in filename:\n",
    "            fstats['region'] = pd.Series(fstats.shape[0]*['thalamus'], index=fstats.index)\n",
    "        elif 'hippocampus' in filename:\n",
    "            fstats['region'] = pd.Series(fstats.shape[0]*['hippocampus'], index=fstats.index)\n",
    "        else:\n",
    "            print('Error, no target')\n",
    "        fstats['Video Number'] = pd.Series(fstats.shape[0]*[video_num], index=fstats.index)\n",
    "        if fstats_tot is None:\n",
    "            fstats_tot = fstats\n",
    "        else:\n",
    "            fstats_tot = fstats_tot.append(fstats, ignore_index=True)\n",
    "        video_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Track_ID         alpha      D_fit   kurtosis  asymmetry1  asymmetry2  \\\n",
       "0       0.0  1.611765e-02  26.711181   3.288428    0.945602    0.118247   \n",
       "1       1.0  1.567008e-08   0.619012   2.837829    0.300884    0.539952   \n",
       "2       2.0  3.825253e-01   0.025727   3.874284    0.038580    0.819546   \n",
       "3       3.0           NaN        NaN  32.947937    0.981209    0.068865   \n",
       "4       4.0  4.294176e-01   0.240604   2.306450    0.156974    0.657617   \n",
       "\n",
       "   asymmetry3        AR  elongation  boundedness  ...  Mean Mean_Intensity  \\\n",
       "0    0.372335  2.366365    0.577411     0.097441  ...                  NaN   \n",
       "1    0.045650  1.128631    0.113970     0.251949  ...                  NaN   \n",
       "2    0.004930  1.091210    0.083586     0.058152  ...                  NaN   \n",
       "3    0.477143  6.559554    0.847551     0.017961  ...                  NaN   \n",
       "4    0.021563  1.523668    0.343689     0.013608  ...                  NaN   \n",
       "\n",
       "   Std Mean_Intensity  Mean SN_Ratio  Std SN_Ratio  Mean Deff1  Std Deff1  \\\n",
       "0                 NaN       0.767566      0.170583    0.959069   1.306709   \n",
       "1                 NaN       0.944781      0.389032    0.196385   0.214294   \n",
       "2                 NaN       0.668841      0.169089    1.263415   2.049538   \n",
       "3                 NaN       0.668841      0.169089    1.263415   2.049538   \n",
       "4                 NaN       0.944781      0.389032    0.196385   0.214294   \n",
       "\n",
       "   Mean Deff2  Std Deff2    region  Video Number  \n",
       "0    0.100702   0.109127  striatum             0  \n",
       "1    0.018856   0.020472  striatum             0  \n",
       "2    0.255571   0.469424  striatum             0  \n",
       "3    0.255571   0.469424  striatum             0  \n",
       "4    0.018856   0.020472  striatum             0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Track_ID</th>\n      <th>alpha</th>\n      <th>D_fit</th>\n      <th>kurtosis</th>\n      <th>asymmetry1</th>\n      <th>asymmetry2</th>\n      <th>asymmetry3</th>\n      <th>AR</th>\n      <th>elongation</th>\n      <th>boundedness</th>\n      <th>...</th>\n      <th>Mean Mean_Intensity</th>\n      <th>Std Mean_Intensity</th>\n      <th>Mean SN_Ratio</th>\n      <th>Std SN_Ratio</th>\n      <th>Mean Deff1</th>\n      <th>Std Deff1</th>\n      <th>Mean Deff2</th>\n      <th>Std Deff2</th>\n      <th>region</th>\n      <th>Video Number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.611765e-02</td>\n      <td>26.711181</td>\n      <td>3.288428</td>\n      <td>0.945602</td>\n      <td>0.118247</td>\n      <td>0.372335</td>\n      <td>2.366365</td>\n      <td>0.577411</td>\n      <td>0.097441</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.767566</td>\n      <td>0.170583</td>\n      <td>0.959069</td>\n      <td>1.306709</td>\n      <td>0.100702</td>\n      <td>0.109127</td>\n      <td>striatum</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.567008e-08</td>\n      <td>0.619012</td>\n      <td>2.837829</td>\n      <td>0.300884</td>\n      <td>0.539952</td>\n      <td>0.045650</td>\n      <td>1.128631</td>\n      <td>0.113970</td>\n      <td>0.251949</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.944781</td>\n      <td>0.389032</td>\n      <td>0.196385</td>\n      <td>0.214294</td>\n      <td>0.018856</td>\n      <td>0.020472</td>\n      <td>striatum</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>3.825253e-01</td>\n      <td>0.025727</td>\n      <td>3.874284</td>\n      <td>0.038580</td>\n      <td>0.819546</td>\n      <td>0.004930</td>\n      <td>1.091210</td>\n      <td>0.083586</td>\n      <td>0.058152</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.668841</td>\n      <td>0.169089</td>\n      <td>1.263415</td>\n      <td>2.049538</td>\n      <td>0.255571</td>\n      <td>0.469424</td>\n      <td>striatum</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>32.947937</td>\n      <td>0.981209</td>\n      <td>0.068865</td>\n      <td>0.477143</td>\n      <td>6.559554</td>\n      <td>0.847551</td>\n      <td>0.017961</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.668841</td>\n      <td>0.169089</td>\n      <td>1.263415</td>\n      <td>2.049538</td>\n      <td>0.255571</td>\n      <td>0.469424</td>\n      <td>striatum</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>4.294176e-01</td>\n      <td>0.240604</td>\n      <td>2.306450</td>\n      <td>0.156974</td>\n      <td>0.657617</td>\n      <td>0.021563</td>\n      <td>1.523668</td>\n      <td>0.343689</td>\n      <td>0.013608</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.944781</td>\n      <td>0.389032</td>\n      <td>0.196385</td>\n      <td>0.214294</td>\n      <td>0.018856</td>\n      <td>0.020472</td>\n      <td>striatum</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 69 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "fstats_tot.columns\n",
    "fstats_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot\n",
    "features = [\n",
    "    'alpha', # Fitted anomalous diffusion alpha exponenet\n",
    "    'D_fit', # Fitted anomalous diffusion coefficient\n",
    "    'kurtosis', # Kurtosis of track\n",
    "    'asymmetry1', # Asymmetry of trajecory (0 for circular symmetric, 1 for linear)\n",
    "    'asymmetry2', # Ratio of the smaller to larger principal radius of gyration\n",
    "    'asymmetry3', # An asymmetric feature that accnts for non-cylindrically symmetric pt distributions\n",
    "    'AR', # Aspect ratio of long and short side of trajectory's minimum bounding rectangle\n",
    "    'elongation', # Est. of amount of extension of trajectory from centroid\n",
    "    'boundedness', # How much a particle with Deff is restricted by a circular confinement of radius r\n",
    "    'fractal_dim', # Measure of how complicated a self similar figure is\n",
    "    'trappedness', # Probability that a particle with Deff is trapped in a region\n",
    "    'efficiency', # Ratio of squared net displacement to the sum of squared step lengths\n",
    "    'straightness', # Ratio of net displacement to the sum of squared step lengths\n",
    "    'MSD_ratio', # MSD ratio of the track\n",
    "    'frames', # Number of frames the track spans\n",
    "    'Deff1', # Effective diffusion coefficient at 0.33 s\n",
    "    'Deff2', # Effective diffusion coefficient at 3.3 s\n",
    "    #'angle_mean', # Mean turning angle which is counterclockwise angle from one frame point to another\n",
    "    #'angle_mag_mean', # Magnitude of the turning angle mean\n",
    "    #'angle_var', # Variance of the turning angle\n",
    "    #'dist_tot', # Total distance of the trajectory\n",
    "   # 'dist_net', # Net distance from first point to last point\n",
    "    #'progression', # Ratio of the net distance traveled and the total distance\n",
    "    'Mean alpha', \n",
    "    'Mean D_fit', \n",
    "    'Mean kurtosis', \n",
    "    'Mean asymmetry1', \n",
    "    'Mean asymmetry2',\n",
    "    'Mean asymmetry3', \n",
    "    'Mean AR',\n",
    "    'Mean elongation', \n",
    "    'Mean boundedness',\n",
    "    'Mean fractal_dim', \n",
    "    'Mean trappedness', \n",
    "    'Mean efficiency',\n",
    "    'Mean straightness', \n",
    "    'Mean MSD_ratio', \n",
    "    'Mean Deff1', \n",
    "    'Mean Deff2',\n",
    "    ]\n",
    "\n",
    "target = 'region'           # prediction target (y)\n",
    "\n",
    "\n",
    "linear_features = [\n",
    "    'Mean Deff1',\n",
    "    'Mean D_fit',\n",
    "    'Mean fractal_dim',\n",
    "    'Mean MSD_ratio',\n",
    "    'Mean kurtosis',\n",
    "    'Mean straightness'\n",
    "    ]\n",
    "    \n",
    "ecm = fstats_tot\n",
    "ecm = fstats_tot[features + [target] + ['X'] + ['Y']]\n",
    "ecm = ecm[~ecm.isin([np.nan, np.inf, -np.inf]).any(1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ratio before data balance (striatum:cortex:hippocampus:ganglia:thalamus) = 17401:6575:124:233:186\nRatio after balance (striatum:cortex:hippocampus:ganglia:thalamus) = 124:124:124:124:124\n"
     ]
    }
   ],
   "source": [
    "#--------------NOT-ADDED-----------------------------\n",
    "def balance_data(df, target, **kwargs):\n",
    "    if 'random_state' not in kwargs:\n",
    "        random_state = 1\n",
    "    else:\n",
    "        random_state = kwargs['random_state']\n",
    "    if isinstance(target, list):\n",
    "        target = target[0]\n",
    "    df_target = []\n",
    "    bal_df = []\n",
    "    for name in df[target].unique():\n",
    "        df_target.append((name, df[df[target] == name]))\n",
    "    print(f\"Ratio before data balance ({':'.join([str(i[0]) for i in df_target])}) = {':'.join([str(len(i[1])) for i in df_target])}\")\n",
    "    for i in range(len(df_target)):\n",
    "        ratio = min([len(i[1]) for i in df_target])/len(df_target[i][1])\n",
    "        bal_df.append(df_target[i][1].sample(frac=ratio, random_state=random_state))\n",
    "    print(f\"Ratio after balance ({':'.join([str(i[0]) for i in df_target])}) = {':'.join([str(len(i)) for i in bal_df])}\")\n",
    "    return pd.concat(bal_df)\n",
    "bal_ecm = balance_data(ecm, target, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 128\n",
    "assert not 2048%resolution and resolution >= 128, \"resolution needs to be a factor of 2048 and > 128\"\n",
    "bins = list(range(0, 2048+1, resolution))\n",
    "bin_labels = [int(i/resolution) for i in bins][:-1]\n",
    "bal_ecm['binx'] = pd.cut(bal_ecm.X, bins, labels=bin_labels, include_lowest=True)\n",
    "bal_ecm['biny'] = pd.cut(bal_ecm.Y, bins, labels=bin_labels, include_lowest=True)\n",
    "bal_ecm['bins'] = (len(bins)-1)*bal_ecm['binx'].astype(np.int32) + bal_ecm['biny'].astype(np.int32)\n",
    "bal_ecm = bal_ecm[np.isfinite(bal_ecm['bins'])]\n",
    "bal_ecm['bins'] = bal_ecm['bins'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['striatum', 'cortex', 'hippocampus', 'ganglia', 'thalamus'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "label_df = bal_ecm[target]\n",
    "df2 = bal_ecm[features]\n",
    "result = pd.concat([df2, label_df], axis=1)\n",
    "#result_small = result.sample(5000)\n",
    "result['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "620\n620\n620\n620\n\nSSE value:  13473.2045886611\nNum iterations for convergence:  21\n"
     ]
    }
   ],
   "source": [
    "result_cleaned = result[~result.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "X = result_cleaned[features]\n",
    "print(len(result))\n",
    "print(len(result_cleaned))\n",
    "print(len(result_cleaned['region']))\n",
    "print(len(X))\n",
    "print()\n",
    "\n",
    "ss = StandardScaler()\n",
    "scaled_features = ss.fit_transform(X.values)\n",
    "kmean = KMeans(n_clusters=5, init='k-means++').fit(scaled_features)\n",
    "centroids = kmean.cluster_centers_\n",
    "\n",
    "print('SSE value: ', kmean.inertia_)\n",
    "print('Num iterations for convergence: ', kmean.n_iter_)\n",
    "#spec = SpectralClustering(n_clusters=4).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Region: striatum\nPercent in cluster 0 = 12.90%\nPercent in cluster 1 = 33.87%\nPercent in cluster 2 = 53.23%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 0.00%\n\nRegion: cortex\nPercent in cluster 0 = 15.32%\nPercent in cluster 1 = 9.68%\nPercent in cluster 2 = 69.35%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 5.65%\n\nRegion: hippocampus\nPercent in cluster 0 = 46.77%\nPercent in cluster 1 = 12.90%\nPercent in cluster 2 = 16.13%\nPercent in cluster 3 = 1.61%\nPercent in cluster 4 = 22.58%\n\nRegion: ganglia\nPercent in cluster 0 = 20.97%\nPercent in cluster 1 = 41.13%\nPercent in cluster 2 = 29.03%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 8.87%\n\nRegion: thalamus\nPercent in cluster 0 = 44.35%\nPercent in cluster 1 = 11.29%\nPercent in cluster 2 = 16.13%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 28.23%\n\n"
     ]
    }
   ],
   "source": [
    "def get_cluster_distributions(cluster_labels, df_with_target, n_clusters):\n",
    "\n",
    "    for region in result_cleaned['region'].unique():\n",
    "        idx = np.array(df_with_target['region'] == region)\n",
    "        clust_labels = cluster_labels[idx]\n",
    "        true_label = result_cleaned.iloc[idx]\n",
    "        print('Region:', region)\n",
    "        for i in range(0, n_clusters):\n",
    "            ct = (clust_labels == i).sum()\n",
    "            percent = '{:.2%}'.format(ct/len(clust_labels))\n",
    "            print('Percent in cluster', i,'=', percent)\n",
    "        print()\n",
    "get_cluster_distributions(kmean.labels_, result_cleaned, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Region: striatum\nPercent in cluster 0 = 0.00%\nPercent in cluster 1 = 0.81%\nPercent in cluster 2 = 27.42%\nPercent in cluster 3 = 62.90%\nPercent in cluster 4 = 8.87%\n\nRegion: cortex\nPercent in cluster 0 = 6.45%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 20.97%\nPercent in cluster 3 = 71.77%\nPercent in cluster 4 = 0.81%\n\nRegion: hippocampus\nPercent in cluster 0 = 42.74%\nPercent in cluster 1 = 4.03%\nPercent in cluster 2 = 30.65%\nPercent in cluster 3 = 17.74%\nPercent in cluster 4 = 4.84%\n\nRegion: ganglia\nPercent in cluster 0 = 12.90%\nPercent in cluster 1 = 0.81%\nPercent in cluster 2 = 28.23%\nPercent in cluster 3 = 32.26%\nPercent in cluster 4 = 25.81%\n\nRegion: thalamus\nPercent in cluster 0 = 58.87%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 32.26%\nPercent in cluster 3 = 8.06%\nPercent in cluster 4 = 0.81%\n\n"
     ]
    }
   ],
   "source": [
    "agg = AgglomerativeClustering(n_clusters=5).fit(scaled_features)\n",
    "get_cluster_distributions(agg.labels_, result_cleaned, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Region: striatum\nPercent in cluster 0 = 100.00%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 0.00%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 0.00%\n\nRegion: cortex\nPercent in cluster 0 = 100.00%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 0.00%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 0.00%\n\nRegion: hippocampus\nPercent in cluster 0 = 99.19%\nPercent in cluster 1 = 0.81%\nPercent in cluster 2 = 0.00%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 0.00%\n\nRegion: ganglia\nPercent in cluster 0 = 100.00%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 0.00%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 0.00%\n\nRegion: thalamus\nPercent in cluster 0 = 100.00%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 0.00%\nPercent in cluster 3 = 0.00%\nPercent in cluster 4 = 0.00%\n\n"
     ]
    }
   ],
   "source": [
    "spec = SpectralClustering(n_clusters=5).fit(scaled_features)\n",
    "get_cluster_distributions(spec.labels_, result_cleaned, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Region: striatum\nPercent in cluster 0 = 30.65%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 56.45%\nPercent in cluster 3 = 6.45%\nPercent in cluster 4 = 6.45%\n\nRegion: cortex\nPercent in cluster 0 = 6.45%\nPercent in cluster 1 = 18.55%\nPercent in cluster 2 = 40.32%\nPercent in cluster 3 = 29.84%\nPercent in cluster 4 = 4.84%\n\nRegion: hippocampus\nPercent in cluster 0 = 25.00%\nPercent in cluster 1 = 42.74%\nPercent in cluster 2 = 5.65%\nPercent in cluster 3 = 7.26%\nPercent in cluster 4 = 19.35%\n\nRegion: ganglia\nPercent in cluster 0 = 30.65%\nPercent in cluster 1 = 22.58%\nPercent in cluster 2 = 34.68%\nPercent in cluster 3 = 0.81%\nPercent in cluster 4 = 11.29%\n\nRegion: thalamus\nPercent in cluster 0 = 9.68%\nPercent in cluster 1 = 60.48%\nPercent in cluster 2 = 4.84%\nPercent in cluster 3 = 1.61%\nPercent in cluster 4 = 23.39%\n\n"
     ]
    }
   ],
   "source": [
    "guass = GaussianMixture(n_components=5).fit_predict(scaled_features)\n",
    "get_cluster_distributions(guass, result_cleaned, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Region: striatum\nPercent in cluster 0 = 41.13%\nPercent in cluster 1 = 0.00%\nPercent in cluster 2 = 4.03%\nPercent in cluster 3 = 10.48%\nPercent in cluster 4 = 44.35%\n\nRegion: cortex\nPercent in cluster 0 = 13.71%\nPercent in cluster 1 = 5.65%\nPercent in cluster 2 = 18.55%\nPercent in cluster 3 = 2.42%\nPercent in cluster 4 = 59.68%\n\nRegion: hippocampus\nPercent in cluster 0 = 16.13%\nPercent in cluster 1 = 8.87%\nPercent in cluster 2 = 56.45%\nPercent in cluster 3 = 8.06%\nPercent in cluster 4 = 10.48%\n\nRegion: ganglia\nPercent in cluster 0 = 38.71%\nPercent in cluster 1 = 1.61%\nPercent in cluster 2 = 29.84%\nPercent in cluster 3 = 6.45%\nPercent in cluster 4 = 23.39%\n\nRegion: thalamus\nPercent in cluster 0 = 7.26%\nPercent in cluster 1 = 8.06%\nPercent in cluster 2 = 75.00%\nPercent in cluster 3 = 6.45%\nPercent in cluster 4 = 3.23%\n\n"
     ]
    }
   ],
   "source": [
    "bay_gauss = BayesianGaussianMixture(n_components=5).fit_predict(scaled_features)\n",
    "get_cluster_distributions(bay_gauss, result_cleaned, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(63, 33)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "affinity = AffinityPropagation().fit(scaled_features)\n",
    "affinity.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}